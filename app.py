import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
import requests
import json
import numpy as np
import os
import telegram_utils
import data_engine
from io import BytesIO
from datetime import datetime, timedelta

# --- CHART THEME ---
def update_chart_layout(fig):
    fig.update_layout(
        template="plotly_dark",
        font=dict(family="Inter, sans-serif", size=13, color="#E0E0E0"),
        margin=dict(l=20, r=20, t=50, b=20),
        paper_bgcolor="rgba(0,0,0,0)",
        plot_bgcolor="rgba(255,255,255,0.02)", # Slight highlight
        hovermode="x unified",
        xaxis=dict(
            showgrid=False, 
            zeroline=False, 
            showline=True, 
            linecolor="rgba(255,255,255,0.2)"
        ),
        yaxis=dict(
            showgrid=True, 
            gridcolor="rgba(255,255,255,0.08)", 
            zeroline=False
        ),
        legend=dict(
            orientation="h",
            yanchor="bottom",
            y=1.02,
            xanchor="right",
            x=1
        )
    )
    return fig

# --- V2.1 Helper ---
def get_secret(key):
    try:
        return st.secrets.get(key)
    except FileNotFoundError:
        return None

# --- –ù–ê–°–¢–†–û–ô–ö–ò –°–¢–†–ê–ù–ò–¶–´ ---
st.set_page_config(page_title="RestoAnalytics: –ú–µ—Å—Ç–æ", layout="wide", initial_sidebar_state="expanded")
st.title("üìä –ê–Ω–∞–ª–∏—Ç–∏–∫–∞: –ë–∞—Ä –ú–ï–°–¢–û")

# --- CSS STYLING ---
def setup_style():
    st.markdown("""
    <style>
        /* Import Inter Font */
        @import url('https://fonts.googleapis.com/css2?family=Inter:wght@300;400;600&display=swap');

        html, body, [class*="css"] {
            font-family: 'Inter', sans-serif;
            background-color: #0e1117; /* Dark background base */
        }

        /* --- GLASSMORPHISM SIDEBAR --- */
        [data-testid="stSidebar"] {
            background-color: rgba(17, 17, 17, 0.7) !important;
            backdrop-filter: blur(12px);
            -webkit-backdrop-filter: blur(12px);
            border-right: 1px solid rgba(255, 255, 255, 0.08) !important;
        }

        /* --- GLASS METRIC CARDS --- */
        [data-testid="stMetric"] {
            background: rgba(45, 45, 45, 0.4) !important; /* Lighter tint */
            backdrop-filter: blur(18px); /* Deeper blur */
            -webkit-backdrop-filter: blur(18px);
            padding: 15px !important;
            border-radius: 16px !important; /* More iOS-like */
            border: 1px solid rgba(255, 255, 255, 0.15) !important; /* Stronger border */
            box-shadow: 0 8px 32px 0 rgba(0, 0, 0, 0.37) !important; /* Deeper shadow */
            transition: transform 0.2s ease, box-shadow 0.2s ease;
        }
        
        [data-testid="stMetric"]:hover {
            transform: translateY(-4px);
            box-shadow: 0 12px 40px rgba(0, 0, 0, 0.5) !important;
            border: 1px solid rgba(255, 255, 255, 0.25) !important;
            background: rgba(60, 60, 60, 0.5) !important;
        }

        [data-testid="stMetricLabel"] {
            font-size: 14px;
            color: rgba(255, 255, 255, 0.6);
        }

        [data-testid="stMetricValue"] {
            font-size: 26px;
            font-weight: 600;
            color: #FFF;
        }
        
        [data-testid="stMetricDelta"] {
            font-size: 14px;
        }

        /* --- HEADERS & TEXT --- */
        h1, h2, h3 {
            font-weight: 600;
            letter-spacing: -0.5px;
            color: #FFF;
        }
        
        /* --- EXPANDER STYLING (GLASS) --- */
        .streamlit-expanderHeader {
            background-color: rgba(30, 30, 30, 0.5);
            border-radius: 8px;
            border: 1px solid rgba(255, 255, 255, 0.05);
        }
        
        /* --- BUTTONS (Optional Polish) --- */
        button[kind="primary"] {
            background: linear-gradient(135deg, #FF4B4B 0%, #FF2B2B 100%);
            border: none;
            box-shadow: 0 4px 12px rgba(255, 75, 75, 0.3);
            transition: all 0.3s ease;
        }
        button[kind="primary"]:hover {
            box-shadow: 0 6px 16px rgba(255, 75, 75, 0.5);
            transform: translateY(-2px);
        }

        /* --- SIDEBAR ELEMENTS --- */
        .stSelectbox label, .stRadio label {
            font-weight: 600 !important;
            color: rgba(255,255,255,0.9) !important;
        }

        /* --- TABLE STYLING --- */
        [data-testid="stDataFrame"] {
            border-radius: 12px;
            border: 1px solid rgba(255, 255, 255, 0.1);
            overflow: hidden;
        }
        
        /* --- STREAMLIT HEADER --- */
        header[data-testid="stHeader"] {
            background: transparent !important;
            backdrop-filter: blur(5px);
        }

        /* Remove Deploy Button & Padding */
        #MainMenu {visibility: hidden;}
        .block-container {
            padding-top: 2rem;
            padding-bottom: 2rem;
        }
        
    </style>
    """, unsafe_allow_html=True)

setup_style()

# --- –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø –ü–ê–ú–Ø–¢–ò ---
if 'df_full' not in st.session_state:
    st.session_state.df_full = None
if 'dropped_stats' not in st.session_state:
    st.session_state.dropped_stats = {'count': 0, 'cost': 0.0, 'items': []}

# --- 1. –ì–†–£–ü–ü–ò–†–û–í–ö–ê –î–õ–Ø –ú–ê–ö–†–û-–£–†–û–í–ù–Ø ---



# --- SMART INSIGHTS ENGINE ---
def generate_insights(df_curr, df_prev, cur_rev, prev_rev, cur_fc):
    with st.expander("üí° Smart Insights (–ê–Ω–∞–ª–∏–∑ –ê–Ω–æ–º–∞–ª–∏–π)", expanded=True):
        insights = data_engine.calculate_insights(df_curr, df_prev, cur_rev, prev_rev, cur_fc)
        
        level_map = {
            'error': st.error,
            'warning': st.warning,
            'info': st.info,
            'success': st.success
        }
        
        for note in insights:
            # Render using the appropriate Streamlit function
            # Some messages in data_engine have bold markdown, st handles that fine.
            if note['level'] in level_map:
                level_map[note['level']](note['message'])

@st.cache_data(ttl=3600, show_spinner="–°–∫–∞—á–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ —Å –Ø–Ω–¥–µ–∫—Å.–î–∏—Å–∫–∞...")
def load_all_from_yandex(root_path):
    token = get_secret("YANDEX_TOKEN")
    if not token: return [], {'count': 0, 'cost': 0.0, 'items': []}
    
    headers = {'Authorization': f'OAuth {token}'}
    api_url = 'https://cloud-api.yandex.net/v1/disk/resources'
    
    all_dfs = []
    # Master accumulator for dropped stats (pure, no session_state)
    master_dropped = {'count': 0, 'cost': 0.0, 'items': []}
    
    def list_items(path, limit=1000):
        items_acc = []
        offset = 0

        while True:
            params = {'path': path, 'limit': limit, 'offset': offset}
            resp = requests.get(api_url, headers=headers, params=params, timeout=20)
            if resp.status_code != 200:
                st.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è –ø–∞–ø–∫–∏ '{path}' (status {resp.status_code})")
                return items_acc

            page_items = resp.json().get('_embedded', {}).get('items', [])
            if not page_items:
                break

            items_acc.extend(page_items)
            if len(page_items) < limit:
                break
            offset += limit

        return items_acc

    # Helper: Pure function returning (processed_dfs, batch_dropped_stats)
    def process_items(files, venue_tag):
        processed = []
        batch_dropped = {'count': 0, 'cost': 0.0, 'items': []}
        
        for item in files:
            try:
                file_resp = requests.get(item['file'], headers=headers, timeout=20)
                if file_resp.status_code != 200:
                    st.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–∫–∞—á–∞—Ç—å {item['name']} (Status {file_resp.status_code})")
                    continue
                    
                df, error, warnings, dropped = data_engine.process_single_file(BytesIO(file_resp.content), filename=item['name'])
                
                # Accumulate dropped stats for this batch
                if dropped:
                    batch_dropped['count'] += dropped['count']
                    batch_dropped['cost'] += dropped['cost']
                    batch_dropped['items'].extend(dropped['items'])

                if error:
                    st.warning(f"{item['name']}: {error}")
                for warn in warnings:
                    st.info(f"{item['name']}: {warn}")
                if df is not None:
                    df['Venue'] = venue_tag
                    processed.append(df)
            except Exception as e:
                st.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ {item['name']}: {e}")
                continue
        
        return processed, batch_dropped

    # Helper to merge stats
    def merge_stats(source):
        master_dropped['count'] += source['count']
        master_dropped['cost'] += source['cost']
        master_dropped['items'].extend(source['items'])

    try:
        # 1. Get Root Items (with pagination)
        items = list_items(root_path, limit=1000)
        if not items:
            return [], master_dropped
        
        folders = [i for i in items if i['type'] == 'dir']
        root_files = [i for i in items if i['type'] == 'file' and (i['name'].endswith('.xlsx') or i['name'].endswith('.csv'))]
        
        # 2. Process Root Files -> Venue = 'Mesto'
        if root_files:
             dfs, d_stats = process_items(root_files, 'Mesto')
             all_dfs.extend(dfs)
             merge_stats(d_stats)

        # 3. Recursive Process Subfolders
        def get_files_recursive(path):
            all_files_in_path = []
            try:
                itms = list_items(path, limit=1000)

                # Files in this dir
                files = [i for i in itms if i['type'] == 'file' and (i['name'].endswith('.xlsx') or i['name'].endswith('.csv'))]
                all_files_in_path.extend(files)

                # Subdirs to recurse
                dirs = [i for i in itms if i['type'] == 'dir']
                for d in dirs:
                    all_files_in_path.extend(get_files_recursive(d['path']))
            except Exception as e:
                st.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ–±—Ö–æ–¥–∞ –ø–∞–ø–∫–∏ {path}: {e}")
            return all_files_in_path

        for folder in folders:
            venue_name = folder['name']
            # Get all files recursively
            venue_files = get_files_recursive(folder['path'])
            
            if venue_files:
                dfs, d_stats = process_items(venue_files, venue_name)
                all_dfs.extend(dfs)
                merge_stats(d_stats)
        
        return all_dfs, master_dropped
    except Exception as e:
        st.error(f"Error loading from Yandex: {e}")
        return [], {'count': 0, 'cost': 0.0, 'items': []}

def load_from_local_folder(root_path):
    all_dfs = []
    
    # helper to process a list of files
    def process_local_files(files, venue_tag):
        processed = []
        dropped_total = {'count': 0, 'cost': 0.0, 'items': []}
        
        for file_path in files:
            try:
                # Read file content
                with open(file_path, 'rb') as f:
                    content = BytesIO(f.read())
                
                filename = os.path.basename(file_path)
                df, error, warnings, dropped = data_engine.process_single_file(content, filename=filename)
                
                # Accumulate
                if dropped:
                    dropped_total['count'] += dropped['count']
                    dropped_total['cost'] += dropped['cost']
                    dropped_total['items'].extend(dropped['items'])

                if error:
                    st.warning(f"{filename}: {error}")
                for warn in warnings:
                    st.info(f"{filename}: {warn}")
                if df is not None:
                    df['Venue'] = venue_tag
                    processed.append(df)
            except Exception as e:
                st.warning(f"Error reading {file_path}: {e}")
        
        return processed, dropped_total

    try:
        if not os.path.exists(root_path):
            st.error(f"–ü–∞–ø–∫–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {root_path}")
            return [], {'count': 0, 'cost': 0.0, 'items': []}

        dropped_total = {'count': 0, 'cost': 0.0, 'items': []}

        # 1. Walk through directory
        for root, dirs, files in os.walk(root_path):
            # Determine Venue from folder name relative to root_path
            rel_path = os.path.relpath(root, root_path)
            
            if rel_path == ".":
                venue_name = "Mesto" # Default for root
            else:
                # Use the first level folder as Venue Name
                # e.g. root/barmesto/2026 -> venue = barmesto
                parts = rel_path.split(os.sep)
                venue_name = parts[0]
            
            # Filter for Excel/CSV
            target_files = [os.path.join(root, f) for f in files if f.endswith(('.xlsx', '.csv')) and not f.startswith('~$')]
            
            if target_files:
                st.write(f"üìÇ Scanning {venue_name} ({len(target_files)} files)...")
                dfs, dropped_sub = process_local_files(target_files, venue_name)
                all_dfs.extend(dfs)
                # Accumulate
                dropped_total['count'] += dropped_sub['count']
                dropped_total['cost'] += dropped_sub['cost']
                dropped_total['items'].extend(dropped_sub['items'])

        return all_dfs, dropped_total
    except Exception as e:
        st.error(f"Error loading local files: {e}")
        return [], {'count': 0, 'cost': 0.0, 'items': []}

# --- AUTO-LOAD CACHE ON STARTUP ---
CACHE_FILE = "data_cache.parquet"
if st.session_state.df_full is None and os.path.exists(CACHE_FILE):
    try:
        st.session_state.df_full = pd.read_parquet(CACHE_FILE)
        # Optional: st.toast("–î–∞–Ω–Ω—ã–µ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã –∏–∑ –∫–µ—à–∞", icon="üíæ")
    except Exception:
        pass # Fail silently, user can load manually

# --- 1. SIDEBAR: DATA LOADING ---
# --- 1. SIDEBAR: DATA LOADING ---
with st.sidebar:
    st.title("üéõ –ú–µ–Ω—é")
    
    # --- DATA SOURCE (EXPANDER) ---
    with st.expander("üìÇ –ò—Å—Ç–æ—á–Ω–∏–∫ –¥–∞–Ω–Ω—ã—Ö", expanded=False):
        source_mode = st.radio("–†–µ–∂–∏–º:", ["–Ø–Ω–¥–µ–∫—Å.–î–∏—Å–∫", "–õ–æ–∫–∞–ª—å–Ω–∞—è –ø–∞–ø–∫–∞", "–†—É—á–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞"], label_visibility="collapsed")

        # --- YANDEX DISK ---
        if source_mode == "–Ø–Ω–¥–µ–∫—Å.–î–∏—Å–∫":
            yandex_path = st.text_input("–ü–∞–ø–∫–∞ –Ω–∞ –î–∏—Å–∫–µ:", "RestoAnalytic")
            if st.button("üöÄ –°–∫–∞—á–∞—Ç—å –æ—Ç—á–µ—Ç—ã", type="primary", use_container_width=True):
                if not get_secret("YANDEX_TOKEN"):
                     st.error("‚ö†Ô∏è –ù–µ—Ç —Ç–æ–∫–µ–Ω–∞!")
                else:
                    temp_data, dropped_load = load_all_from_yandex(yandex_path)
                    if temp_data:
                        st.session_state.df_full = pd.concat(temp_data, ignore_index=True).sort_values(by='–î–∞—Ç–∞_–û—Ç—á–µ—Ç–∞')
                        
                        # Update Stats
                        if dropped_load:
                            st.session_state.dropped_stats = dropped_load
                            
                        st.success(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(temp_data)} –æ—Ç—á–µ—Ç–æ–≤!")
                        st.rerun()
                    else:
                        st.warning("–§–∞–π–ª–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ.")

        # --- LOCAL FOLDER ---
        elif source_mode == "–õ–æ–∫–∞–ª—å–Ω–∞—è –ø–∞–ø–∫–∞":
            local_path = st.text_input("–ü—É—Ç—å –∫ –ø–∞–ø–∫–µ:", ".")
            if st.button(" –°–∫–∞–Ω–∏—Ä–æ–≤–∞—Ç—å –ø–∞–ø–∫—É", type="primary", use_container_width=True):
                temp_data, dropped_load = load_from_local_folder(local_path)
                if temp_data:
                    st.session_state.df_full = pd.concat(temp_data, ignore_index=True).sort_values(by='–î–∞—Ç–∞_–û—Ç—á–µ—Ç–∞')
                    
                    # Update Stats
                    if dropped_load:
                        st.session_state.dropped_stats = dropped_load
                        
                    st.success(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(temp_data)} –æ—Ç—á–µ—Ç–æ–≤!")
                    st.rerun()
                else:
                    st.warning("–§–∞–π–ª–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ.")

        # --- MANUAL UPLOAD ---
        elif source_mode == "–†—É—á–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞":
            uploaded_files = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç—å (CSV/Excel)", accept_multiple_files=True)
            if uploaded_files and st.button("üì• –û–±—Ä–∞–±–æ—Ç–∞—Ç—å —Ñ–∞–π–ª—ã", type="primary", use_container_width=True):
                temp_data = []
                st.session_state.dropped_stats = {'count': 0, 'cost': 0.0, 'items': []}
                
                for f in uploaded_files:
                    df_res = data_engine.process_single_file(f, f.name)
                    # Unwrap 4 args
                    if isinstance(df_res, tuple) and len(df_res) == 4:
                        df, error, warnings, dropped = df_res
                    else:
                        df, error, warnings, dropped = None, "Unknown error", [], None
                    
                    # Accumulate dropped
                    if dropped:
                        st.session_state.dropped_stats['count'] += dropped['count']
                        st.session_state.dropped_stats['cost'] += dropped['cost']
                        st.session_state.dropped_stats['items'].extend(dropped['items'])

                    if error: st.warning(error)
                    for w in warnings: st.warning(w)
                    if df is not None: temp_data.append(df)
                
                if temp_data:
                    st.session_state.df_full = pd.concat(temp_data, ignore_index=True).sort_values(by='–î–∞—Ç–∞_–û—Ç—á–µ—Ç–∞')
                    st.success("–§–∞–π–ª—ã –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã!")
                    st.rerun()

    # --- ADVANCED OPTIONS (Cache, Reset) ---
    with st.expander("‚öôÔ∏è –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –æ–ø—Ü–∏–∏"):
        CACHE_FILE = "data_cache.parquet"
        
        col1, col2 = st.columns(2)
        with col1:
            if st.button("üíæ –ö–µ—à", use_container_width=True):
                if st.session_state.df_full is not None:
                    st.session_state.df_full.to_parquet(CACHE_FILE, index=False)
                    st.success("–û–ö!")
                else:
                    st.warning("–ü—É—Å—Ç–æ")
        with col2:
            if st.button("üöÄ Load", use_container_width=True):
                if os.path.exists(CACHE_FILE):
                     st.session_state.df_full = pd.read_parquet(CACHE_FILE)
                     st.success("–û–ö!")
                     st.rerun()
                else:
                     st.warning("–ù–µ—Ç")
        
        if st.button("üóë –°–±—Ä–æ—Å", use_container_width=True):
            st.cache_data.clear()
            st.session_state.df_full = None
            st.session_state.dropped_stats = {'count': 0, 'cost': 0.0, 'items': []}
            st.rerun()
            
    # --- DEBUG INFO IN SIDEBAR ---
    with st.expander("üêû Debug: –û—Ç–±—Ä–æ—à–µ–Ω–Ω—ã–µ", expanded=False):
        if st.session_state.dropped_stats and st.session_state.dropped_stats['count'] > 0:
            st.write(f"**–ö–æ–ª-–≤–æ:** {st.session_state.dropped_stats['count']}")
            st.write(f"**C—É–º–º–∞:** {st.session_state.dropped_stats['cost']:,.0f} ‚ÇΩ")
            
            # Show top items
            items_df = pd.DataFrame(st.session_state.dropped_stats['items'])
            if not items_df.empty:
                items_df = items_df.sort_values(by='–°–µ–±–µ—Å—Ç–æ–∏–º–æ—Å—Ç—å', ascending=False).head(20)
                st.dataframe(items_df, hide_index=True)


# --- CUSTOM CATEGORY LOGIC (GLOBAL) ---
MAPPING_FILE = "category_mapping.json"

def load_custom_categories():
    if os.path.exists(MAPPING_FILE):
        try:
            with open(MAPPING_FILE, 'r', encoding='utf-8') as f:
                return json.load(f)
        except: return {}
    return {}

def save_custom_categories(new_map):
    current_map = load_custom_categories()
    current_map.update(new_map)
    with open(MAPPING_FILE, 'w', encoding='utf-8') as f:
        json.dump(current_map, f, ensure_ascii=False, indent=4)

# Load and Apply Custom Categories globally to df_full
if st.session_state.df_full is not None:
    custom_cats = load_custom_categories()
    if custom_cats:
        st.session_state.df_full['–ö–∞—Ç–µ–≥–æ—Ä–∏—è'] = st.session_state.df_full.apply(
            lambda x: custom_cats.get(x['–ë–ª—é–¥–æ'], x['–ö–∞—Ç–µ–≥–æ—Ä–∏—è']), axis=1
        )
        
        # --- GLOBAL FILTER: DELETE IGNORED ITEMS ---
        # Remove rows where category is "‚õî –ò—Å–∫–ª—é—á–∏—Ç—å –∏–∑ –æ—Ç—á–µ—Ç–æ–≤"
        st.session_state.df_full = st.session_state.df_full[st.session_state.df_full['–ö–∞—Ç–µ–≥–æ—Ä–∏—è'] != "‚õî –ò—Å–∫–ª—é—á–∏—Ç—å –∏–∑ –æ—Ç—á–µ—Ç–æ–≤"]

# --- –û–°–ù–û–í–ù–ê–Ø –õ–û–ì–ò–ö–ê ---
tg_token = get_secret("TELEGRAM_TOKEN")
tg_chat = get_secret("TELEGRAM_CHAT_ID")

if st.session_state.df_full is not None:

    # --- SIDEBAR: FILTERS (EXPANDER) ---
    with st.sidebar.expander("ÔøΩ –§–∏–ª—å—Ç—Ä—ã –ø–µ—Ä–∏–æ–¥–∞", expanded=False):

        # 1. VENUE SELECTOR
        selected_venue = "–í—Å–µ –∑–∞–≤–µ–¥–µ–Ω–∏—è"
        if 'Venue' in st.session_state.df_full.columns:
            unique_venues = sorted(st.session_state.df_full['Venue'].astype(str).unique())
            if len(unique_venues) > 1 or (len(unique_venues) == 1 and unique_venues[0] != 'nan'):
                 selected_venue = st.selectbox("üè† –ó–∞–≤–µ–¥–µ–Ω–∏–µ:", ["–í—Å–µ –∑–∞–≤–µ–¥–µ–Ω–∏—è"] + unique_venues)

        # –õ–ï–ß–ï–ù–ò–ï –î–ê–ù–ù–´–• –í –ü–ê–ú–Ø–¢–ò (–ï—Å–ª–∏ –≤–¥—Ä—É–≥ –Ω–µ—Ç –∫–æ–ª–æ–Ω–∫–∏)
        if '–ü–æ—Å—Ç–∞–≤—â–∏–∫' not in st.session_state.df_full.columns:
            st.session_state.df_full['–ü–æ—Å—Ç–∞–≤—â–∏–∫'] = '–ù–µ —É–∫–∞–∑–∞–Ω'

        # –§–ò–õ–¨–¢–†–ê–¶–ò–Ø
        if selected_venue != "–í—Å–µ –∑–∞–≤–µ–¥–µ–Ω–∏—è":
            df_full = st.session_state.df_full[st.session_state.df_full['Venue'] == selected_venue].copy()
        else:
            df_full = st.session_state.df_full.copy()
        
        # MACRO
        df_full['–ú–∞–∫—Ä–æ_–ö–∞—Ç–µ–≥–æ—Ä–∏—è'] = df_full['–ö–∞—Ç–µ–≥–æ—Ä–∏—è'].apply(data_engine.get_macro_category)

        dates_list = sorted(df_full['–î–∞—Ç–∞_–û—Ç—á–µ—Ç–∞'].unique(), reverse=True)

        # 2. PERIOD SELECTOR
        # –í—ã–±–æ—Ä —Ä–µ–∂–∏–º–∞: –ú–µ—Å—è—Ü (–¥–ª—è KPI/MoM) –∏–ª–∏ –ü—Ä–æ–∏–∑–≤–æ–ª—å–Ω—ã–π (–¥–ª—è –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞)
        period_mode = st.radio("–†–µ–∂–∏–º:", ["üìÖ –ú–µ—Å—è—Ü (–°—Ä–∞–≤–Ω–µ–Ω–∏–µ)", "üìÜ –ò–Ω—Ç–µ—Ä–≤–∞–ª –¥–∞—Ç"], label_visibility="collapsed", horizontal=True)
        
        df_current = pd.DataFrame()
        df_prev = pd.DataFrame()
        prev_label = ""
        target_date = datetime.now()
        
        if period_mode == "üìÖ –ú–µ—Å—è—Ü (–°—Ä–∞–≤–Ω–µ–Ω–∏–µ)":
            df_full['Month_Year'] = df_full['–î–∞—Ç–∞_–û—Ç—á–µ—Ç–∞'].dt.to_period('M')
            available_months = sorted(df_full['Month_Year'].unique(), reverse=True)
            
            if available_months:
                selected_month = st.selectbox("–í—ã–±–µ—Ä–∏ –º–µ—Å—è—Ü:", available_months, format_func=lambda x: x.strftime('%B %Y'))
                compare_options = ["–ü—Ä–µ–¥—ã–¥—É—â–∏–π –º–µ—Å—è—Ü", "–¢–æ—Ç –∂–µ –º–µ—Å—è—Ü (–≥–æ–¥ –Ω–∞–∑–∞–¥)", "–ù–µ—Ç"]
                compare_mode = st.selectbox("–°—Ä–∞–≤–Ω–∏—Ç—å —Å:", compare_options)
                
                # –¢–µ–∫—É—â–∏–π
                df_current = df_full[df_full['Month_Year'] == selected_month]
                target_date = df_current['–î–∞—Ç–∞_–û—Ç—á–µ—Ç–∞'].max()
                
                # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ
                if compare_mode == "–ü—Ä–µ–¥—ã–¥—É—â–∏–π –º–µ—Å—è—Ü":
                    prev_month = selected_month - 1
                    df_prev = df_full[df_full['Month_Year'] == prev_month]
                    prev_label = prev_month.strftime('%B %Y')
                elif compare_mode == "–¢–æ—Ç –∂–µ –º–µ—Å—è—Ü (–≥–æ–¥ –Ω–∞–∑–∞–¥)":
                    prev_month = selected_month - 12
                    df_prev = df_full[df_full['Month_Year'] == prev_month]
                    prev_label = prev_month.strftime('%B %Y')
        else:
            # –†–µ–∂–∏–º –ò–ù–¢–ï–†–í–ê–õ
            min_date = df_full['–î–∞—Ç–∞_–û—Ç—á–µ—Ç–∞'].min().date()
            max_date = df_full['–î–∞—Ç–∞_–û—Ç—á–µ—Ç–∞'].max().date()
            date_range = st.date_input("–í—ã–±–µ—Ä–∏—Ç–µ –¥–∞—Ç—ã:", value=(min_date, max_date), min_value=min_date, max_value=max_date)
            
            if isinstance(date_range, tuple) and len(date_range) == 2:
                start_d, end_d = date_range
                df_current = df_full[(df_full['–î–∞—Ç–∞_–û—Ç—á–µ—Ç–∞'].dt.date >= start_d) & (df_full['–î–∞—Ç–∞_–û—Ç—á–µ—Ç–∞'].dt.date <= end_d)]
                target_date = end_d
                
                # --- COMPARISON LOGIC ---
                compare_options = ["–ù–µ—Ç", "–ü—Ä–µ–¥—ã–¥—É—â–∏–π –ø–µ—Ä–∏–æ–¥", "–¢–æ—Ç –∂–µ –ø–µ—Ä–∏–æ–¥ (–≥–æ–¥ –Ω–∞–∑–∞–¥)"]
                compare_mode = st.selectbox("–°—Ä–∞–≤–Ω–∏—Ç—å —Å:", compare_options)
                
                if compare_mode == "–ü—Ä–µ–¥—ã–¥—É—â–∏–π –ø–µ—Ä–∏–æ–¥":
                    delta = end_d - start_d
                    prev_end = start_d - timedelta(days=1)
                    prev_start = prev_end - delta
                    prev_label = f"{prev_start.strftime('%d.%m')} - {prev_end.strftime('%d.%m')}"
                    
                    df_prev = df_full[(df_full['–î–∞—Ç–∞_–û—Ç—á–µ—Ç–∞'].dt.date >= prev_start) & (df_full['–î–∞—Ç–∞_–û—Ç—á–µ—Ç–∞'].dt.date <= prev_end)]
                    
                elif compare_mode == "–¢–æ—Ç –∂–µ –ø–µ—Ä–∏–æ–¥ (–≥–æ–¥ –Ω–∞–∑–∞–¥)":
                    # Simple Shift - 1 Year
                    def safe_year_sub(d):
                        try: return d.replace(year=d.year - 1)
                        except ValueError: return d.replace(year=d.year - 1, day=28)
                    
                    prev_start = safe_year_sub(start_d)
                    prev_end = safe_year_sub(end_d)
                    prev_label = f"{prev_start.strftime('%d.%m.%y')} - {prev_end.strftime('%d.%m.%y')}"
                    
                    df_prev = df_full[(df_full['–î–∞—Ç–∞_–û—Ç—á–µ—Ç–∞'].dt.date >= prev_start) & (df_full['–î–∞—Ç–∞_–û—Ç—á–µ—Ç–∞'].dt.date <= prev_end)]
                else:
                    prev_label = "–ë–µ–∑ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è"
                    df_prev = pd.DataFrame()
    
            else:
                st.warning("–í—ã–±–µ—Ä–∏—Ç–µ –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π –∏–Ω—Ç–µ—Ä–≤–∞–ª")

    # --- SIDEBAR: ACTIONS & EXPORT (EXPANDER) ---
    with st.sidebar.expander("‚ö° –î–µ–π—Å—Ç–≤–∏—è –∏ –≠–∫—Å–ø–æ—Ä—Ç", expanded=False):
        
        if st.button("üì§ –û—Ç—á–µ—Ç –≤ Telegram", use_container_width=True):
            if not tg_token or not tg_chat:
                st.error("‚ùå –ù–µ—Ç —Ç–æ–∫–µ–Ω–∞/—á–∞—Ç–∞!")
            elif st.session_state.df_full is None:
                st.warning("‚ö†Ô∏è –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö.")
            else:
                with st.spinner("–§–æ—Ä–º–∏—Ä—É—é –æ—Ç—á–µ—Ç..."):
                    report_text = telegram_utils.format_report(st.session_state.df_full, target_date)
                    success, msg = telegram_utils.send_to_all(tg_token, tg_chat, report_text)
                    if success: st.success("–û—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ!")
                    else: st.error(msg)
        
        st.divider()
        
        if not df_current.empty:
            # --- EXPORT SETTINGS ---
            sort_opt = st.radio(
                "–°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞:",
                ["üí∞ –ü–æ –í—ã—Ä—É—á–∫–µ", "üìâ –ü–æ –§—É–¥-–∫–æ—Å—Ç—É", "üì¶ –ü–æ –ö–æ–ª–∏—á–µ—Å—Ç–≤—É"],
                index=0
            )
            
            # Function to convert DF to Excel with fallback AND CHARTS
            @st.cache_data
            def convert_df(df, sort_mode):
                output = BytesIO()
                try:
                    # 1. Prepare Data
                    exp_df = df.copy()
                    
                    # Normalize 'Cost' column name (handle '–§—É–¥–∫–æ—Å—Ç' if present)
                    if '–§—É–¥–∫–æ—Å—Ç' in exp_df.columns and '–ö–æ—Å—Ç %' not in exp_df.columns:
                        exp_df['–ö–æ—Å—Ç %'] = exp_df['–§—É–¥–∫–æ—Å—Ç']
                    
                    # Calculate Cost % if still missing
                    if '–ö–æ—Å—Ç %' not in exp_df.columns:
                         exp_df['–ö–æ—Å—Ç %'] = (exp_df['–°–µ–±–µ—Å—Ç–æ–∏–º–æ—Å—Ç—å'] / exp_df['–í—ã—Ä—É—á–∫–∞ —Å –ù–î–°'] * 100).fillna(0)
                    
                    # 2. Sort
                    if "–í—ã—Ä—É—á–∫–µ" in sort_mode:
                        exp_df = exp_df.sort_values(by='–í—ã—Ä—É—á–∫–∞ —Å –ù–î–°', ascending=False)
                        sort_col = '–í—ã—Ä—É—á–∫–∞'
                    elif "–§—É–¥-–∫–æ—Å—Ç—É" in sort_mode:
                        exp_df = exp_df.sort_values(by='–ö–æ—Å—Ç %', ascending=False)
                        sort_col = '–ö–æ—Å—Ç %'
                    elif "–ö–æ–ª–∏—á–µ—Å—Ç–≤—É" in sort_mode:
                        exp_df = exp_df.sort_values(by='–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ', ascending=False)
                        sort_col = '–ö–æ–ª-–≤–æ'
                    else:
                        sort_col = '–í—ã—Ä—É—á–∫–∞'
                    
                    # 3. Filter & Rename Columns
                    cols_map = {
                        '–ë–ª—é–¥–æ': '–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ', 
                        '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ': '–ö–æ–ª-–≤–æ', 
                        '–°–µ–±–µ—Å—Ç–æ–∏–º–æ—Å—Ç—å': '–°–µ–±–µ—Å—Ç.', 
                        '–í—ã—Ä—É—á–∫–∞ —Å –ù–î–°': '–í—ã—Ä—É—á–∫–∞', 
                        '–ö–æ—Å—Ç %': '–ö–æ—Å—Ç %', 
                        '–ö–∞—Ç–µ–≥–æ—Ä–∏—è': '–ö–∞—Ç–µ–≥–æ—Ä–∏—è'
                    }
                    
                    # Select only existing columns from the map
                    available_cols = [c for c in cols_map.keys() if c in exp_df.columns]
                    final_df = exp_df[available_cols].rename(columns=cols_map)
                    
                    # 4. Write to Excel using XlsxWriter
                    try:
                        with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
                            final_df.to_excel(writer, index=False, sheet_name='Report')
                            workbook  = writer.book
                            worksheet = writer.sheets['Report']

                            # --- FORMATTING ---
                            # Formats
                            fmt_header = workbook.add_format({'bold': True, 'bg_color': '#D3D3D3', 'border': 1, 'align': 'center', 'valign': 'vcenter'})
                            fmt_money = workbook.add_format({'num_format': '#,##0 ‚ÇΩ'})
                            fmt_pct = workbook.add_format({'num_format': '0.0%"'}) # Quote to avoid excel issues
                            fmt_int = workbook.add_format({'num_format': '0'})

                            # Apply Header Format
                            for col_num, value in enumerate(final_df.columns.values):
                                worksheet.write(0, col_num, value, fmt_header)
                                
                            # Apply Column Widths & Formats
                            for i, col in enumerate(final_df.columns):
                                width = 15
                                fmt = None
                                if col in ['–í—ã—Ä—É—á–∫–∞', '–°–µ–±–µ—Å—Ç.']:
                                    width = 18
                                    fmt = fmt_money
                                elif col == '–ö–æ—Å—Ç %':
                                    width = 12
                                    fmt = fmt_pct
                                elif col == '–ö–æ–ª-–≤–æ':
                                    width = 10
                                    fmt = fmt_int
                                elif col == '–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ':
                                    width = 40
                                
                                worksheet.set_column(i, i, width, fmt)

                            # --- CHARTS ---
                            charts_sheet = workbook.add_worksheet('Charts')
                            
                            # 1. COLUMN CHART (Top 10 Items)
                            chart_col = workbook.add_chart({'type': 'column'})
                            max_row = min(10, len(final_df))
                            try:
                                val_idx = final_df.columns.get_loc(sort_col)
                                chart_col.add_series({
                                    'name':       [ 'Report', 0, val_idx],
                                    'categories': [ 'Report', 1, 0, max_row, 0], # Top 10 names
                                    'values':     [ 'Report', 1, val_idx, max_row, val_idx], # Top 10 values
                                    'data_labels': {'value': True},
                                    'gap':        30,
                                })
                                chart_col.set_title ({'name': f'–¢–æ–ø-10: {sort_col}'})
                                chart_col.set_x_axis({'name': '–ü–æ–∑–∏—Ü–∏—è', 'major_gridlines': {'visible': False}})
                                chart_col.set_y_axis({'name': sort_col, 'major_gridlines': {'visible': True, 'line': {'style': 'dash'}}})
                                chart_col.set_legend({'position': 'none'})
                                chart_col.set_style(11)
                                charts_sheet.insert_chart('B2', chart_col, {'x_scale': 2.5, 'y_scale': 2})
                            except:
                                pass

                            # 2. PIE CHART (Category Distribution - Micro)
                            # We need to aggregate data for the pie chart
                            if '–ö–∞—Ç–µ–≥–æ—Ä–∏—è' in final_df.columns:
                                try:
                                    # Group by Category and Sum Sort Column (e.g. Revenue)
                                    cat_df = final_df.groupby('–ö–∞—Ç–µ–≥–æ—Ä–∏—è')[sort_col].sum().reset_index().sort_values(by=sort_col, ascending=False)
                                    
                                    # Write summarized data to Charts sheet (hidden/side)
                                    # Start writing at row 20 (below chart) or side
                                    # Let's write it to columns O and P on Charts sheet
                                    charts_sheet.write(0, 14, '–ö–∞—Ç–µ–≥–æ—Ä–∏—è', fmt_header)
                                    charts_sheet.write(0, 15, sort_col, fmt_header)
                                    
                                    for r_idx, row in cat_df.iterrows():
                                        charts_sheet.write(r_idx + 1, 14, row['–ö–∞—Ç–µ–≥–æ—Ä–∏—è'])
                                        charts_sheet.write(r_idx + 1, 15, row[sort_col], fmt_money)
                                        
                                    # Create Pie Chart
                                    chart_pie = workbook.add_chart({'type': 'pie'})
                                    cat_len = len(cat_df)
                                    
                                    chart_pie.add_series({
                                        'name':       f'–î–æ–ª–∏ (–ú–∏–∫—Ä–æ-–ö–∞—Ç–µ–≥–æ—Ä–∏–∏)',
                                        'categories': [ 'Charts', 1, 14, cat_len, 14],
                                        'values':     [ 'Charts', 1, 15, cat_len, 15],
                                        'data_labels': {'percentage': True},
                                    })
                                    
                                    chart_pie.set_title({'name': f'–î–æ–ª–∏ (–ú–∏–∫—Ä–æ): {sort_col}'})
                                    chart_pie.set_style(10)
                                    
                                    # Insert Pie Chart next to Column Chart
                                    charts_sheet.insert_chart('J2', chart_pie, {'x_scale': 1.5, 'y_scale': 1.5})
                                except Exception as e_pie:
                                    pass

                            # 3. DONUT CHART (Macro-Category Distribution)
                            if '–ú–∞–∫—Ä–æ_–ö–∞—Ç–µ–≥–æ—Ä–∏—è' in exp_df.columns: # Check original DF for Macro
                                try:
                                    # Aggregate
                                    macro_df = exp_df.groupby('–ú–∞–∫—Ä–æ_–ö–∞—Ç–µ–≥–æ—Ä–∏—è')[sort_col].sum().reset_index().sort_values(by=sort_col, ascending=False)
                                    
                                    # Write Data
                                    charts_sheet.write(0, 17, '–ú–∞–∫—Ä–æ-–ì—Ä—É–ø–ø–∞', fmt_header) # Col R
                                    charts_sheet.write(0, 18, sort_col, fmt_header)       # Col S
                                    
                                    for r_idx, row in macro_df.iterrows():
                                        charts_sheet.write(r_idx + 1, 17, row['–ú–∞–∫—Ä–æ_–ö–∞—Ç–µ–≥–æ—Ä–∏—è'])
                                        charts_sheet.write(r_idx + 1, 18, row[sort_col], fmt_money)
                                        
                                    # Create Donut Chart
                                    chart_donut = workbook.add_chart({'type': 'doughnut'})
                                    macro_len = len(macro_df)
                                    
                                    chart_donut.add_series({
                                        'name':       f'–°—Ç—Ä—É–∫—Ç—É—Ä–∞ (–ú–∞–∫—Ä–æ)',
                                        'categories': [ 'Charts', 1, 17, macro_len, 17],
                                        'values':     [ 'Charts', 1, 18, macro_len, 18],
                                        'data_labels': {'percentage': True},
                                    })
                                    
                                    chart_donut.set_title({'name': f'–°—Ç—Ä—É–∫—Ç—É—Ä–∞ –í—ã—Ä—É—á–∫–∏ (–ú–∞–∫—Ä–æ)'})
                                    chart_donut.set_style(10)
                                    chart_donut.set_rotation(90)
                                    
                                    # Insert Donut Chart below Column Chart
                                    charts_sheet.insert_chart('B18', chart_donut, {'x_scale': 1.5, 'y_scale': 1.5})

                                except Exception as e_donut:
                                    pass # Fail silently


                    except Exception as e_xlsx:
                        # FALLBACK if xlsxwriter fails (module missing? engine error?)
                        # Use openpyxl but export FINAL_DF (filtered/sorted)
                        with pd.ExcelWriter(output, engine='openpyxl') as writer:
                             final_df.to_excel(writer, index=False, sheet_name='Report')

                except Exception as e:
                    # General error (conversion failed)
                    st.sidebar.error(f"–û—à–∏–±–∫–∞ —ç–∫—Å–ø–æ—Ä—Ç–∞: {e}")
                    return None
                return output.getvalue()

            excel_data = convert_df(df_current, sort_opt)
            
            if excel_data:
                st.sidebar.download_button(
                    label="üìä –°–∫–∞—á–∞—Ç—å Excel (+–ì—Ä–∞—Ñ–∏–∫–∏)",
                    data=excel_data,
                    file_name=f"report_{target_date.strftime('%Y-%m-%d')}.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                    use_container_width=True
                )
        else:
            st.info("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞.")

    # --- KPI DISPLAY ---
    if not df_current.empty:
        # –†–∞—Å—á–µ—Ç KPI
        def calc_kpis(df):
            if df.empty: return 0, 0, 0, 0
            rev = df['–í—ã—Ä—É—á–∫–∞ —Å –ù–î–°'].sum()
            cost = df['–°–µ–±–µ—Å—Ç–æ–∏–º–æ—Å—Ç—å'].sum()
            margin = rev - cost
            fc = (cost / rev * 100) if rev > 0 else 0
            return rev, cost, margin, fc

        cur_rev, cur_cost, cur_margin, cur_fc = calc_kpis(df_current)
        prev_rev, prev_cost, prev_margin, prev_fc = calc_kpis(df_prev)
        
        # –î–µ–ª—å—Ç—ã
        delta_rev = cur_rev - prev_rev if not df_prev.empty else 0
        delta_margin = cur_margin - prev_margin if not df_prev.empty else 0
        delta_fc = cur_fc - prev_fc if not df_prev.empty else 0
        
        sub_title = "–ü—Ä–æ–∏–∑–≤–æ–ª—å–Ω—ã–π –ø–µ—Ä–∏–æ–¥" if period_mode == "üìÜ –ò–Ω—Ç–µ—Ä–≤–∞–ª –¥–∞—Ç" else f"{selected_month.strftime('%B %Y')} vs {prev_label if not df_prev.empty else '–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö'}"
        
        # --- SMART INSIGHTS ---
        generate_insights(df_current, df_prev, cur_rev, prev_rev, cur_fc)
        
        st.write(f"### üìä –°–≤–æ–¥–∫–∞: {sub_title}")
        
        kpi1, kpi2, kpi3, kpi4 = st.columns(4)
        kpi1.metric("üí∞ –í—ã—Ä—É—á–∫–∞", f"{cur_rev:,.0f} ‚ÇΩ", f"{delta_rev:+,.0f} ‚ÇΩ" if not df_prev.empty else None)
        kpi2.metric("üìâ –§—É–¥-–∫–æ—Å—Ç", f"{cur_fc:.1f} %", f"{delta_fc:+.1f} %" if not df_prev.empty else None, delta_color="inverse")
        kpi3.metric("üí≥ –ú–∞—Ä–∂–∞", f"{cur_margin:,.0f} ‚ÇΩ", f"{delta_margin:+,.0f} ‚ÇΩ" if not df_prev.empty else None)
        kpi4.metric("üßæ –ü–æ–∑–∏—Ü–∏–π", len(df_current))

        # --- –ì–†–ê–§–ò–ö –î–ò–ù–ê–ú–ò–ö–ò –ü–û –î–ù–Ø–ú ---
        if period_mode == "üìÖ –ú–µ—Å—è—Ü (–°—Ä–∞–≤–Ω–µ–Ω–∏–µ)" and not df_current.empty:
            with st.expander("üìà –î–∏–Ω–∞–º–∏–∫–∞ –í—ã—Ä—É—á–∫–∏ (–î–µ–Ω—å –∑–∞ –¥–Ω—ë–º)", expanded=False):
                # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
                df_chart_cur = df_current.groupby(df_current['–î–∞—Ç–∞_–û—Ç—á–µ—Ç–∞'].dt.day)['–í—ã—Ä—É—á–∫–∞ —Å –ù–î–°'].sum().cumsum()
                
                chart_data = pd.DataFrame({'–¢–µ–∫—É—â–∏–π': df_chart_cur})
                
                if not df_prev.empty and compare_mode != "–ù–µ—Ç":
                    df_chart_prev = df_prev.groupby(df_prev['–î–∞—Ç–∞_–û—Ç—á–µ—Ç–∞'].dt.day)['–í—ã—Ä—É—á–∫–∞ —Å –ù–î–°'].sum().cumsum()
                    chart_data['–ü—Ä–æ—à–ª—ã–π'] = df_chart_prev
                
                st.line_chart(chart_data)

        df_view = df_current # –î–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å –æ—Å—Ç–∞–ª—å–Ω—ã–º –∫–æ–¥–æ–º
    else:
        st.warning("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö —Å –¥–∞—Ç–∞–º–∏.")
        df_view = df_full
        target_date = datetime.now()

    # --- –ù–ê–í–ò–ì–ê–¶–ò–Ø ---
    tab_options = ["üî• –ò–Ω—Ñ–ª—è—Ü–∏—è", "üìâ –î–∏–Ω–∞–º–∏–∫–∞ –∏ –ü–æ—Å—Ç–∞–≤—â–∏–∫–∏", "üç∞ –ú–µ–Ω—é –∏ –ö–æ—Å—Ç—ã", "‚≠ê –ú–∞—Ç—Ä–∏—Ü–∞ (ABC)", "üóì –î–Ω–∏ –Ω–µ–¥–µ–ª–∏", "üì¶ –ü–ª–∞–Ω –ó–∞–∫—É–ø–æ–∫", "üîÆ –°–∏–º—É–ª—è—Ç–æ—Ä"]
    
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º session_state –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤—ã–±–æ—Ä–∞ –≤–∫–ª–∞–¥–∫–∏, –µ—Å–ª–∏ –Ω—É–∂–Ω–æ, –Ω–æ st.radio –∏ —Ç–∞–∫ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç —Å–æ—Å—Ç–æ—è–Ω–∏–µ
    selected_tab = st.radio("–†–∞–∑–¥–µ–ª:", tab_options, horizontal=True, label_visibility="collapsed")
    st.sidebar.caption("v2.3 (Multi-Venue) üöÄ")
    st.write("---")

    # --- 1. –ò–ù–§–õ–Ø–¶–ò–Ø ---
    if selected_tab == "üî• –ò–Ω—Ñ–ª—è—Ü–∏—è":
        st.subheader(f"üî• –ò–Ω—Ñ–ª—è—Ü–∏–æ–Ω–Ω—ã–π –¢—Ä–µ–∫–µ—Ä (–ø–æ —Å–æ—Å—Ç–æ—è–Ω–∏—é –Ω–∞ {target_date.strftime('%d.%m.%Y')})")
        
        # Ensure target_date is datetime for comparison
        if isinstance(target_date, datetime):
             target_ts = target_date
        else:
             target_ts = pd.to_datetime(target_date)

        df_inflation_scope = df_full[df_full['–î–∞—Ç–∞_–û—Ç—á–µ—Ç–∞'] <= target_ts]
        price_history = df_inflation_scope.groupby(['–ë–ª—é–¥–æ', '–î–∞—Ç–∞_–û—Ç—á–µ—Ç–∞'])['Unit_Cost'].mean().reset_index()
        unique_items = price_history['–ë–ª—é–¥–æ'].unique()
        inflation_data = []
        total_gross_loss = 0
        total_gross_save = 0

        for item in unique_items:
            p_data = price_history[price_history['–ë–ª—é–¥–æ'] == item].sort_values('–î–∞—Ç–∞_–û—Ç—á–µ—Ç–∞')
            if len(p_data) > 1:
                first_price = p_data.iloc[0]['Unit_Cost']
                last_price = p_data.iloc[-1]['Unit_Cost']
                qty_sold = df_view[df_view['–ë–ª—é–¥–æ'] == item]['–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ'].sum()

                if first_price > 5 and qty_sold > 0: 
                    diff_abs = last_price - first_price
                    diff_pct = (diff_abs / first_price) * 100
                    financial_impact = diff_abs * qty_sold
                    if financial_impact > 0: total_gross_loss += financial_impact
                    else: total_gross_save += abs(financial_impact)
                    if abs(diff_pct) > 1:
                        inflation_data.append({'–¢–æ–≤–∞—Ä': item, '–°—Ç–∞—Ä–∞—è —Ü–µ–Ω–∞': first_price, '–ù–æ–≤–∞—è —Ü–µ–Ω–∞': last_price, '–†–æ—Å—Ç %': diff_pct, '–≠—Ñ—Ñ–µ–∫—Ç (‚ÇΩ)': financial_impact})
        
        net_result = total_gross_loss - total_gross_save
        inf1, inf2, inf3 = st.columns(3)
        inf1.metric("üî¥ –ü–æ—Ç–µ—Ä–∏ (–ò–Ω—Ñ–ª—è—Ü–∏—è)", f"-{total_gross_loss:,.0f} ‚ÇΩ")
        inf2.metric("üü¢ –≠–∫–æ–Ω–æ–º–∏—è (–°–∫–∏–¥–∫–∏)", f"+{total_gross_save:,.0f} ‚ÇΩ")
        inf3.metric("üèÅ –ß–∏—Å—Ç—ã–π –ò—Ç–æ–≥", f"-{net_result:,.0f} ‚ÇΩ" if net_result > 0 else f"+{abs(net_result):,.0f} ‚ÇΩ", delta_color="inverse")
        
        st.write("---")
        if inflation_data:
            df_inf = pd.DataFrame(inflation_data)
            col_up, col_down = st.columns(2)
            with col_up:
                st.write("### üî∫ –¢–æ–ø-30: –¶–µ–Ω–∞ –≤—ã—Ä–æ—Å–ª–∞ (–£–±—ã—Ç–æ–∫)")
                if not df_inf.empty:
                    df_up = df_inf.sort_values('–≠—Ñ—Ñ–µ–∫—Ç (‚ÇΩ)', ascending=False).head(30)
                    st.dataframe(
                        df_up[['–¢–æ–≤–∞—Ä', '–†–æ—Å—Ç %', '–≠—Ñ—Ñ–µ–∫—Ç (‚ÇΩ)']],
                        column_config={
                            "–†–æ—Å—Ç %": st.column_config.NumberColumn(format="+%.1f %%"),
                            "–≠—Ñ—Ñ–µ–∫—Ç (‚ÇΩ)": st.column_config.NumberColumn(format="%.0f ‚ÇΩ"),
                        },
                        use_container_width=True
                    )
            with col_down:
                st.write("### üîª –¢–æ–ø-30: –¶–µ–Ω–∞ —É–ø–∞–ª–∞ (–≠–∫–æ–Ω–æ–º–∏—è)")
                if not df_inf.empty:
                    df_down = df_inf.sort_values('–≠—Ñ—Ñ–µ–∫—Ç (‚ÇΩ)', ascending=True).head(30)
                    st.dataframe(
                        df_down[['–¢–æ–≤–∞—Ä', '–†–æ—Å—Ç %', '–≠—Ñ—Ñ–µ–∫—Ç (‚ÇΩ)']],
                        column_config={
                            "–†–æ—Å—Ç %": st.column_config.NumberColumn(format="%.1f %%"),
                            "–≠—Ñ—Ñ–µ–∫—Ç (‚ÇΩ)": st.column_config.NumberColumn(format="%.0f ‚ÇΩ"),
                        },
                        use_container_width=True
                    )
        else:
            st.success("–¶–µ–Ω—ã —Å—Ç–∞–±–∏–ª—å–Ω—ã.")

    # --- 2. –î–ò–ù–ê–ú–ò–ö–ê –ò –ü–û–°–¢–ê–í–©–ò–ö–ò ---
    elif selected_tab == "üìâ –î–∏–Ω–∞–º–∏–∫–∞ –∏ –ü–æ—Å—Ç–∞–≤—â–∏–∫–∏":
        st.subheader("üìâ –ò—Å—Ç–æ—Ä–∏—è —Ü–µ–Ω –∏ –†–µ–π—Ç–∏–Ω–≥ –ü–æ—Å—Ç–∞–≤—â–∏–∫–æ–≤")
        
        c_dyn1, c_dyn2 = st.columns([2, 1])
        
        with c_dyn1:
            st.write("### üîç –ö–∞–∫ –º–µ–Ω—è–ª–∞—Å—å —Ü–µ–Ω–∞ –∑–∞–∫—É–ø–∫–∏?")
            all_items = sorted(df_full['–ë–ª—é–¥–æ'].unique())
            selected_item = st.selectbox("–í—ã–±–µ—Ä–∏—Ç–µ —Ç–æ–≤–∞—Ä/–±–ª—é–¥–æ:", all_items)
            item_data = df_full[df_full['–ë–ª—é–¥–æ'] == selected_item].sort_values('–î–∞—Ç–∞_–û—Ç—á–µ—Ç–∞')
            
            if not item_data.empty:
                fig_trend = px.line(item_data, x='–î–∞—Ç–∞_–û—Ç—á–µ—Ç–∞', y='Unit_Cost', markers=True, 
                                    title=f"–î–∏–Ω–∞–º–∏–∫–∞ —Ü–µ–Ω—ã: {selected_item}",
                                    labels={'Unit_Cost': '–¶–µ–Ω–∞ –∑–∞–∫—É–ø–∫–∏ (‚ÇΩ)', '–î–∞—Ç–∞_–û—Ç—á–µ—Ç–∞': '–î–∞—Ç–∞'})
                st.plotly_chart(update_chart_layout(fig_trend), use_container_width=True)
                
                # –ë–ï–ó–û–ü–ê–°–ù–´–ô –í–´–í–û–î –¢–ê–ë–õ–ò–¶–´
                cols_to_show = ['–î–∞—Ç–∞_–û—Ç—á–µ—Ç–∞', 'Unit_Cost']
                if '–ü–æ—Å—Ç–∞–≤—â–∏–∫' in item_data.columns:
                    cols_to_show.append('–ü–æ—Å—Ç–∞–≤—â–∏–∫')
                
                st.dataframe(
                    item_data[cols_to_show],
                    column_config={
                        "Unit_Cost": st.column_config.NumberColumn(format="%.2f ‚ÇΩ"),
                        "–î–∞—Ç–∞_–û—Ç—á–µ—Ç–∞": st.column_config.DateColumn(format="DD.MM.YYYY"),
                    },
                    use_container_width=True
                )
            else:
                st.warning("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –ø–æ —ç—Ç–æ–º—É —Ç–æ–≤–∞—Ä—É.")

        with c_dyn2:
            st.write("### üèÜ –¢–æ–ø –ü–æ—Å—Ç–∞–≤—â–∏–∫–æ–≤")
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∫–æ–ª–æ–Ω–∫–∏ –ø–µ—Ä–µ–¥ –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–æ–π
            if '–ü–æ—Å—Ç–∞–≤—â–∏–∫' in df_view.columns:
                supplier_stats = df_view.groupby('–ü–æ—Å—Ç–∞–≤—â–∏–∫')['–°–µ–±–µ—Å—Ç–æ–∏–º–æ—Å—Ç—å'].sum().reset_index()
                supplier_stats = supplier_stats[supplier_stats['–ü–æ—Å—Ç–∞–≤—â–∏–∫'] != '–ù–µ —É–∫–∞–∑–∞–Ω'].sort_values('–°–µ–±–µ—Å—Ç–æ–∏–º–æ—Å—Ç—å', ascending=False).head(10)
                
                if not supplier_stats.empty:
                    fig_sup = px.bar(supplier_stats, x='–°–µ–±–µ—Å—Ç–æ–∏–º–æ—Å—Ç—å', y='–ü–æ—Å—Ç–∞–≤—â–∏–∫', orientation='h', text_auto='.0s', color='–°–µ–±–µ—Å—Ç–æ–∏–º–æ—Å—Ç—å')
                    st.plotly_chart(update_chart_layout(fig_sup), use_container_width=True)
                else:
                    st.info("–î–∞–Ω–Ω—ã–µ –ø–æ –ø–æ—Å—Ç–∞–≤—â–∏–∫–∞–º –Ω–µ –Ω–∞–π–¥–µ–Ω—ã.")
            else:
                st.info("–í –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–∞—Ö –Ω–µ—Ç –∫–æ–ª–æ–Ω–∫–∏ '–ü–æ—Å—Ç–∞–≤—â–∏–∫'.")

    # --- 3. –ú–ï–ù–Æ –ò –ö–û–°–¢–´ ---
    elif selected_tab == "üç∞ –ú–µ–Ω—é –∏ –ö–æ—Å—Ç—ã":
        view_mode = st.radio("–î–µ—Ç–∞–ª–∏–∑–∞—Ü–∏—è –∫–∞—Ç–µ–≥–æ—Ä–∏–π:", ["üîç –£–∫—Ä—É–ø–Ω–µ–Ω–Ω–æ (–ú–∞–∫—Ä–æ-–≥—Ä—É–ø–ø—ã)", "üî¨ –î–µ—Ç–∞–ª—å–Ω–æ (–ú–∏–∫—Ä–æ-–∫–∞—Ç–µ–≥–æ—Ä–∏–∏)"], horizontal=True)
        target_cat = '–ú–∞–∫—Ä–æ_–ö–∞—Ç–µ–≥–æ—Ä–∏—è' if '–ú–∞–∫—Ä–æ' in view_mode else '–ö–∞—Ç–µ–≥–æ—Ä–∏—è'

        c1, c2 = st.columns([1, 1])
        with c1:
            st.subheader("–°—Ç—Ä—É–∫—Ç—É—Ä–∞ –≤—ã—Ä—É—á–∫–∏")
            df_cat = df_view.groupby(target_cat)['–í—ã—Ä—É—á–∫–∞ —Å –ù–î–°'].sum().reset_index()
            fig_pie = px.pie(df_cat, values='–í—ã—Ä—É—á–∫–∞ —Å –ù–î–°', names=target_cat, hole=0.4)
            fig_pie.update_traces(hovertemplate='%{label}: %{value:,.0f} ‚ÇΩ (%{percent})')
            st.plotly_chart(update_chart_layout(fig_pie), use_container_width=True)
        
        with c2:
            st.subheader("üìä –î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –§—É–¥-–∫–æ—Å—Ç–∞")
            df_menu = df_view.groupby(['–ë–ª—é–¥–æ', target_cat]).agg({'–í—ã—Ä—É—á–∫–∞ —Å –ù–î–°': 'sum', '–°–µ–±–µ—Å—Ç–æ–∏–º–æ—Å—Ç—å': 'sum', '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ': 'sum'}).reset_index()
            df_menu['–§—É–¥–∫–æ—Å—Ç %'] = np.where(df_menu['–í—ã—Ä—É—á–∫–∞ —Å –ù–î–°']>0, df_menu['–°–µ–±–µ—Å—Ç–æ–∏–º–æ—Å—Ç—å']/df_menu['–í—ã—Ä—É—á–∫–∞ —Å –ù–î–°']*100, 0)
            df_menu = df_menu.sort_values('–í—ã—Ä—É—á–∫–∞ —Å –ù–î–°', ascending=False).head(50)
            df_menu = df_menu.rename(columns={target_cat: '–ö–∞—Ç–µ–≥–æ—Ä–∏—è'})
            
            # Highlight High FC > 26%
            def highlight_fc(s):
                return ['color: #FF4B4B; font-weight: bold' if v > 26 else '' for v in s]

            st.dataframe(
                df_menu.style.apply(highlight_fc, subset=['–§—É–¥–∫–æ—Å—Ç %'], axis=0).format(precision=1),
                column_config={
                    "–í—ã—Ä—É—á–∫–∞ —Å –ù–î–°": st.column_config.NumberColumn(format="%.0f ‚ÇΩ"),
                    "–§—É–¥–∫–æ—Å—Ç %": st.column_config.NumberColumn(format="%.1f %%"),
                },
                use_container_width=True,
                height=400
            )

        # --- VISUAL CATEGORY EDITOR (Relocated) ---
        st.write("---")
        st.subheader("üõ† –†–∞–∑–±–æ—Ä –Ω–µ—Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã—Ö –±–ª—é–¥ ('–ü—Ä–æ—á–µ–µ')")
        
        # Find items in "Other" based on current df_items (which is scoped by date/venue)
        # OR better: use global df_full to find ALL unmapped items to fix them once
        other_items_global = st.session_state.df_full[st.session_state.df_full['–ö–∞—Ç–µ–≥–æ—Ä–∏—è'] == 'üì¶ –ü—Ä–æ—á–µ–µ']['–ë–ª—é–¥–æ'].unique()
        
        if len(other_items_global) > 0:
            st.warning(f"–ù–∞–π–¥–µ–Ω–æ {len(other_items_global)} –±–ª—é–¥ –≤ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ '–ü—Ä–æ—á–µ–µ'. –î–∞–≤–∞–π—Ç–µ –∏—Ö —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–∏–º!")
            
            # 1. Prepare Categories List
            standard_cats = [
                "‚õî –ò—Å–∫–ª—é—á–∏—Ç—å –∏–∑ –æ—Ç—á–µ—Ç–æ–≤", # NEW: Special category to hide item
                "üçî –ï–¥–∞ (–ö—É—Ö–Ω—è)", "üçπ –ö–æ–∫—Ç–µ–π–ª–∏", "‚òï –ö–æ—Ñ–µ", "üçµ –ß–∞–π", "üç∫ –ü–∏–≤–æ –†–æ–∑–ª–∏–≤", "üíß –í–æ–¥–∫–∞",
                "üç∑ –í–∏–Ω–æ", "ü•§ –°—Ç–µ–∫–ª–æ/–ë–∞–Ω–∫–∞ –ë/–ê", "üö∞ –†–æ–∑–ª–∏–≤ –ë/–ê", "üçì –ú–∏–ª–∫/–§—Ä–µ—à/–°–º—É–∑–∏", 
                "üçè –°–∏–¥—Ä –®–¢", "üçæ –ü–∏–≤–æ –®–¢", "ü•É –í–∏—Å–∫–∏", "üíß –í–æ–¥–∫–∞", "üè¥‚Äç‚ò†Ô∏è –†–æ–º", 
                "üåµ –¢–µ–∫–∏–ª–∞", "üå≤ –î–∂–∏–Ω", "üçá –ö–æ–Ω—å—è–∫/–ë—Ä–µ–Ω–¥–∏", "üçí –õ–∏–∫–µ—Ä/–ù–∞—Å—Ç–æ–π–∫–∞", "üç¨ –î–æ–ø. –∏–Ω–≥—Ä–µ–¥–∏–µ–Ω—Ç—ã"
            ]
            existing_cats = [c for c in st.session_state.df_full['–ö–∞—Ç–µ–≥–æ—Ä–∏—è'].unique() if c != 'üì¶ –ü—Ä–æ—á–µ–µ']
            all_options = sorted(list(set(standard_cats + existing_cats)))

            # 2. Prepare Data for Editor
            df_to_edit = pd.DataFrame({'–ë–ª—é–¥–æ': other_items_global, '–ö–∞—Ç–µ–≥–æ—Ä–∏—è': 'üì¶ –ü—Ä–æ—á–µ–µ'})

            # 3. Render Editor
            edited_df = st.data_editor(
                df_to_edit,
                column_config={
                    "–ë–ª—é–¥–æ": st.column_config.TextColumn("–ë–ª—é–¥–æ", disabled=True),
                    "–ö–∞—Ç–µ–≥–æ—Ä–∏—è": st.column_config.SelectboxColumn(
                        "–í—ã–±–µ—Ä–∏—Ç–µ –∫–∞—Ç–µ–≥–æ—Ä–∏—é",
                        options=all_options,
                        required=True
                    )
                },
                hide_index=True,
                use_container_width=True,
                num_rows="fixed",
                key="editor_changes_tab"
            )

            # 4. Save Logic
            if st.button("üíæ –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –∏–∑–º–µ–Ω–µ–Ω–∏—è (–ú–µ–Ω—é)"):
                changed_rows = edited_df[edited_df['–ö–∞—Ç–µ–≥–æ—Ä–∏—è'] != 'üì¶ –ü—Ä–æ—á–µ–µ']
                if not changed_rows.empty:
                    new_map = dict(zip(changed_rows['–ë–ª—é–¥–æ'], changed_rows['–ö–∞—Ç–µ–≥–æ—Ä–∏—è']))
                    # Assuming save_custom_categories and load_custom_categories are defined elsewhere or need to be added
                    # For this specific instruction, I'll assume they are available or will be added by the user.
                    # If not, this part would cause an error.
                    # Placeholder for actual save/load logic if not defined:
                    # save_custom_categories(new_map) 
                    # st.session_state.custom_cats = load_custom_categories() 
                    save_custom_categories(new_map)
                    st.cache_data.clear()
                    st.success(f"‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ {len(new_map)} –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–π! –ü–µ—Ä–µ–∑–∞–≥—Ä—É–∂–∞—é...")
                    st.rerun()
                else:
                    st.warning("‚ö†Ô∏è –í—ã –Ω–µ –≤—ã–±—Ä–∞–ª–∏ –Ω–æ–≤—ã–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏.")
        else:
            st.success("üéâ –í—Å–µ –±–ª—é–¥–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω—ã! –ù–µ—Ç –ø–æ–∑–∏—Ü–∏–π –≤ '–ü—Ä–æ—á–µ–µ'.")
        


    # --- 4. ABC –ú–ê–¢–†–ò–¶–ê ---
    elif selected_tab == "‚≠ê –ú–∞—Ç—Ä–∏—Ü–∞ (ABC)":
        st.subheader("‚≠ê –ú–∞—Ç—Ä–∏—Ü–∞ –ú–µ–Ω—é (ABC)")
        col_L1, col_L2, col_L3, col_L4 = st.columns(4)
        col_L1.info("‚≠ê **–ó–≤–µ–∑–¥—ã**\n\n–í—ã—Å–æ–∫–∞—è –º–∞—Ä–∂–∞, –ü–æ–ø—É–ª—è—Ä–Ω—ã–µ.\n(–°–∏–Ω)")
        col_L2.warning("üêé **–õ–æ—à–∞–¥–∫–∏**\n\n–ù–∏–∑–∫–∞—è –º–∞—Ä–∂–∞, –ü–æ–ø—É–ª—è—Ä–Ω—ã–µ.\n(–ñ–µ–ª)")
        col_L3.success("‚ùì **–ó–∞–≥–∞–¥–∫–∏**\n\n–í—ã—Å–æ–∫–∞—è –º–∞—Ä–∂–∞, –ú–∞–ª–æ –ø—Ä–æ–¥–∞–∂.\n(–ó–µ–ª)")
        col_L4.error("üê∂ **–°–æ–±–∞–∫–∏**\n\n–ù–∏–∑–∫–∞—è –º–∞—Ä–∂–∞, –ú–∞–ª–æ –ø—Ä–æ–¥–∞–∂.\n(–ö—Ä–∞—Å)")

        abc_df = df_view.groupby('–ë–ª—é–¥–æ').agg({'–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ': 'sum', '–í—ã—Ä—É—á–∫–∞ —Å –ù–î–°': 'sum', '–°–µ–±–µ—Å—Ç–æ–∏–º–æ—Å—Ç—å': 'sum'}).reset_index()
        abc_df = abc_df[abc_df['–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ'] > 0]
        abc_df['–ú–∞—Ä–∂–∞'] = abc_df['–í—ã—Ä—É—á–∫–∞ —Å –ù–î–°'] - abc_df['–°–µ–±–µ—Å—Ç–æ–∏–º–æ—Å—Ç—å']
        abc_df['Unit_Margin'] = abc_df['–ú–∞—Ä–∂–∞'] / abc_df['–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ']
        avg_qty = abc_df['–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ'].mean()
        avg_margin = abc_df['Unit_Margin'].mean()
        
        def classify_abc(row):
            if row['Unit_Margin'] >= avg_margin and row['–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ'] >= avg_qty: return "‚≠ê –ó–≤–µ–∑–¥–∞"
            if row['Unit_Margin'] < avg_margin and row['–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ'] >= avg_qty: return "üêé –õ–æ—à–∞–¥–∫–∞"
            if row['Unit_Margin'] >= avg_margin and row['–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ'] < avg_qty: return "‚ùì –ó–∞–≥–∞–¥–∫–∞"
            return "üê∂ –°–æ–±–∞–∫–∞"

        abc_df['–ö–ª–∞—Å—Å'] = abc_df.apply(classify_abc, axis=1)
        # –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–µ —Ü–≤–µ—Ç–∞: –ó–≤–µ–∑–¥—ã=–°–∏–Ω–∏–π, –õ–æ—à–∞–¥–∫–∏=–ó–æ–ª–æ—Ç–æ–π, –ó–∞–≥–∞–¥–∫–∏=–ó–µ–ª–µ–Ω—ã–π, –°–æ–±–∞–∫–∏=–ö—Ä–∞—Å–Ω—ã–π
        fig_abc = px.scatter(abc_df, x="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ", y="Unit_Margin", color="–ö–ª–∞—Å—Å", hover_name="–ë–ª—é–¥–æ", size="–í—ã—Ä—É—á–∫–∞ —Å –ù–î–°", 
                             color_discrete_map={"‚≠ê –ó–≤–µ–∑–¥–∞": "blue", "üêé –õ–æ—à–∞–¥–∫–∞": "gold", "‚ùì –ó–∞–≥–∞–¥–∫–∞": "green", "üê∂ –°–æ–±–∞–∫–∞": "red"}, log_x=True)
        fig_abc.update_traces(hovertemplate='<b>%{hovertext}</b><br>–ü—Ä–æ–¥–∞–∂–∏: %{x} —à—Ç<br>–ú–∞—Ä–∂–∞ —Å –±–ª—é–¥–∞: %{y:.0f} ‚ÇΩ')
        fig_abc.add_vline(x=avg_qty, line_dash="dash", line_color="gray")
        fig_abc.add_hline(y=avg_margin, line_dash="dash", line_color="gray")
        st.plotly_chart(update_chart_layout(fig_abc), use_container_width=True)

    # --- 5. –î–ù–ò –ù–ï–î–ï–õ–ò ---
    elif selected_tab == "üóì –î–Ω–∏ –Ω–µ–¥–µ–ª–∏":
        st.subheader("üóì –î–Ω–∏ –Ω–µ–¥–µ–ª–∏")
        if len(dates_list) > 1:
            df_full['–î–µ–Ω—å–ù–µ–¥–µ–ª–∏'] = df_full['–î–∞—Ç–∞_–û—Ç—á–µ—Ç–∞'].dt.day_name()
            days_order = ["Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday"]
            days_rus = ["–ü–ù", "–í–¢", "–°–†", "–ß–¢", "–ü–¢", "–°–ë", "–í–°"]
            dow_stats = df_full.groupby(['–î–∞—Ç–∞_–û—Ç—á–µ—Ç–∞', '–î–µ–Ω—å–ù–µ–¥–µ–ª–∏'])['–í—ã—Ä—É—á–∫–∞ —Å –ù–î–°'].sum().reset_index().groupby('–î–µ–Ω—å–ù–µ–¥–µ–ª–∏')['–í—ã—Ä—É—á–∫–∞ —Å –ù–î–°'].mean().reindex(days_order).reset_index()
            dow_stats['–î–µ–Ω—å–†—É—Å'] = days_rus
            fig_dow = px.bar(dow_stats, x='–î–µ–Ω—å–†—É—Å', y='–í—ã—Ä—É—á–∫–∞ —Å –ù–î–°', color='–í—ã—Ä—É—á–∫–∞ —Å –ù–î–°')
            fig_dow.update_traces(texttemplate='%{y:,.0f} ‚ÇΩ', textposition='auto')
            st.plotly_chart(update_chart_layout(fig_dow), use_container_width=True)
        else:
            st.warning("–ú–∞–ª–æ –¥–∞–Ω–Ω—ã—Ö.")

    # --- 6. –ü–õ–ê–ù –ó–ê–ö–£–ü–û–ö ---
    elif selected_tab == "üì¶ –ü–ª–∞–Ω –ó–∞–∫—É–ø–æ–∫":
        st.subheader("üì¶ –ö–∞–ª—å–∫—É–ª—è—Ç–æ—Ä –ó–∞–∫—É–ø–∫–∏")
        c_set1, c_set2 = st.columns(2)
        days_to_buy = c_set1.slider("üìÖ –î–Ω–µ–π –∑–∞–∫—É–ø–∫–∏", 1, 14, 3)
        safety_stock = c_set2.slider("üõ° –ó–∞–ø–∞—Å (%)", 0, 50, 10)
        
        last_30_days = df_full['–î–∞—Ç–∞_–û—Ç—á–µ—Ç–∞'].max() - timedelta(days=30)
        df_recent = df_full[df_full['–î–∞—Ç–∞_–û—Ç—á–µ—Ç–∞'] >= last_30_days]
        daily_sales = df_recent.groupby('–ë–ª—é–¥–æ')['–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ'].sum().reset_index()
        daily_sales['Avg_Daily_Qty'] = daily_sales['–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ'] / 30
        last_prices = df_full.sort_values('–î–∞—Ç–∞_–û—Ç—á–µ—Ç–∞').groupby('–ë–ª—é–¥–æ')['Unit_Cost'].last().reset_index()
        plan_df = pd.merge(daily_sales[['–ë–ª—é–¥–æ', 'Avg_Daily_Qty']], last_prices, on='–ë–ª—é–¥–æ')
        
        plan_df['Need_Qty'] = plan_df['Avg_Daily_Qty'] * days_to_buy * (1 + safety_stock/100)
        plan_df['Budget'] = plan_df['Need_Qty'] * plan_df['Unit_Cost']
        plan_df = plan_df[plan_df['Need_Qty'] > 0.5].sort_values('Budget', ascending=False)
        
        st.metric("üí∞ –ë—é–¥–∂–µ—Ç", f"{plan_df['Budget'].sum():,.0f} ‚ÇΩ")
        st.dataframe(
            plan_df[['–ë–ª—é–¥–æ', 'Unit_Cost', 'Need_Qty', 'Budget']],
            column_config={
                "Unit_Cost": st.column_config.NumberColumn(format="%.1f ‚ÇΩ"),
                "Need_Qty": st.column_config.NumberColumn(format="%.1f"),
                "Budget": st.column_config.NumberColumn(format="%.0f ‚ÇΩ"),
            },
            use_container_width=True
        )

    # --- 7. –°–ò–ú–£–õ–Ø–¢–û–† ---
    elif selected_tab == "üîÆ –°–∏–º—É–ª—è—Ç–æ—Ä":
        st.subheader("üîÆ –°–∏–º—É–ª—è—Ç–æ—Ä: –ê–Ω–∞–ª–∏–∑ '–ß—Ç–æ –µ—Å–ª–∏?'")
        st.info("–≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∏—Ä—É–π—Ç–µ —Å —Ü–µ–Ω–∞–º–∏ –∏ –∑–∞—Ç—Ä–∞—Ç–∞–º–∏, —á—Ç–æ–±—ã —É–≤–∏–¥–µ—Ç—å, –∫–∞–∫ –∏–∑–º–µ–Ω–∏—Ç—Å—è –≤–∞—à–∞ –ø—Ä–∏–±—ã–ª—å.")
        
        col_input, col_result = st.columns([1, 2])
        
        with col_input:
            st.write("### üéõ –ù–∞—Å—Ç—Ä–æ–π–∫–∏")
            
            # 1. –í—ã–±–æ—Ä –∫–∞—Ç–µ–≥–æ—Ä–∏–π
            all_cats = sorted(df_full['–ö–∞—Ç–µ–≥–æ—Ä–∏—è'].dropna().unique())
            selected_cats = st.multiselect("–í—ã–±–µ—Ä–∏—Ç–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏:", all_cats, default=all_cats[:3] if len(all_cats) > 3 else all_cats)
            
            if not selected_cats:
                st.warning("üëà –í—ã–±–µ—Ä–∏—Ç–µ —Ö–æ—Ç—è –±—ã –æ–¥–Ω—É –∫–∞—Ç–µ–≥–æ—Ä–∏—é.")
            else:
                st.markdown("---")
                st.write("**–ü–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏—è:**")
                
                delta_price = st.slider("üí∞ –ò–∑–º–µ–Ω–∏—Ç—å –¶–µ–Ω—É –ø—Ä–æ–¥–∞–∂–∏ (%)", -50, 50, 0, step=1, help="–ù–∞—Å–∫–æ–ª—å–∫–æ –º—ã –ø–æ–¥–Ω–∏–º–µ–º –∏–ª–∏ –æ–ø—É—Å—Ç–∏–º —Ü–µ–Ω—ã –≤ –º–µ–Ω—é")
                delta_cost = st.slider("üìâ –ò–∑–º–µ–Ω–∏—Ç—å –°–µ–±–µ—Å—Ç–æ–∏–º–æ—Å—Ç—å (%)", -50, 50, 0, step=1, help="–ï—Å–ª–∏ –ø–æ—Å—Ç–∞–≤—â–∏–∫–∏ –ø–æ–¥–Ω–∏–º—É—Ç —Ü–µ–Ω—ã")
                delta_vol = st.slider("üõí –≠–ª–∞—Å—Ç–∏—á–Ω–æ—Å—Ç—å —Å–ø—Ä–æ—Å–∞ (–ü—Ä–æ–¥–∞–∂–∏ %)", -50, 50, 0, step=1, help="–ö–∞–∫ –∏–∑–º–µ–Ω–∏—Ç—Å—è –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —á–µ–∫–æ–≤ (–æ–±—ã—á–Ω–æ –µ—Å–ª–∏ —Ü–µ–Ω–∞ —Ä–∞—Å—Ç–µ—Ç, –ø—Ä–æ–¥–∞–∂–∏ –ø–∞–¥–∞—é—Ç)")

        with col_result:
            if selected_cats:
                # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö
                df_sim = df_view[df_view['–ö–∞—Ç–µ–≥–æ—Ä–∏—è'].isin(selected_cats)].copy()
                
                # –ë–∞–∑–æ–≤—ã–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏
                base_revenue = df_sim['–í—ã—Ä—É—á–∫–∞ —Å –ù–î–°'].sum()
                base_cost_total = df_sim['–°–µ–±–µ—Å—Ç–æ–∏–º–æ—Å—Ç—å'].sum()
                base_margin = base_revenue - base_cost_total
                base_qty = df_sim['–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ'].sum()
                
                # –°–∏–º—É–ª—è—Ü–∏—è
                # –ù–æ–≤–∞—è —Ü–µ–Ω–∞ = –°—Ç–∞—Ä–∞—è —Ü–µ–Ω–∞ * (1 + %) -> –ù–æ–≤–∞—è –≤—ã—Ä—É—á–∫–∞ –Ω–∞ –µ–¥. = –°—Ç–∞—Ä–∞—è –≤—ã—Ä—É—á–∫–∞ * (1 + %)
                # –ù–æ–≤–∞—è —Å/—Å = –°—Ç–∞—Ä–∞—è —Å/—Å * (1 + %)
                # –ù–æ–≤–æ–µ –∫–æ–ª-–≤–æ = –°—Ç–∞—Ä–æ–µ –∫–æ–ª-–≤–æ * (1 + %)
                
                sim_revenue = base_revenue * (1 + delta_price/100) * (1 + delta_vol/100)
                sim_cost_total = base_cost_total * (1 + delta_cost/100) * (1 + delta_vol/100)
                sim_margin = sim_revenue - sim_cost_total
                
                # –î–µ–ª—å—Ç—ã
                diff_rev = sim_revenue - base_revenue
                diff_margin = sim_margin - base_margin
                
                st.write(f"### üìä –ü—Ä–æ–≥–Ω–æ–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ (–ö–∞—Ç–µ–≥–æ—Ä–∏–∏: {len(selected_cats)})")
                
                # –ú–µ—Ç—Ä–∏–∫–∏
                kpi1, kpi2, kpi3 = st.columns(3)
                kpi1.metric("–í—ã—Ä—É—á–∫–∞ (Sim)", f"{sim_revenue:,.0f} ‚ÇΩ", f"{diff_rev:+,.0f} ‚ÇΩ")
                kpi2.metric("–ú–∞—Ä–∂–∞ (Sim)", f"{sim_margin:,.0f} ‚ÇΩ", f"{diff_margin:+,.0f} ‚ÇΩ")
                
                new_profitability = (sim_margin / sim_revenue * 100) if sim_revenue > 0 else 0
                old_profitability = (base_margin / base_revenue * 100) if base_revenue > 0 else 0
                kpi3.metric("–†–µ–Ω—Ç–∞–±–µ–ª—å–Ω–æ—Å—Ç—å", f"{new_profitability:.1f}%", f"{new_profitability - old_profitability:+.1f}%")
                
                st.markdown("---")
                
                # –ì—Ä–∞—Ñ–∏–∫ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
                st.write("#### ‚öñÔ∏è –°—Ä–∞–≤–Ω–µ–Ω–∏–µ: –î–æ –∏ –ü–æ—Å–ª–µ")
                
                comp_data = [
                    {'–ü–æ–∫–∞–∑–∞—Ç–µ–ª—å': '–í—ã—Ä—É—á–∫–∞', '–°—Ü–µ–Ω–∞—Ä–∏–π': '–ë—ã–ª–æ', '–°—É–º–º–∞': base_revenue},
                    {'–ü–æ–∫–∞–∑–∞—Ç–µ–ª—å': '–í—ã—Ä—É—á–∫–∞', '–°—Ü–µ–Ω–∞—Ä–∏–π': '–°—Ç–∞–Ω–µ—Ç', '–°—É–º–º–∞': sim_revenue},
                    {'–ü–æ–∫–∞–∑–∞—Ç–µ–ª—å': '–ú–∞—Ä–∂–∞ (–ü—Ä–∏–±—ã–ª—å)', '–°—Ü–µ–Ω–∞—Ä–∏–π': '–ë—ã–ª–æ', '–°—É–º–º–∞': base_margin},
                    {'–ü–æ–∫–∞–∑–∞—Ç–µ–ª—å': '–ú–∞—Ä–∂–∞ (–ü—Ä–∏–±—ã–ª—å)', '–°—Ü–µ–Ω–∞—Ä–∏–π': '–°—Ç–∞–Ω–µ—Ç', '–°—É–º–º–∞': sim_margin},
                ]
                df_comp = pd.DataFrame(comp_data)
                
                fig_comp = px.bar(df_comp, x='–ü–æ–∫–∞–∑–∞—Ç–µ–ª—å', y='–°—É–º–º–∞', color='–°—Ü–µ–Ω–∞—Ä–∏–π', barmode='group', 
                                  color_discrete_map={'–ë—ã–ª–æ': 'gray', '–°—Ç–∞–Ω–µ—Ç': 'blue' if diff_margin >= 0 else 'red'})
                fig_comp.update_traces(texttemplate='%{y:,.0f} ‚ÇΩ', textposition='auto')
                st.plotly_chart(update_chart_layout(fig_comp), use_container_width=True)
                
                if diff_margin > 0:
                    st.success(f"üöÄ –û—Ç–ª–∏—á–Ω—ã–π —Å—Ü–µ–Ω–∞—Ä–∏–π! –í—ã –∑–∞—Ä–∞–±–æ—Ç–∞–µ—Ç–µ –Ω–∞ **{diff_margin:,.0f} ‚ÇΩ** –±–æ–ª—å—à–µ.")
                elif diff_margin < 0:
                    st.error(f"‚ö†Ô∏è –û—Å—Ç–æ—Ä–æ–∂–Ω–æ! –≠—Ç–æ –ø—Ä–∏–≤–µ–¥–µ—Ç –∫ —É–±—ã—Ç–∫–∞–º –≤ —Ä–∞–∑–º–µ—Ä–µ **{abs(diff_margin):,.0f} ‚ÇΩ**.")
                else:
                    st.info("–ù–∏–∫–∞–∫–∏—Ö –∏–∑–º–µ–Ω–µ–Ω–∏–π.")

else:
    st.info("üëà –ó–∞–≥—Ä—É–∑–∏—Ç–µ –¥–∞–Ω–Ω—ã–µ.")

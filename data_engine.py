import pandas as pd
import numpy as np
import re
import os
import requests
from io import BytesIO
from datetime import datetime

# --- CONSTANTS ---
IGNORE_NAMES = [
    "–ë–∞—Ä –ú–µ—Å—Ç–æ", "–ë–∞—Ä –ú–µ—Å—Ç–æ –ë—É—Ä–≥–µ—Ä–Ω–∞—è", "–ò—Ç–æ–≥–æ", "–ù–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä–∞", "–°–∫–ª–∞–¥—ã", 
    "–ù–µ–∑–∞–≤–µ—Ä—à—ë–Ω–Ω–æ–µ –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–æ", "–¢–æ–≤–∞—Ä—ã", "–£—Å–ª—É–≥–∏", "–ï–ì–ê–ò–°", "–ê–ª–∫–æ–≥–æ–ª—å",
    "–ü–∏–≤–æ —Ä–∞–∑–ª–∏–≤–Ω–æ–µ –†–æ—Å—Å–∏—è", "–ü–∏–≤–æ –∏–º–ø–æ—Ä—Ç–Ω–æ–µ", "–ü–∏–≤–æ –±—É—Ç—ã–ª–æ—á–Ω–æ–µ", "–°–∏–¥—Ä", 
    "–í–æ–¥–∫–∞", "–°–∞–º–æ–≥–æ–Ω", "–ù–∞—Å—Ç–æ–π–∫–∏", "–ß–∞—á–∞/–ì—Ä–∞–ø–∞", "–î–∂–∏–Ω", "–í–∏—Å–∫–∏/–ë—É—Ä–±–æ–Ω", 
    "–¢–µ–∫–∏–ª–∞", "–†–æ–º", "–ö–æ–Ω—å—è–∫/–ë—Ä–µ–Ω–¥–∏", "–ê–ø–µ—Ä–∏—Ç–∏–≤—ã", "–õ–∏–∫–µ—Ä—ã –∏ –Ω–∞—Å—Ç–æ–π–∫–∏", 
    "–í–µ—Ä–º—É—Ç—ã", "–ò–≥—Ä–∏—Å—Ç—ã–µ –≤–∏–Ω–∞", "–¢–∏—Ö–∏–µ –±–µ–ª—ã–µ –≤–∏–Ω–∞", "–¢–∏—Ö–∏–µ —Ä–æ–∑–æ–≤—ã–µ –≤–∏–Ω–∞", 
    "–¢–∏—Ö–∏–µ –∫—Ä–∞—Å–Ω—ã–µ –≤–∏–Ω–∞", "–ö—Ä–µ–ø–ª–µ–Ω—ã–µ –≤–∏–Ω–∞", "–ë/–∞ –Ω–∞–ø–∏—Ç–∫–∏", "–ö–æ–∫—Ç–µ–π–ª–∏ –ø–æ –∫–æ–Ω—Ç—Ä–∞–∫—Ç—É"
]

RUS_MONTHS = {
    '—è–Ω–≤–∞—Ä—è': 1, '—Ñ–µ–≤—Ä–∞–ª—è': 2, '–º–∞—Ä—Ç–∞': 3, '–∞–ø—Ä–µ–ª—è': 4, '–º–∞—è': 5, '–∏—é–Ω—è': 6,
    '–∏—é–ª—è': 7, '–∞–≤–≥—É—Å—Ç–∞': 8, '—Å–µ–Ω—Ç—è–±—Ä—è': 9, '–æ–∫—Ç—è–±—Ä—è': 10, '–Ω–æ—è–±—Ä—è': 11, '–¥–µ–∫–∞–±—Ä—è': 12,
    '—è–Ω–≤': 1, '—Ñ–µ–≤': 2, '–º–∞—Ä': 3, '–∞–ø—Ä': 4, '–º–∞–π': 5, '–∏—é–Ω': 6,
    '–∏—é–ª': 7, '–∞–≤–≥': 8, '—Å–µ–Ω': 9, '–æ–∫—Ç': 10, '–Ω–æ—è': 11, '–¥–µ–∫': 12
}

RUS_MONTH_NAMES = {
    1: '–Ø–Ω–≤–∞—Ä—å', 2: '–§–µ–≤—Ä–∞–ª—å', 3: '–ú–∞—Ä—Ç', 4: '–ê–ø—Ä–µ–ª—å', 5: '–ú–∞–π', 6: '–ò—é–Ω—å',
    7: '–ò—é–ª—å', 8: '–ê–≤–≥—É—Å—Ç', 9: '–°–µ–Ω—Ç—è–±—Ä—å', 10: '–û–∫—Ç—è–±—Ä—å', 11: '–ù–æ—è–±—Ä—å', 12: '–î–µ–∫–∞–±—Ä—å'
}

CACHE_FILE = "data_cache.parquet"
LAST_SYNC_META = {
    "dropped_stats": {"count": 0, "cost": 0.0, "items": []},
    "warnings": [],
}

# --- HELPERS ---
def parse_russian_date(text):
    if not isinstance(text, str): return None
    text = text.lower()
    match_text = re.search(r'(\d{1,2})\s+([–∞-—è]+)\s+(\d{4})', text)
    if match_text:
        day, month_str, year = match_text.groups()
        if month_str in RUS_MONTHS:
            try:
                return datetime(int(year), RUS_MONTHS[month_str], int(day))
            except ValueError: return None
    match_digit = re.search(r'(\d{2})\.(\d{2})\.(\d{4})', text)
    if match_digit:
        try:
            return datetime.strptime(match_digit.group(0), '%d.%m.%Y')
        except ValueError: return None
    return None

def detect_header_row(df_preview, required_column):
    for idx in range(min(20, len(df_preview))):
        row_values = df_preview.iloc[idx].astype(str).str.lower()
        if row_values.str.contains(required_column.lower(), regex=False).any():
            return idx
    return None

from services import category_service

def get_macro_category(cat):
    if cat in ['‚òï –ö–æ—Ñ–µ', 'üçµ –ß–∞–π', 'üçì –ú–∏–ª–∫/–§—Ä–µ—à/–°–º—É–∑–∏', 'üßâ –ö–æ–∫—Ç–µ–π–ª—å –ë/–ê', 'üö∞ –†–æ–∑–ª–∏–≤ –ë/–ê', 'ü•§ –°—Ç–µ–∫–ª–æ/–ë–∞–Ω–∫–∞ –ë/–ê']: 
        return '‚òï –ë–µ–∑–∞–ª–∫–æ–≥–æ–ª—å–Ω–æ–µ'
    if cat in ['üçè –°–∏–¥—Ä –®–¢', 'üçæ –ü–∏–≤–æ –®–¢', 'üç∫ –ü–∏–≤–æ –†–æ–∑–ª–∏–≤']: 
        return 'üç∫ –ü–∏–≤–æ/–°–∏–¥—Ä'
    if cat in ['ü•É –í–∏—Å–∫–∏', 'üíß –í–æ–¥–∫–∞', 'üè¥‚Äç‚ò†Ô∏è –†–æ–º', 'üåµ –¢–µ–∫–∏–ª–∞', 'üå≤ –î–∂–∏–Ω', 'üçá –ö–æ–Ω—å—è–∫/–ë—Ä–µ–Ω–¥–∏', 'üçí –õ–∏–∫–µ—Ä/–ù–∞—Å—Ç–æ–π–∫–∞']: 
        return 'ü•É –ö—Ä–µ–ø–∫–æ–µ'
    return cat

def detect_category_granular(name_input, mapping=None):
    name = str(name_input).strip().lower()
    
    # 1. DYNAMIC MAPPING (JSON)
    # Check exact match first
    # mapping keys might be original case, so we should check carefully
    # Assuming mapping keys are case-sensitive or we lower them?
    # Let's assume exact match for now as per `admin_view` editor
    if mapping:
        if name in mapping:
            return mapping[name]
        if name_input in mapping:
            return mapping[name_input]
    
    # 2. HARDCODED FALLBACK (Original Dictionary)
    manual_dict = {
        'banana tiki': 'üçπ –ö–æ–∫—Ç–µ–π–ª–∏', 'black hole': 'üçπ –ö–æ–∫—Ç–µ–π–ª–∏', 'clover club': 'üçπ –ö–æ–∫—Ç–µ–π–ª–∏', 
        'drunk bee': 'üçπ –ö–æ–∫—Ç–µ–π–ª–∏', 'milk punch –±—É—Ä–±–æ–Ω-—á–µ—Ä–Ω–∞—è —Å–º–æ—Ä–æ–¥–∏–Ω–∞': 'üçπ –ö–æ–∫—Ç–µ–π–ª–∏', 
        'milk punch –≤–∏—Å–∫–∏-–≤–∏—à–Ω—è': 'ü•É –í–∏—Å–∫–∏', 'milk punch —Ä–æ–º-–∫–æ–∫–æ—Å': 'üçπ –ö–æ–∫—Ç–µ–π–ª–∏', 
        'nevermind': 'üçπ –ö–æ–∫—Ç–µ–π–ª–∏', 'party-mix —Å –≤–∏—Å–∫–∏': 'ü•É –í–∏—Å–∫–∏', 'passion star martini': 'üçπ –ö–æ–∫—Ç–µ–π–ª–∏', 
        'pineapple spritz dmf pineapple': 'üçπ –ö–æ–∫—Ç–µ–π–ª–∏', 'rum bubble': 'üçπ –ö–æ–∫—Ç–µ–π–ª–∏', 'zombieville': 'üçπ –ö–æ–∫—Ç–µ–π–ª–∏', 
        '–∞–≤—Ç–æ—Ä—Å–∫–æ–µ —Ä–∏—Å–ª–∏–Ω–≥ 125–º–ª': 'üç∑ –í–∏–Ω–æ', '–∞–≤—Ç–æ—Ä—Å–∫–æ–µ —Å–æ–≤–∏–Ω—å–æ–Ω –±–ª–∞–Ω 125–º–ª': 'üç∑ –í–∏–Ω–æ', 
        '–∞–≤—Ç–æ—Ä—Å–∫–æ–µ —Å–æ–≤–∏–Ω—å–æ–Ω –±–ª–∞–Ω 750–º–ª': 'üç∑ –í–∏–Ω–æ', '–∞–π—Ä–∏—à –∫–æ—Ñ–µ': 'üçπ –ö–æ–∫—Ç–µ–π–ª–∏', '–∞–Ω—Ç–∏–∫–æ –∏—Ç–∞–ª—å—è–Ω–æ 125–º–ª': 'üç∑ –í–∏–Ω–æ', 
        '–∞–Ω—Ç–∏–∫–æ –∏—Ç–∞–ª—å—è–Ω–æ 700–º–ª': 'üç∑ –í–∏–Ω–æ', '–∞–ø–µ–ª—å—Å–∏–Ω 20–≥': 'üç¨ –î–æ–ø. –∏–Ω–≥—Ä–µ–¥–∏–µ–Ω—Ç—ã', '–∞–ø–µ—Ä–æ–ª—å —à–ø—Ä–∏—Ü': 'üçπ –ö–æ–∫—Ç–µ–π–ª–∏', 
        '–∞—Å–∫–∞–Ω–µ–ª–∏ 40–º–ª': 'üçá –ö–æ–Ω—å—è–∫/–ë—Ä–µ–Ω–¥–∏', '–±–∞–ª–∞–Ω—Ç–∞–π–Ω—Å 40–º–ª': 'ü•É –í–∏—Å–∫–∏', '–±–∞–Ω–¥–∏–¥–æ 40–º–ª': 'üåµ –¢–µ–∫–∏–ª–∞', 
        '–±–µ–ª–∞—è –±–µ—Ä–µ–∑–∫–∞ 40–º–ª': 'üíß –í–æ–¥–∫–∞', '–±–µ–ª—É–≥–∞ –Ω–æ–±–ª 40–º–ª': 'üíß –í–æ–¥–∫–∞', '–±–µ–ª—ã–π —Ä—É—Å—Å–∫–∏–π': 'üçπ –ö–æ–∫—Ç–µ–π–ª–∏', 
        '–±–µ—Ä–Ω 0,33': 'ü•§ –°—Ç–µ–∫–ª–æ/–ë–∞–Ω–∫–∞ –ë/–ê', '–±–∏—Ç—Ç–µ—Ä–±—É–ª–ª': 'üçπ –ö–æ–∫—Ç–µ–π–ª–∏', '–±–ª—ç–∫ —Ä—ç–º 40 –º–ª': 'ü•É –í–∏—Å–∫–∏', 
        '–±–ª—ç–∫ —à–∏–ø 500–º–ª': 'üç∫ –ü–∏–≤–æ –†–æ–∑–ª–∏–≤', '–±–æ—Ä–∂–æ–º–∏ 0,5': 'ü•§ –°—Ç–µ–∫–ª–æ/–ë–∞–Ω–∫–∞ –ë/–ê', '–±—Ä–∞–º–±–ª': 'üçπ –ö–æ–∫—Ç–µ–π–ª–∏', 
        '–±—Ä—É–º –≤ –∞—Å—Å. 40–º–ª': 'üå≤ –î–∂–∏–Ω', '–≤–∏–Ω–æ –º–µ—Å—Ç–Ω–æ–µ 125–º–ª': 'üç∑ –í–∏–Ω–æ', '–≤–∏–Ω–æ –º–µ—Å—Ç–Ω–æ–µ –µ–∂–µ–≤–∏—á–Ω–æ–µ 125–º–ª': 'üç∫ –ü–∏–≤–æ –†–æ–∑–ª–∏–≤', 
        '–≤–∏—Å–∫–∏ –∫–æ–ª–∞': 'üçπ –ö–æ–∫—Ç–µ–π–ª–∏', '–≤–æ–¥–∞ —Å –ª–∏–º–æ–Ω–æ–º': 'üö∞ –†–æ–∑–ª–∏–≤ –ë/–ê', '–≥–∞—Ç–æ –Ω–µ–≥—Ä–æ 125–º–ª': 'üç∑ –í–∏–Ω–æ', 
        '–≥–ª–µ–Ω–ª–∏–≤–µ—Ç 12 –ª–µ—Ç 40–º–ª': 'ü•É –í–∏—Å–∫–∏', '–≥–ª–∏–Ω—Ç–≤–µ–π –±/–∞': 'üßâ –ö–æ–∫—Ç–µ–π–ª—å –ë/–ê', '–≥–ª–∏–Ω—Ç–≤–µ–π–Ω': 'üçπ –ö–æ–∫—Ç–µ–π–ª–∏', 
        '–≥–ª–∏–Ω—Ç–≤–µ–π–Ω –±/–∞ –±—É—Ä': 'üßâ –ö–æ–∫—Ç–µ–π–ª—å –ë/–ê', '–≥–ª–∏–Ω—Ç–≤–µ–π–Ω –±–µ–ª—ã–π': 'üçπ –ö–æ–∫—Ç–µ–π–ª–∏', '–≥–ª–∏–Ω—Ç–≤–µ–π–Ω –±–µ–ª—ã–π –±/–∞': 'üßâ –ö–æ–∫—Ç–µ–π–ª—å –ë/–ê', 
        '–≥–ª–∏–Ω—Ç–≤–µ–π–Ω –±—É—Ä': 'üçπ –ö–æ–∫—Ç–µ–π–ª–∏', '–≥–æ–ª—É–±—ã–µ –≥–∞–≤–∞–∏': 'üçπ –ö–æ–∫—Ç–µ–π–ª–∏', '–≥—Ä–µ–π–ø—Ñ—Ä—É—Ç–æ–≤—ã–π —Ñ—Ä–µ—à 250 –º–ª': 'üçì –ú–∏–ª–∫/–§—Ä–µ—à/–°–º—É–∑–∏', 
        '–¥–∞–π–∫–∏—Ä–∏ –≤ –∞—Å—Å–æ—Ä—Ç–∏–º–µ–Ω—Ç–µ': 'üçπ –ö–æ–∫—Ç–µ–π–ª–∏', '–¥–∂–µ–º–µ—Å–æ–Ω 40–º–ª': 'ü•É –í–∏—Å–∫–∏', '–¥–∂–∏–Ω-—Ç–æ–Ω–∏–∫': 'ü•§ –°—Ç–µ–∫–ª–æ/–ë–∞–Ω–∫–∞ –ë/–ê', 
        '–¥–∂–∏–Ω-—Ç—Ä–æ–ø–∏–∫': 'üçπ –ö–æ–∫—Ç–µ–π–ª–∏', '–µ–≥–µ—Ä–º–µ–π—Å—Ç–µ—Ä 40–º–ª': 'üçí –õ–∏–∫–µ—Ä/–ù–∞—Å—Ç–æ–π–∫–∞', '–∏–≤–∞–Ω —á–∞–π 400–º–ª –±—É—Ä': 'üçµ –ß–∞–π', 
        '–∫–∞–ø—É—á–∏–Ω–æ —Å –∫–æ–∫–æ—Å–æ–≤—ã–º –º–æ–ª–æ–∫–æ–º': '‚òï –ö–æ—Ñ–µ', '–∫–∞–ø—É—á–∏–Ω–æ —Å –º–∏–Ω–¥–∞–ª—å–Ω—ã–º –º–æ–ª–æ–∫–æ–º': '‚òï –ö–æ—Ñ–µ', '–∫–æ—Å–º–æ–ø–æ–ª–∏—Ç–µ–Ω': 'üçπ –ö–æ–∫—Ç–µ–π–ª–∏', 
        '–∫–æ—Ñ–µ –∞–º–µ—Ä–∏–∫–∞–Ω–æ 150 –º–ª': '‚òï –ö–æ—Ñ–µ', '–∫–æ—Ñ–µ –∞–º–µ—Ä–∏–∫–∞–Ω–æ –±—É—Ä': '‚òï –ö–æ—Ñ–µ', '–∫–æ—Ñ–µ –∞–º–µ—Ä–∏–∫–∞–Ω–æ –¥–ª—è –ø–µ—Ä—Å–æ–Ω–∞–ª–∞': '‚òï –ö–æ—Ñ–µ', 
        '–∫–æ—Ñ–µ –¥–≤–æ–π–Ω–æ–π –∞–º–µ—Ä–∏–∫–∞–Ω–æ –±—É—Ä': '‚òï –ö–æ—Ñ–µ', '–∫–æ—Ñ–µ –¥–≤–æ–π–Ω–æ–π –∫–∞–ø—É—á–∏–Ω–æ –±—É—Ä': '‚òï –ö–æ—Ñ–µ', '–∫–æ—Ñ–µ –∫–∞–ø—É—á–∏–Ω–æ': '‚òï –ö–æ—Ñ–µ', 
        '–∫–æ—Ñ–µ –∫–∞–ø—É—á–∏–Ω–æ –¥–ª—è –ø–µ—Ä—Å–æ–Ω–∞–ª–∞': '‚òï –ö–æ—Ñ–µ', '–∫–æ—Ñ–µ –ª–∞—Ç—Ç–µ': '‚òï –ö–æ—Ñ–µ', '–∫–æ—Ñ–µ –ª–∞—Ç—Ç–µ –±—É—Ä': '‚òï –ö–æ—Ñ–µ', 
        '–∫–æ—Ñ–µ –ø–æ –≤–æ—Å—Ç–æ—á–Ω–æ–º': '‚òï –ö–æ—Ñ–µ', '–∫–æ—Ñ–µ —Å–æ —Å–ø–µ—Ü–∏—è–º–∏': '‚òï –ö–æ—Ñ–µ', '–∫–æ—Ñ–µ —ç—Å–ø—Ä–µ—Å—Å–æ': '‚òï –ö–æ—Ñ–µ', 
        '–∫–æ—Ñ–µ —ç—Å–ø—Ä–µ—Å—Å–æ –¥–≤–æ–π–Ω–æ–π': '‚òï –ö–æ—Ñ–µ', '–∫—Ä–∞—Å–Ω–æ—Å—Ç–æ–ø, –∫–æ—Ä–≤–∏–Ω–∞ 125–º–ª': 'üç∑ –í–∏–Ω–æ', '–∫—Ä—É—à–æ–≤–∏—Ü–µ 0,33': 'üçæ –ü–∏–≤–æ –®–¢', 
        '–∫—Ä—É—à–æ–≤–∏—Ü–µ 0,33 –±/–∞': 'ü•§ –°—Ç–µ–∫–ª–æ/–ë–∞–Ω–∫–∞ –ë/–ê', '–∫—Ä—É—à–æ–≤–∏—Ü–µ —Ç–µ–º–Ω–æ–µ 500–º–ª': 'üç∫ –ü–∏–≤–æ –†–æ–∑–ª–∏–≤', '–∫—Ä—É—à–æ–≤–∏—Ü–µ —á–µ—Ä–Ω–µ, 0,45': 'üçæ –ü–∏–≤–æ –®–¢', 
        '–∫—É–±–∞ –ª–∏–±—Ä–µ': 'üçπ –ö–æ–∫—Ç–µ–π–ª–∏', '–ª–∞–π–º 20–≥': 'üç¨ –î–æ–ø. –∏–Ω–≥—Ä–µ–¥–∏–µ–Ω—Ç—ã', '–ª–∞–º–±—Ä—É—Å–∫–æ\xa0 125–º–ª': 'üç∑ –í–∏–Ω–æ', 
        '–ª–∞—Ç—Ç–µ —Å –∫–æ–∫–æ—Å–æ–≤—ã–º –º–æ–ª–æ–∫–æ–º': '‚òï –ö–æ—Ñ–µ', '–ª–∞—Ç—Ç–µ —Å –º–∏–Ω–¥–∞–ª—å–Ω—ã–º –º–æ–ª–æ–∫–æ–º': '‚òï –ö–æ—Ñ–µ', '–ª–µ –≥—Ä–∞–Ω 125–º–ª': 'üç∑ –í–∏–Ω–æ', 
        '–ª–µ –≥—Ä–∞–Ω –Ω—É–∞—Ä 750–º–ª': 'üç∑ –í–∏–Ω–æ', '–ª–∏–º–æ–Ω 20–≥': 'üç¨ –î–æ–ø. –∏–Ω–≥—Ä–µ–¥–∏–µ–Ω—Ç—ã', '–ª–æ–Ω–≥ –∞–π–ª–µ–Ω–¥ –∞–π—Å —Ç–∏': 'üçπ –ö–æ–∫—Ç–µ–π–ª–∏', 
        '–º–∞–π —Ç–∞–π': 'üçπ –ö–æ–∫—Ç–µ–π–ª–∏', '–º–∞—Ä–∞–∫—É–π—è –≥—É–∞–≤–∞': 'üçµ –ß–∞–π', '–º–∞—Ä–≥–∞—Ä–∏—Ç–∞': 'üçπ –ö–æ–∫—Ç–µ–π–ª–∏', '–º–µ–π–∑–æ–Ω 500–º–ª': 'üç∫ –ü–∏–≤–æ –†–æ–∑–ª–∏–≤', 
        '–º–µ—Å—Ç–Ω–æ–µ —Å–≤–µ—Ç–ª–æ–µ 1000–º–ª': 'üç∫ –ü–∏–≤–æ –†–æ–∑–ª–∏–≤', '–º–µ—Å—Ç–Ω–æ–µ —Å–≤–µ—Ç–ª–æ–µ 500–º–ª': 'üç∫ –ü–∏–≤–æ –†–æ–∑–ª–∏–≤', '–º–∏–ª–∫ —à–µ–π–∫ –≤–∞–Ω–∏–ª—å–Ω—ã–π': 'üçì –ú–∏–ª–∫/–§—Ä–µ—à/–°–º—É–∑–∏', 
        '–º–∏–ª–∫ —à–µ–π–∫ –∫–ª—É–±–Ω–∏—á–Ω–æ-–±–∞–Ω–∞–Ω–æ–≤—ã–π': 'üçì –ú–∏–ª–∫/–§—Ä–µ—à/–°–º—É–∑–∏', '–º–∏–ª–∫ —à–µ–π–∫ –ª–µ—Å–Ω—ã–µ —è–≥–æ–¥—ã': 'üçì –ú–∏–ª–∫/–§—Ä–µ—à/–°–º—É–∑–∏', 
        '–º–∏–ª–∫ —à–µ–π–∫ —à–æ–∫–æ–ª–∞–¥–Ω—ã–π': 'üçì –ú–∏–ª–∫/–§—Ä–µ—à/–°–º—É–∑–∏', '–º–∏–Ω–µ—Ä–∞–ª—å–Ω–∞—è –≤–æ–¥–∞ 0,33': 'ü•§ –°—Ç–µ–∫–ª–æ/–ë–∞–Ω–∫–∞ –ë/–ê', '–º–∏–Ω–µ—Ä–∞–ª—å–Ω–∞—è –≤–æ–¥–∞ 0,5': 'ü•§ –°—Ç–µ–∫–ª–æ/–ë–∞–Ω–∫–∞ –ë/–ê', 
        '–º–æ–ª–æ–∫–æ 50–º–ª': 'üç¨ –î–æ–ø. –∏–Ω–≥—Ä–µ–¥–∏–µ–Ω—Ç—ã', '–º–æ—Ä—Å 250 –º–ª': 'üö∞ –†–æ–∑–ª–∏–≤ –ë/–ê', '–º–æ—Ä—Å–∫–æ–π –±—Ä–∏–∑ –º–∞–ª–∏–±—É': 'üçπ –ö–æ–∫—Ç–µ–π–ª–∏', 
        '–º–æ—Ö–∏—Ç–æ –±/–∞': 'üßâ –ö–æ–∫—Ç–µ–π–ª—å –ë/–ê', '–º–æ—Ö–∏—Ç–æ –≤ –∞—Å—Å.': 'üçπ –ö–æ–∫—Ç–µ–π–ª–∏', '–º—è—Ç–∞ 20–≥': 'üç¨ –î–æ–ø. –∏–Ω–≥—Ä–µ–¥–∏–µ–Ω—Ç—ã', 
        '–º—ë–¥ 50–≥': 'üç¨ –î–æ–ø. –∏–Ω–≥—Ä–µ–¥–∏–µ–Ω—Ç—ã', '–Ω–∞–ø–∏—Ç–æ–∫ –≥–∞–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π 0,33': 'ü•§ –°—Ç–µ–∫–ª–æ/–ë–∞–Ω–∫–∞ –ë/–ê', '–Ω–∞–ø–∏—Ç–æ–∫ –≥–∞–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π 0,5': 'ü•§ –°—Ç–µ–∫–ª–æ/–ë–∞–Ω–∫–∞ –ë/–ê', 
        '–Ω–∞–ø–∏—Ç–æ–∫ –≥–∞–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ä–æ–∑–ª–∏–≤ 250 –º–ª': 'üö∞ –†–æ–∑–ª–∏–≤ –ë/–ê', '–Ω–∞–ø–∏—Ç–æ–∫ –∏–∑ —Å–∏—Ä–æ–ø–∞ –±–∏–± (–∫—Ñ—Å)': 'üö∞ –†–æ–∑–ª–∏–≤ –ë/–ê', '–Ω–µ–≥—Ä–æ–Ω–∏': 'üçπ –ö–æ–∫—Ç–µ–π–ª–∏', 
        '–Ω–∫ –∫–ª—É–±–Ω–∏–∫–∞ –±–∞–∑–∏–ª–∏–∫ 40 –º–ª': 'üçí –õ–∏–∫–µ—Ä/–ù–∞—Å—Ç–æ–π–∫–∞', '–Ω–∫ –∫–æ–∫–æ—Å 40 –º–ª': 'üçí –õ–∏–∫–µ—Ä/–ù–∞—Å—Ç–æ–π–∫–∞', '–Ω–∫ —Å–ª–∏–≤–æ—á–Ω–∞—è –ª–∏–º–æ–Ω—á–µ–ª–ª–æ 40 –º–ª': 'üçí –õ–∏–∫–µ—Ä/–ù–∞—Å—Ç–æ–π–∫–∞', 
        '–Ω–∫ —á–µ—Ä–µ—à–Ω—è 40 –º–ª': 'üçí –õ–∏–∫–µ—Ä/–ù–∞—Å—Ç–æ–π–∫–∞', '–Ω–∫ —â–∞–≤–µ–ª–∏–≤–∞—è 40 –º–ª': 'üçí –õ–∏–∫–µ—Ä/–ù–∞—Å—Ç–æ–π–∫–∞', '–Ω–∫\xa0 —Ñ–µ–π—Ö–æ–∞ –º—è—Ç–∞ 40 –º–ª': 'üçí –õ–∏–∫–µ—Ä/–ù–∞—Å—Ç–æ–π–∫–∞', 
        '–æ–±–ª–µ–ø–∏—Ö–æ–≤—ã–π —á–∞–π —Å –∏–º–±–∏—Ä—ë–º': 'üçµ –ß–∞–π', '–æ–±–Ω–∏–º–∞—à–∫–∏': 'üçπ –ö–æ–∫—Ç–µ–π–ª–∏', '–æ–∫—Ä–æ–≤–∞–≤–ª–µ–Ω–Ω–∞—è –º–µ—Ä—Ä–∏': 'üçπ –ö–æ–∫—Ç–µ–π–ª–∏', '–æ–Ω–µ–≥–∏–Ω 40 –º–ª': 'üíß –í–æ–¥–∫–∞', 
        '–ø–∏–Ω–æ –∫–æ–ª–∞–¥–∞ –±/–∞': 'üßâ –ö–æ–∫—Ç–µ–π–ª—å –ë/–ê', '–ø–∏–Ω—å—è –∫–æ–ª–∞–¥–∞': 'üçπ –ö–æ–∫—Ç–µ–π–ª–∏', '–ø–ª—è–∂ –ª–æ–Ω–≥ –∞–π–ª–µ–Ω–¥–∞': 'üçπ –ö–æ–∫—Ç–µ–π–ª–∏', 
        '–ø—Ä–æ—Å–µ–∫–∫–æ —à–∞—Ä–¥–æ–Ω–µ 125–º–ª': 'üç∑ –í–∏–Ω–æ', '–ø—Ñ–µ—Ñ—Ñ–µ—Ä–µ—Ä 125–º–ª': 'üç∑ –í–∏–Ω–æ', '—Ä–∞—á–∞': 'üçπ –ö–æ–∫—Ç–µ–π–ª–∏', '—Ä–µ–¥ –±—É–ª - –≤–∏—Å–∫–∏': 'üçπ –ö–æ–∫—Ç–µ–π–ª–∏', 
        '—Ä–µ–¥ –±—É–ª–ª - –≤–æ–¥–∫–∞': 'ü•§ –°—Ç–µ–∫–ª–æ/–ë–∞–Ω–∫–∞ –ë/–ê', '—Ä–µ–¥ –±—É–ª–ª 0,25': 'ü•§ –°—Ç–µ–∫–ª–æ/–ë–∞–Ω–∫–∞ –ë/–ê', '—Ä–æ–º –∫–æ–ª–∞': 'üçπ –ö–æ–∫—Ç–µ–π–ª–∏', 
        '—Å–≤–µ—Ç–ª–æ–µ 500–º–ª –±—É—Ä': 'üç∫ –ü–∏–≤–æ –†–æ–∑–ª–∏–≤', '—Å–∏–¥—Ä –≤–ø –ø—É–∞—Ä–µ, 0,33–ª': 'üçè –°–∏–¥—Ä –®–¢', '—Å–∏–¥—Ä —á–µ—Å—Ç–µ—Ä—Å –≤–∏—à–Ω—è, 0,5': 'üçè –°–∏–¥—Ä –®–¢', 
        '—Å–∏–¥—Ä —á–µ—Å—Ç–µ—Ä—Å –ª–µ—Å–Ω. —è–≥–æ–¥—ã, 0,5': 'üçè –°–∏–¥—Ä –®–¢', '—Å–∏–¥—Ä —á–µ—Å—Ç–µ—Ä—Å –ø–µ—Ä—Å–∏–∫-–∞–±—Ä–∏–∫–æ—Å, 0,45': 'üçè –°–∏–¥—Ä –®–¢', '—Å–∏–¥—Ä —á–µ—Å—Ç–µ—Ä—Å —è–±–ª–æ–∫–æ, 0,5': 'üçè –°–∏–¥—Ä –®–¢', 
        '—Å–∏—Ä–æ–ø 50–º–ª': 'üç¨ –î–æ–ø. –∏–Ω–≥—Ä–µ–¥–∏–µ–Ω—Ç—ã', '—Å–ª–∏–≤–∫–∏ 50–º–ª': 'üç¨ –î–æ–ø. –∏–Ω–≥—Ä–µ–¥–∏–µ–Ω—Ç—ã', '—Å–º—É–∑–∏ –µ–∂–µ–≤–∏—á–Ω—ã–π': 'üçì –ú–∏–ª–∫/–§—Ä–µ—à/–°–º—É–∑–∏', 
        '—Å–º—É–∑–∏ –∫–ª—É–±–Ω–∏—á–Ω–æ-–±–∞–Ω–∞–Ω–æ–≤—ã–π': 'üçì –ú–∏–ª–∫/–§—Ä–µ—à/–°–º—É–∑–∏', '—Å–æ–∫ rich —Å—Ç–µ–∫–ª–æ 0,2–ª, —à—Ç': 'ü•§ –°—Ç–µ–∫–ª–æ/–ë–∞–Ω–∫–∞ –ë/–ê', '—Å–æ–∫ –≤ –∞—Å—Å. 250–º–ª': 'üö∞ –†–æ–∑–ª–∏–≤ –ë/–ê', 
        '—Å—ç—Ç –¥–æ –µ–¥—ã': 'üçπ –ö–æ–∫—Ç–µ–π–ª–∏', '—Å—ç—Ç —É–±–∏–π—Ü—ã': 'üçπ –ö–æ–∫—Ç–µ–π–ª–∏', '—Ç–µ–∫–∏–ª–∞ —Å–∞–Ω—Ä–∞–π–∑': 'üåµ –¢–µ–∫–∏–ª–∞', '—Ç–∏–Ω–∏ 750–º–ª': 'üç∑ –í–∏–Ω–æ', 
        '—Ç–æ–º –∫–æ–ª–ª–∏–Ω–∑': 'üçπ –ö–æ–∫—Ç–µ–π–ª–∏', '—Ç–æ–Ω–∏–∫ 0,33': 'ü•§ –°—Ç–µ–∫–ª–æ/–ë–∞–Ω–∫–∞ –ë/–ê', '—Ç–æ—Ä—Ä–µ—Å 10 –ª–µ—Ç 40–º–ª': 'üçá –ö–æ–Ω—å—è–∫/–ë—Ä–µ–Ω–¥–∏', '—Ñ–ª—ç—Ç —É–∞–π—Ç': '‚òï –ö–æ—Ñ–µ', 
        '—Ñ—Ä–µ—Å–∫–µ–ª–ª–æ–≤ –∞—Å—Å 125–º–ª': 'üç∑ –í–∏–Ω–æ', '—Ñ—Ä–µ—à –∞–ø–µ–ª—å—Å–∏–Ω–æ–≤—ã–π 100 –º–ª –¥–ª—è –∫–æ–º–±–æ —Å —è–±–ª–æ—á–Ω—ã–º': 'üçì –ú–∏–ª–∫/–§—Ä–µ—à/–°–º—É–∑–∏', 
        '—Ñ—Ä–µ—à –∞–ø–µ–ª—å—Å–∏–Ω–æ–≤—ã–π 200 –º–ª': 'üçì –ú–∏–ª–∫/–§—Ä–µ—à/–°–º—É–∑–∏', '—Ñ—Ä—É–∫—Ç–æ–≤—ã–π —Ñ–∏–∑': 'üçπ –ö–æ–∫—Ç–µ–π–ª–∏', '—Ö–∞–Ω—Å –±–∞–µ—Ä —Ä–∏—Å–ª–∏–Ω–≥ 125–º–ª': 'üç∑ –í–∏–Ω–æ', 
        '—Ö–∞–Ω—Å –±–∞–µ—Ä —Ä–∏—Å–ª–∏–Ω–≥ 750–º–ª': 'üç∑ –í–∏–Ω–æ', '—Ö–∞—Å–∫–∏ 40–º–ª': 'üíß –í–æ–¥–∫–∞', '—Ö–∞—Å–∫–∏ –±–µ—Ä—Ä–∏ –º–∏–∫—Å 40–º–ª': 'üíß –í–æ–¥–∫–∞', '—Ö—Ö—Ö—á–∞–π –µ–∂–µ–≤–∏–∫–∞ –º–∏–Ω–¥–∞–ª—å': 'üçµ –ß–∞–π', 
        '—á–∞–π 800 –º–ª': 'üçµ –ß–∞–π', '—á–∞–π –∞–∫—Ü–∏—è, –ø–æ—Ä—Ü': 'üçµ –ß–∞–π', '—á–∞–π –±–∞—Ä–¥–∞–∫ –±–µ—Ä–≥–∞–º–æ—Ç–∞': 'üçµ –ß–∞–π', '—á–∞–π –±—Ä—É—Å–Ω–∏—á–Ω—ã–π': 'üçµ –ß–∞–π', 
        '—á–∞–π –¥–∞ —Ö—É–Ω –ø–∞–æ 400 –º–ª': 'üçµ –ß–∞–π', '—á–∞–π –µ–∂–µ–≤–∏–∫–∞ –º–∏–Ω–¥–∞–ª—å_': 'üçµ –ß–∞–π', '—á–∞–π –∏–≤–∞–Ω —á–∞–π —Å –º–∞–ª–∏–Ω–æ–π –∏ —Ç—Ä–∞–≤–∞–º–∏': 'üçµ –ß–∞–π', 
        '—á–∞–π –∏–º–±–∏—Ä–Ω—ã–π 200': 'üçµ –ß–∞–π', '—á–∞–π –∏–º–±–∏—Ä–Ω—ã–π 400': 'üçµ –ß–∞–π', '—á–∞–π –º–∞–Ω–¥–∞—Ä–∏–Ω–æ–≤—ã–π 200': 'üçµ –ß–∞–π', '—á–∞–π –º–∞–Ω–¥–∞—Ä–∏–Ω–æ–≤—ã–π 400': 'üçµ –ß–∞–π', 
        '—á–∞–π –º–µ–¥–æ–≤–æ–µ —è–±–ª–æ–∫–æ': 'üçµ –ß–∞–π', '—á–∞–π –æ–±–ª–µ–ø–∏—Ö–æ–≤—ã–π 200': 'üçµ –ß–∞–π', '—á–∞–π –æ–±–ª–µ–ø–∏—Ö–æ–≤—ã–π 400': 'üçµ –ß–∞–π', '—á–∞–π –ø–∞–∫–µ—Ç–∏—Ä–æ–≤–∞–Ω—ã–π –±—É—Ä, –ø–æ—Ä—Ü–∏—è': 'üçµ –ß–∞–π', 
        '—á–∞–π —Ä–æ–∑–º–∞—Ä–∏–Ω 200': 'üçµ –ß–∞–π', '—á–∞–π —Ä–æ–∑–º–∞—Ä–∏–Ω 400': 'üçµ –ß–∞–π', '—á–∞–π —Ç–µ–≥—É–∞–Ω—å –∏–Ω—å 400 –º–ª': 'üçµ –ß–∞–π', '—á–∏–≤–∞—Å —Ä–∏–≥–∞–ª 12 –ª–µ—Ç 40–º–ª': 'ü•É –í–∏—Å–∫–∏', 
        '—á–∏—Å—Ç—ã–µ —Ä–æ—Å—ã 40 –º–ª': 'üíß –í–æ–¥–∫–∞', '—à–∞—Ç–æ —Ç–∞–º–∞–Ω—å —Å–µ–ª–µ–∫—Ç –±–ª–∞–Ω 125–º–ª': 'üç∑ –í–∏–Ω–æ', '—ç—Å–ø–æ–ª–æ–Ω –±–ª–∞–Ω–∫–æ 40–º–ª': 'üåµ –¢–µ–∫–∏–ª–∞', '—è—â–µ—Ä–∏—Ü–∞ –ª–æ–Ω–≥ –∞–π–ª–µ–Ω–¥–∞': 'üçπ –ö–æ–∫—Ç–µ–π–ª–∏'
    }
    if name in manual_dict: return manual_dict[name]

    # –†–ï–ó–ï–†–í–ù–´–ô –ü–û–ò–°–ö
    food_keywords = ['–±—É—Ä–≥–µ—Ä', '—Å—É–ø', '—Å–∞–ª–∞—Ç', '—Ñ—Ä–∏', '—Å—ã—Ä', '–º—è—Å–æ', '—Å—Ç–µ–π–∫', '—Ö–ª–µ–±', '—Å–æ—É—Å', '–∫–∞—Ä—Ç–æ—Ñ–µ–ª—å', '–≥—Ä–µ–Ω–∫–∏', '–∫—Ä—ã–ª—å—è', '–∫—Ä–µ–≤–µ—Ç–∫–∏', '–ø–∞—Å—Ç–∞', '—Å—É—Ö–∞—Ä–∏–∫–∏', '—Å—ç–Ω–¥–≤–∏—á', '–¥–æ–±–∞–≤–∫–∞', '–¥–µ—Å–µ—Ä—Ç', '–º–æ—Ä–æ–∂–µ–Ω–æ–µ', '—á–∏–∑–∫–µ–π–∫', '–Ω–∞—á–æ—Å', '–∫–µ—Å–∞–¥–∏–ª—å—è']
    if any(w in name for w in food_keywords): return 'üçî –ï–¥–∞ (–ö—É—Ö–Ω—è)'

    extra_keywords = ['—Å–∏—Ä–æ–ø', '–¥–æ–ø.', '—Å–ª–∏–≤–∫–∏', '–º–æ–ª–æ–∫–æ 50', '–ª–∏–º–æ–Ω 20', '–ª–∞–π–º 20', '–º—è—Ç–∞ 20', '–∞–ø–µ–ª—å—Å–∏–Ω 20', '–º—ë–¥']
    if any(w in name for w in extra_keywords): return 'üç¨ –î–æ–ø. –∏–Ω–≥—Ä–µ–¥–∏–µ–Ω—Ç—ã'

    if any(w in name for w in ['–∫–æ—Ñ–µ', '–∫–∞–ø—É—á–∏–Ω–æ', '–ª–∞—Ç—Ç–µ', '—ç—Å–ø—Ä–µ—Å—Å–æ', '–∞–º–µ—Ä–∏–∫–∞–Ω–æ', '—Ä–∞—Ñ', '—Ñ–ª—ç—Ç —É–∞–π—Ç']): return '‚òï –ö–æ—Ñ–µ'
    if any(w in name for w in ['—á–∞–π', '—Å–µ–Ω—á–∞', '–ø—É—ç—Ä', '—ç—Ä–ª –≥—Ä–µ–π']): return 'üçµ –ß–∞–π'
    if any(w in name for w in ['—Å–º—É–∑–∏', '–º–∏–ª–∫', '—à–µ–π–∫', '—Ñ—Ä–µ—à']): return 'üçì –ú–∏–ª–∫/–§—Ä–µ—à/–°–º—É–∑–∏'
    if '–±/–∞' in name and any(w in name for w in ['–º–æ—Ö–∏—Ç–æ', '–ø–∏–Ω–∞', '–≥–ª–∏–Ω—Ç–≤–µ–π–Ω', '–∫–æ–∫—Ç–µ–π–ª—å']): return 'üßâ –ö–æ–∫—Ç–µ–π–ª—å –ë/–ê'
    if any(w in name for w in ['–º–æ—Ä—Å', '–ª–∏–º–æ–Ω–∞–¥', '–Ω–∞–ø–∏—Ç–æ–∫']): 
        if not any(b in name for b in ['—á–µ—Ä–Ω–æ–≥–æ–ª–æ–≤–∫–∞', '–Ω–∞—Ç–∞—Ö—Ç–∞—Ä–∏']): return 'üö∞ –†–æ–∑–ª–∏–≤ –ë/–ê'
    if any(w in name for w in ['cola', '—Ç–æ–Ω–∏–∫', 'red bull', 'rich', '–≤–æ–¥–∞', 'water', '–∫–æ–ª–∞']): return 'ü•§ –°—Ç–µ–∫–ª–æ/–ë–∞–Ω–∫–∞ –ë/–ê'

    if '—Å–∏–¥—Ä' in name: return 'üçè –°–∏–¥—Ä –®–¢'
    if any(w in name for w in ['corona', 'clausthaler']) or ('–ø–∏–≤–æ' in name and '—à—Ç' in name): return 'üçæ –ü–∏–≤–æ –®–¢'
    if any(w in name for w in ['–ø–∏–≤–æ', 'beer', 'ale', 'lager', 'stout', '—Å–≤–µ—Ç–ª–æ–µ', '—Ç–µ–º–Ω–æ–µ']): return 'üç∫ –ü–∏–≤–æ –†–æ–∑–ª–∏–≤'
    if any(w in name for w in ['–≤–∏—Å–∫–∏', 'jameson', 'jack', 'jim beam', 'macallan']): return 'ü•É –í–∏—Å–∫–∏'
    if any(w in name for w in ['–≤–æ–¥–∫–∞', '–±–µ–ª—É–≥–∞', '—Ö–∞—Å–∫–∏', '–æ–Ω–µ–≥–∏–Ω', 'finlandia']): return 'üíß –í–æ–¥–∫–∞'
    if any(w in name for w in ['—Ä–æ–º', 'bacardi', 'morgan', 'havana']): return 'üè¥‚Äç‚ò†Ô∏è –†–æ–º'
    if any(w in name for w in ['—Ç–µ–∫–∏–ª–∞', 'olmeca', 'espolon']): return 'üåµ –¢–µ–∫–∏–ª–∞'
    if any(w in name for w in ['–¥–∂–∏–Ω', 'beefeater', 'gordon', 'bombay']): return 'üå≤ –î–∂–∏–Ω'
    if any(w in name for w in ['–∫–æ–Ω—å—è–∫', '–∞—Ä–∞—Ä–∞—Ç', 'hennessy']): return 'üçá –ö–æ–Ω—å—è–∫/–ë—Ä–µ–Ω–¥–∏'
    if any(w in name for w in ['–ª–∏–∫–µ—Ä', '–Ω–∞—Å—Ç–æ–π–∫–∞', '–µ–≥–µ—Ä—å', 'baileys', '–∞–ø–µ—Ä–æ–ª—å', '—Å–∞–º–±—É–∫–∞']): return 'üçí –õ–∏–∫–µ—Ä/–ù–∞—Å—Ç–æ–π–∫–∞'
    if any(w in name for w in ['–≤–∏–Ω–æ', 'wine', '–±—Ä—é—Ç', '–ø—Ä–æ—Å–µ–∫–∫–æ', '—à–∞—Ä–¥–æ–Ω–µ']): return 'üç∑ –í–∏–Ω–æ'
    if any(w in name for w in ['–∫–æ–∫—Ç–µ–π–ª—å', '—à–æ—Ç', '–ª–æ–Ω–≥', '–¥–∞–π–∫–∏—Ä–∏', '–º–∞—Ä–≥–∞—Ä–∏—Ç–∞']): return 'üçπ –ö–æ–∫—Ç–µ–π–ª–∏'

    return 'üì¶ –ü—Ä–æ—á–µ–µ'

# --- CORE PARSING ---
def process_single_file(file_content, filename=""):
    """
    Parses a single Excel/CSV file into a DataFrame.
    Returns: (DataFrame, error_message, warnings, dropped_stats)
    dropped_stats is a dict: {'count': int, 'cost': float, 'items': list}
    """
    warnings = []
    dropped_stats = {'count': 0, 'cost': 0.0, 'items': []}
    
    try:
        # 1. READ RAW (Snippet for header detection)
        if isinstance(file_content, BytesIO):
             file_content.seek(0)
             content_for_preview = BytesIO(file_content.read())
             file_content.seek(0) # Reset main pointer
        else:
             # If it's a file path, read bytes
             with open(file_content, 'rb') as f:
                 raw_bytes = f.read()
             file_content = BytesIO(raw_bytes)
             content_for_preview = BytesIO(raw_bytes)

        try:
            df_raw = pd.read_csv(content_for_preview, header=None, nrows=20, sep=None, engine='python')
        except:
            content_for_preview.seek(0)
            df_raw = pd.read_excel(content_for_preview, header=None, nrows=20)

        # 2. DETECT DATE
        header_text = " ".join(df_raw.iloc[0:10, 0].astype(str).tolist())
        report_date = parse_russian_date(header_text)

        if not report_date:
            month_map = {'jan': '—è–Ω–≤–∞—Ä—è', 'feb': '—Ñ–µ–≤—Ä–∞–ª—è', 'mar': '–º–∞—Ä—Ç–∞', 'apr': '–∞–ø—Ä–µ–ª—è', 'may': '–º–∞—è', 'jun': '–∏—é–Ω—è', 'jul': '–∏—é–ª—è', 'aug': '–∞–≤–≥—É—Å—Ç–∞', 'sep': '—Å–µ–Ω—Ç—è–±—Ä—è', 'oct': '–æ–∫—Ç—è–±—Ä—è', 'nov': '–Ω–æ—è–±—Ä—è', 'dec': '–¥–µ–∫–∞–±—Ä—è'}
            for eng, rus in month_map.items():
                if eng in filename.lower():
                    d_match = re.search(r'(\d{1,2})', filename)
                    if d_match:
                        # Try to find year in filename
                        y_match = re.search(r'(20\d{2})', filename)
                        current_year = int(y_match.group(1)) if y_match else datetime.now().year
                        
                        report_date = datetime(current_year, RUS_MONTHS[rus], int(d_match.group(1)))
                        break
        
        if not report_date:
            warnings.append(f"–î–∞—Ç–∞ –æ—Ç—á–µ—Ç–∞ –Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∞: {filename}")
            return None, "–ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –¥–∞—Ç—É –æ—Ç—á–µ—Ç–∞", warnings, dropped_stats

        # 3. LOCATE HEADER ROW
        header_row = detect_header_row(df_raw, "–í—ã—Ä—É—á–∫–∞ —Å –ù–î–°")
        if header_row is None:
            warnings.append(f"–ó–∞–≥–æ–ª–æ–≤–æ–∫ –Ω–µ –Ω–∞–π–¥–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Å—Ç—Ä–æ–∫–∞ 6: {filename}")
            header_row = 5

        # 4. READ FULL DATAFRAME
        file_content.seek(0)
        try:
            df = pd.read_csv(file_content, header=header_row, sep=None, engine='python')
        except:
            file_content.seek(0)
            df = pd.read_excel(file_content, header=header_row)

        df.columns = df.columns.astype(str).str.strip()
        
        # VALIDATE COLUMNS
        required_cols = ['–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ', '–°–µ–±–µ—Å—Ç–æ–∏–º–æ—Å—Ç—å', '–í—ã—Ä—É—á–∫–∞ —Å –ù–î–°']
        missing_cols = [col for col in required_cols if col not in df.columns]
        if missing_cols:
            return None, f"–ù–µ –Ω–∞–π–¥–µ–Ω—ã –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏: {', '.join(missing_cols)}", warnings, dropped_stats

        # 5. CLEAN & CONVERT NUMBERS
        cols_to_num = ['–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ', '–°–µ–±–µ—Å—Ç–æ–∏–º–æ—Å—Ç—å', '–í—ã—Ä—É—á–∫–∞ —Å –ù–î–°']
        for col in cols_to_num:
            if col in df.columns:
                # Keep original for debug before conversion? No, convert first
                df[col] = df[col].astype(str).str.replace(r'\s+', '', regex=True).str.replace(',', '.')
                df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)

        col_name = df.columns[0] # Usually "–ù–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä–∞" or "–ë–ª—é–¥–æ"
        
        # 6. HANDLE MULTI-DAY FILES (Date markers inside first column)
        # Example marker: "01.01.2025 17:00:00" followed by item rows.
        first_col_raw = df[col_name].astype(str).str.strip()
        date_tokens = first_col_raw.str.extract(r'(?P<d>\d{2}\.\d{2}\.\d{4})', expand=True)['d']
        row_dates = pd.to_datetime(date_tokens, format='%d.%m.%Y', errors='coerce')
        unique_row_dates = row_dates.dropna().dt.normalize().nunique()

        if unique_row_dates > 1:
            df['–î–∞—Ç–∞_–û—Ç—á–µ—Ç–∞'] = row_dates.dt.normalize().ffill()
            # Rows containing date markers are structural rows, exclude from item lines.
            df = df[row_dates.isna()].copy()
            # Keep only rows that have a resolved day after forward fill.
            df = df[df['–î–∞—Ç–∞_–û—Ç—á–µ—Ç–∞'].notna()].copy()
        else:
            df['–î–∞—Ç–∞_–û—Ç—á–µ—Ç–∞'] = report_date

        # 7. CAPTURE DROPPED ROWS (DEBUG)
        # Identify rows that would be dropped
        # A. Empty Identifiers
        # B. Ignore Names
        # C. "–ò—Ç–æ–≥–æ" rows
        
        # We need to compute 'dropped' before we actually drop them to sum their metrics
        
        # Normalized Identifier
        df['norm_name'] = df[col_name].astype(str).str.strip()
        
        # Filter Masks
        mask_valid_name = df[col_name].notna()
        mask_not_ignore = ~df['norm_name'].isin(IGNORE_NAMES)
        mask_not_total = ~df['norm_name'].str.contains("–ò—Ç–æ–≥–æ", case=False)
        
        mask_keep = mask_valid_name & mask_not_ignore & mask_not_total
        
        # Extract Dropped Data
        df_dropped = df[~mask_keep].copy()
        if not df_dropped.empty:
            dropped_stats['count'] = len(df_dropped)
            if '–°–µ–±–µ—Å—Ç–æ–∏–º–æ—Å—Ç—å' in df_dropped.columns:
                dropped_stats['cost'] = df_dropped['–°–µ–±–µ—Å—Ç–æ–∏–º–æ—Å—Ç—å'].sum()
            
            # Save top 50 dropped items for review
            items_list = df_dropped[['norm_name', '–°–µ–±–µ—Å—Ç–æ–∏–º–æ—Å—Ç—å']].to_dict('records')
            dropped_stats['items'] = items_list

        # Apply Filter
        df = df[mask_keep].copy()
        
        # 8. ENRICH DATA
        df['Unit_Cost'] = np.where(df['–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ'] != 0, df['–°–µ–±–µ—Å—Ç–æ–∏–º–æ—Å—Ç—å'] / df['–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ'], 0)
        df['–§—É–¥–∫–æ—Å—Ç'] = np.where(df['–í—ã—Ä—É—á–∫–∞ —Å –ù–î–°'] > 0, (df['–°–µ–±–µ—Å—Ç–æ–∏–º–æ—Å—Ç—å'] / df['–í—ã—Ä—É—á–∫–∞ —Å –ù–î–°'] * 100), 0)
        df = df.rename(columns={col_name: '–ë–ª—é–¥–æ'})
        
        # Load mapping once per file (or rely on cache)
        cat_mapping = category_service.load_categories()
        df['–ö–∞—Ç–µ–≥–æ—Ä–∏—è'] = df['–ë–ª—é–¥–æ'].apply(lambda x: detect_category_granular(x, cat_mapping))
        df['–ú–∞–∫—Ä–æ_–ö–∞—Ç–µ–≥–æ—Ä–∏—è'] = df['–ö–∞—Ç–µ–≥–æ—Ä–∏—è'].apply(get_macro_category)
        
        # Helper for vendor
        if '–ü–æ—Å—Ç–∞–≤—â–∏–∫' in df.columns:
            df['–ü–æ—Å—Ç–∞–≤—â–∏–∫'] = df['–ü–æ—Å—Ç–∞–≤—â–∏–∫'].fillna('–ù–µ —É–∫–∞–∑–∞–Ω')
        else:
            df['–ü–æ—Å—Ç–∞–≤—â–∏–∫'] = '–ù–µ —É–∫–∞–∑–∞–Ω'

        return df, None, warnings, dropped_stats

    except Exception as exc:
        return None, f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {exc}", warnings, dropped_stats

# --- ANALYTICS ---
def calculate_insights(df_curr, df_prev, cur_rev, prev_rev, cur_fc):
    """
    Calculates business insights/alerts based on current and previous data.
    Returns a list of dicts: {'type': str, 'message': str, 'level': str}
    Levels: 'success', 'warning', 'error', 'info'
    """
    insights = []
    
    # 1. Revenue Check
    if prev_rev > 0:
        rev_diff_pct = (cur_rev - prev_rev) / prev_rev * 100
        if rev_diff_pct < -10:
            insights.append({
                'type': 'rev_drop',
                'message': f"üìâ **–¢—Ä–µ–≤–æ–≥–∞ –ø–æ –í—ã—Ä—É—á–∫–µ**: –ü–∞–¥–µ–Ω–∏–µ –Ω–∞ {abs(rev_diff_pct):.1f}% –ø–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—é —Å –ø—Ä–æ—à–ª—ã–º –ø–µ—Ä–∏–æ–¥–æ–º.",
                'level': 'error'
            })
        elif rev_diff_pct > 20:
            insights.append({
                'type': 'rev_growth',
                'message': f"üöÄ **–û—Ç–ª–∏—á–Ω—ã–π —Ä–æ—Å—Ç**: –í—ã—Ä—É—á–∫–∞ –≤—ã—Ä–æ—Å–ª–∞ –Ω–∞ {rev_diff_pct:.1f}%!",
                'level': 'success'
            })

    # 2. Food Cost Check
    TARGET_FC = 35.0
    if cur_fc > TARGET_FC:
        insights.append({
            'type': 'high_fc',
            'message': f"‚ö†Ô∏è **–í—ã—Å–æ–∫–∏–π –§—É–¥-–∫–æ—Å—Ç**: –¢–µ–∫—É—â–∏–π {cur_fc:.1f}% (–¶–µ–ª—å: {TARGET_FC}%).",
            'level': 'warning'
        })
    
    # 3. Ingredient Inflation (Top Spike)
    if not df_prev.empty and 'Unit_Cost' in df_curr.columns and 'Unit_Cost' in df_prev.columns:
        # Compare average purchase prices
        curr_prices = df_curr.groupby('–ë–ª—é–¥–æ')['Unit_Cost'].mean()
        prev_prices = df_prev.groupby('–ë–ª—é–¥–æ')['Unit_Cost'].mean()
        
        safe_prev_prices = prev_prices.replace(0, np.nan)
        price_changes = (curr_prices - safe_prev_prices) / safe_prev_prices * 100
        price_changes = price_changes.replace([np.inf, -np.inf], np.nan).dropna().sort_values(ascending=False)
        
        if not price_changes.empty:
            top_inflator = price_changes.index[0]
            top_val = price_changes.iloc[0]
            if top_val > 15: # Raised/Spiked more than 15%
                insights.append({
                    'type': 'inflation',
                    'message': f"üí∏ **–°–∫–∞—á–æ–∫ —Ü–µ–Ω—ã**: {top_inflator} –ø–æ–¥–æ—Ä–æ–∂–∞–ª –Ω–∞ {top_val:.0f}%.",
                    'level': 'warning'
                })

    # 4. Dead Items ("Dogs")
    # Logic: Low Sales (< Avg) AND Low Margin (< Avg)
    if not df_curr.empty:
        item_stats = df_curr.groupby('–ë–ª—é–¥–æ').agg({'–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ': 'sum', '–í—ã—Ä—É—á–∫–∞ —Å –ù–î–°': 'sum', '–°–µ–±–µ—Å—Ç–æ–∏–º–æ—Å—Ç—å': 'sum'}).reset_index()
        item_stats['–ú–∞—Ä–∂–∞'] = item_stats['–í—ã—Ä—É—á–∫–∞ —Å –ù–î–°'] - item_stats['–°–µ–±–µ—Å—Ç–æ–∏–º–æ—Å—Ç—å']
        item_stats = item_stats[item_stats['–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ'] > 0]
        
        if not item_stats.empty:
            avg_qty = item_stats['–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ'].mean()
            avg_margin = item_stats['–ú–∞—Ä–∂–∞'].mean()
            
            dogs = item_stats[(item_stats['–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ'] < avg_qty * 0.5) & (item_stats['–ú–∞—Ä–∂–∞'] < avg_margin * 0.5)]
            if len(dogs) > 5:
                insights.append({
                    'type': 'dogs',
                    'message': f"üê∂ **–ú–µ—Ä—Ç–≤—ã–π –≥—Ä—É–∑**: –ù–∞–π–¥–µ–Ω–æ {len(dogs)} –ø–æ–∑–∏—Ü–∏–π '–°–æ–±–∞–∫' (–º–∞–ª–æ –ø—Ä–æ–¥–∞–∂, –º–∞–ª–æ –¥–µ–Ω–µ–≥).",
                    'level': 'info'
                })

    if not insights:
        insights.append({
            'type': 'all_good',
            'message': "‚úÖ **–í—Å—ë —Å–ø–æ–∫–æ–π–Ω–æ**: –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–π –Ω–µ –Ω–∞–π–¥–µ–Ω–æ.",
            'level': 'success'
        })

    return insights

def get_last_sync_meta():
    return LAST_SYNC_META


def download_and_process_yandex(yandex_token, yandex_path="RestoAnalytic"):
    if not yandex_token:
        return False, "–ù–µ –∑–∞–¥–∞–Ω —Ç–æ–∫–µ–Ω –Ø–Ω–¥–µ–∫—Å.–î–∏—Å–∫–∞."

    headers = {"Authorization": f"OAuth {yandex_token}"}
    api_url = "https://cloud-api.yandex.net/v1/disk/resources"
    data_frames = []
    dropped_total = {"count": 0, "cost": 0.0}
    dropped_items = []
    warnings_total = []

    def list_items(path, limit=1000):
        items = []
        offset = 0
        while True:
            resp = requests.get(
                api_url,
                headers=headers,
                params={"path": path, "limit": limit, "offset": offset},
                timeout=20,
            )
            if resp.status_code != 200:
                return None
            page = resp.json().get("_embedded", {}).get("items", [])
            if not page:
                break
            items.extend(page)
            if len(page) < limit:
                break
            offset += limit
        return items

    def get_files_recursive(path):
        items = list_items(path)
        if items is None:
            return []
        files = [i for i in items if i.get("type") == "file"]
        dirs = [i for i in items if i.get("type") == "dir"]
        result = [f for f in files if str(f.get("name", "")).lower().endswith((".xlsx", ".csv"))]
        for d in dirs:
            result.extend(get_files_recursive(d.get("path")))
        return result

    def process_remote_file(file_meta, venue):
        file_url = file_meta.get("file")
        filename = file_meta.get("name", "")
        if not file_url:
            return
        resp = requests.get(file_url, headers=headers, timeout=30)
        if resp.status_code != 200:
            warnings_total.append(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–∫–∞—á–∞—Ç—å: {filename}")
            return
        df, err, warns, dropped = process_single_file(BytesIO(resp.content), filename=filename)
        warnings_total.extend(warns)
        dropped_total["count"] += dropped.get("count", 0)
        dropped_total["cost"] += float(dropped.get("cost", 0.0))
        dropped_items.extend(dropped.get("items", []))
        if err:
            warnings_total.append(f"{filename}: {err}")
            return
        if df is not None and not df.empty:
            df["–¢–æ—á–∫–∞"] = venue
            data_frames.append(df)

    try:
        root_items = list_items(yandex_path)
        if root_items is None:
            return False, "–û—à–∏–±–∫–∞ –¥–æ—Å—Ç—É–ø–∞ –∫ –ø–∞–ø–∫–µ –Ω–∞ –Ø–Ω–¥–µ–∫—Å.–î–∏—Å–∫–µ."
        root_files = [
            i for i in root_items
            if i.get("type") == "file" and str(i.get("name", "")).lower().endswith((".xlsx", ".csv"))
        ]
        subfolders = [i for i in root_items if i.get("type") == "dir"]

        for f in root_files:
            process_remote_file(f, "Mesto")
        for folder in subfolders:
            venue = folder.get("name", "Unknown")
            for f in get_files_recursive(folder.get("path")):
                process_remote_file(f, venue)

        if not data_frames:
            return False, "–§–∞–π–ª—ã –Ω–∞–π–¥–µ–Ω—ã, –Ω–æ –¥–∞–Ω–Ω—ã–µ –Ω–µ –±—ã–ª–∏ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω—ã."

        full_df = pd.concat(data_frames, ignore_index=True)
        if "–î–∞—Ç–∞_–û—Ç—á–µ—Ç–∞" in full_df.columns:
            full_df["–î–∞—Ç–∞_–û—Ç—á–µ—Ç–∞"] = pd.to_datetime(full_df["–î–∞—Ç–∞_–û—Ç—á–µ—Ç–∞"], errors="coerce")
            full_df = full_df.dropna(subset=["–î–∞—Ç–∞_–û—Ç—á–µ—Ç–∞"]).sort_values("–î–∞—Ç–∞_–û—Ç—á–µ—Ç–∞")
        full_df.to_parquet(CACHE_FILE, index=False)

        dropped_df = pd.DataFrame(dropped_items)
        if not dropped_df.empty and "–°–µ–±–µ—Å—Ç–æ–∏–º–æ—Å—Ç—å" in dropped_df.columns:
            dropped_df = dropped_df.sort_values(by="–°–µ–±–µ—Å—Ç–æ–∏–º–æ—Å—Ç—å", ascending=False)
            dropped_top = dropped_df.head(50).to_dict("records")
        else:
            dropped_top = dropped_items[:50]

        LAST_SYNC_META["dropped_stats"] = {
            "count": int(dropped_total["count"]),
            "cost": float(dropped_total["cost"]),
            "items": dropped_top,
        }
        LAST_SYNC_META["warnings"] = warnings_total

        msg = f"–û–±–Ω–æ–≤–ª–µ–Ω–æ —Å—Ç—Ä–æ–∫: {len(full_df)}. –û—Ç–±—Ä–æ—à–µ–Ω–æ: {dropped_total['count']}."
        if warnings_total:
            msg += f" –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–π: {len(warnings_total)}."
        return True, msg
    except Exception as exc:
        LAST_SYNC_META["warnings"] = [str(exc)]
        return False, f"–û—à–∏–±–∫–∞ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏: {exc}"

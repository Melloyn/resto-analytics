import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
import logging
import ui
import telegram_utils
from io import BytesIO
from datetime import datetime, timedelta
import data_engine
from services import parsing_service
from services import analytics_service

logger = logging.getLogger(__name__)

# --- EXCEL EXPORT ---
@st.cache_data
def convert_df_to_excel(df, sort_mode, target_date_str):
    output = BytesIO()
    try:
        exp_df = df.copy()
        
        # Normalize
        if '–§—É–¥–∫–æ—Å—Ç' in exp_df.columns and '–ö–æ—Å—Ç %' not in exp_df.columns:
            exp_df['–ö–æ—Å—Ç %'] = exp_df['–§—É–¥–∫–æ—Å—Ç']
        if '–ö–æ—Å—Ç %' not in exp_df.columns:
             exp_df['–ö–æ—Å—Ç %'] = (exp_df['–°–µ–±–µ—Å—Ç–æ–∏–º–æ—Å—Ç—å'] / exp_df['–í—ã—Ä—É—á–∫–∞ —Å –ù–î–°'] * 100).fillna(0)
        
        # Sort
        if "–í—ã—Ä—É—á–∫–µ" in sort_mode:
            exp_df = exp_df.sort_values(by='–í—ã—Ä—É—á–∫–∞ —Å –ù–î–°', ascending=False)
            sort_col = '–í—ã—Ä—É—á–∫–∞'
            source_metric_col = '–í—ã—Ä—É—á–∫–∞ —Å –ù–î–°'
        elif "–§—É–¥-–∫–æ—Å—Ç—É" in sort_mode:
            exp_df = exp_df.sort_values(by='–ö–æ—Å—Ç %', ascending=False)
            sort_col = '–ö–æ—Å—Ç %'
            source_metric_col = '–ö–æ—Å—Ç %'
        elif "–ö–æ–ª–∏—á–µ—Å—Ç–≤—É" in sort_mode:
            exp_df = exp_df.sort_values(by='–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ', ascending=False)
            sort_col = '–ö–æ–ª-–≤–æ'
            source_metric_col = '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ'
        else:
            sort_col = '–í—ã—Ä—É—á–∫–∞'
            source_metric_col = '–í—ã—Ä—É—á–∫–∞ —Å –ù–î–°'
        
        # Map
        cols_map = {
            '–ë–ª—é–¥–æ': '–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ', 
            '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ': '–ö–æ–ª-–≤–æ', 
            '–°–µ–±–µ—Å—Ç–æ–∏–º–æ—Å—Ç—å': '–°–µ–±–µ—Å—Ç.', 
            '–í—ã—Ä—É—á–∫–∞ —Å –ù–î–°': '–í—ã—Ä—É—á–∫–∞', 
            '–ö–æ—Å—Ç %': '–ö–æ—Å—Ç %', 
            '–ö–∞—Ç–µ–≥–æ—Ä–∏—è': '–ö–∞—Ç–µ–≥–æ—Ä–∏—è',
            '–ú–∞–∫—Ä–æ_–ö–∞—Ç–µ–≥–æ—Ä–∏—è': '–ú–∞–∫—Ä–æ_–ö–∞—Ç–µ–≥–æ—Ä–∏—è'
        }
        available_cols = [c for c in cols_map.keys() if c in exp_df.columns]
        final_df = exp_df[available_cols].rename(columns=cols_map)
        if '–ö–æ—Å—Ç %' in final_df.columns:
            final_df['–ö–æ—Å—Ç %'] = final_df['–ö–æ—Å—Ç %'] / 100.0
        
        with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
            final_df.to_excel(writer, index=False, sheet_name='Report')
            workbook  = writer.book
            worksheet = writer.sheets['Report']
            
            # Formats
            fmt_header = workbook.add_format({'bold': True, 'bg_color': '#D3D3D3', 'border': 1, 'align': 'center', 'valign': 'vcenter'})
            fmt_money = workbook.add_format({'num_format': '#,##0 ‚ÇΩ'})
            fmt_pct = workbook.add_format({'num_format': '0.0%'}) 
            fmt_int = workbook.add_format({'num_format': '0'})

            for col_num, value in enumerate(final_df.columns.values):
                worksheet.write(0, col_num, value, fmt_header)
                
            for i, col in enumerate(final_df.columns):
                width = 15
                fmt = None
                if col in ['–í—ã—Ä—É—á–∫–∞', '–°–µ–±–µ—Å—Ç.']:
                    width = 18; fmt = fmt_money
                elif col == '–ö–æ—Å—Ç %':
                    width = 12; fmt = fmt_pct
                elif col == '–ö–æ–ª-–≤–æ':
                    width = 10; fmt = fmt_int
                elif col == '–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ':
                    width = 40
                worksheet.set_column(i, i, width, fmt)

            # Charts Sheet
            charts_sheet = workbook.add_worksheet('Charts')
            
            # 1. Top 10 Column
            chart_col = workbook.add_chart({'type': 'column'})
            max_row = min(10, len(final_df))
            try:
                val_idx = final_df.columns.get_loc(sort_col)
                chart_col.add_series({
                    'name':       ['Report', 0, val_idx],
                    'categories': ['Report', 1, 0, max_row, 0],
                    'values':     ['Report', 1, val_idx, max_row, val_idx],
                    'data_labels': {'value': True},
                })
                chart_col.set_title({'name': f'–¢–æ–ø-10: {sort_col}'})
                charts_sheet.insert_chart('B2', chart_col, {'x_scale': 2.5, 'y_scale': 2})
            except Exception as exc:
                logger.warning("Failed to build Top-10 chart: %s", exc)

            # 2. Pie (Micro)
            if '–ö–∞—Ç–µ–≥–æ—Ä–∏—è' in final_df.columns:
                try:
                    cat_df = final_df.groupby('–ö–∞—Ç–µ–≥–æ—Ä–∏—è')[sort_col].sum().reset_index().sort_values(by=sort_col, ascending=False)
                    charts_sheet.write(0, 14, '–ö–∞—Ç–µ–≥–æ—Ä–∏—è', fmt_header)
                    charts_sheet.write(0, 15, sort_col, fmt_header)
                    for r_idx, row in cat_df.iterrows():
                        charts_sheet.write(r_idx + 1, 14, row['–ö–∞—Ç–µ–≥–æ—Ä–∏—è'])
                        charts_sheet.write(r_idx + 1, 15, row[sort_col], fmt_money)
                    
                    chart_pie = workbook.add_chart({'type': 'pie'})
                    chart_pie.add_series({
                        'name': '–î–æ–ª–∏',
                        'categories': ['Charts', 1, 14, len(cat_df), 14],
                        'values': ['Charts', 1, 15, len(cat_df), 15],
                        'data_labels': {'percentage': True},
                    })
                    chart_pie.set_title({'name': f'–î–æ–ª–∏: {sort_col}'})
                    charts_sheet.insert_chart('J2', chart_pie, {'x_scale': 1.5, 'y_scale': 1.5})
                except Exception as exc:
                    logger.warning("Failed to build category pie chart: %s", exc)

            # 3. Donut (Macro)
            if '–ú–∞–∫—Ä–æ_–ö–∞—Ç–µ–≥–æ—Ä–∏—è' in exp_df.columns:
                try:
                    macro_df = (
                        exp_df.groupby('–ú–∞–∫—Ä–æ_–ö–∞—Ç–µ–≥–æ—Ä–∏—è')[source_metric_col]
                        .sum()
                        .reset_index()
                        .sort_values(by=source_metric_col, ascending=False)
                    )
                    charts_sheet.write(0, 17, '–ú–∞–∫—Ä–æ', fmt_header)
                    charts_sheet.write(0, 18, sort_col, fmt_header)
                    for r_idx, row in macro_df.iterrows():
                        charts_sheet.write(r_idx + 1, 17, row['–ú–∞–∫—Ä–æ_–ö–∞—Ç–µ–≥–æ—Ä–∏—è'])
                        charts_sheet.write(r_idx + 1, 18, row[source_metric_col], fmt_money)
                        
                    chart_donut = workbook.add_chart({'type': 'doughnut'})
                    chart_donut.add_series({
                        'name': '–°—Ç—Ä—É–∫—Ç—É—Ä–∞ (–ú–∞–∫—Ä–æ)',
                        'categories': ['Charts', 1, 17, len(macro_df), 17],
                        'values': ['Charts', 1, 18, len(macro_df), 18],
                        'data_labels': {'percentage': True},
                    })
                    chart_donut.set_title({'name': '–°—Ç—Ä—É–∫—Ç—É—Ä–∞ (–ú–∞–∫—Ä–æ)'})
                    chart_donut.set_rotation(90)
                    charts_sheet.insert_chart('B18', chart_donut, {'x_scale': 1.5, 'y_scale': 1.5})
                except Exception as exc:
                    logger.warning("Failed to build macro donut chart: %s", exc)
                
    except Exception as e:
        logger.exception("Excel export failed: %s", e)
        return None
    return output.getvalue()


# --- RENDERERS ---

def render_kpi(df_current, df_prev, period_title):
    cur_rev = df_current['–í—ã—Ä—É—á–∫–∞ —Å –ù–î–°'].sum()
    cur_cost = df_current['–°–µ–±–µ—Å—Ç–æ–∏–º–æ—Å—Ç—å'].sum()
    cur_fc = (cur_cost / cur_rev * 100) if cur_rev else 0
    cur_margin = cur_rev - cur_cost
    
    prev_rev = 0
    prev_fc = 0
    prev_margin = 0
    if not df_prev.empty:
        prev_rev = df_prev['–í—ã—Ä—É—á–∫–∞ —Å –ù–î–°'].sum()
        prev_cost = df_prev['–°–µ–±–µ—Å—Ç–æ–∏–º–æ—Å—Ç—å'].sum()
        prev_fc = (prev_cost / prev_rev * 100) if prev_rev else 0
        prev_margin = prev_rev - prev_cost
    
    st.write(f"### üìä –°–≤–æ–¥–∫–∞: {period_title}")
    
    c1, c2, c3, c4 = st.columns(4)
    c1.metric("üí∞ –í—ã—Ä—É—á–∫–∞", f"{cur_rev:,.0f} ‚ÇΩ", f"{cur_rev - prev_rev:+,.0f} ‚ÇΩ" if not df_prev.empty else None)
    c2.metric("üìâ –§—É–¥-–∫–æ—Å—Ç", f"{cur_fc:.1f} %", f"{cur_fc - prev_fc:+.1f} %" if not df_prev.empty else None, delta_color="inverse")
    c3.metric("üí≥ –ú–∞—Ä–∂–∞", f"{cur_margin:,.0f} ‚ÇΩ", f"{cur_margin - prev_margin:+,.0f} ‚ÇΩ" if not df_prev.empty else None)
    c4.metric("üßæ –ü–æ–∑–∏—Ü–∏–π", len(df_current))

def render_sidebar_export(df_current, df_full, tg_token, tg_chat, target_date):
    with st.sidebar.expander("‚ö° –î–µ–π—Å—Ç–≤–∏—è –∏ –≠–∫—Å–ø–æ—Ä—Ç", expanded=False):
        if st.button("üì§ –û—Ç—á–µ—Ç –≤ Telegram", use_container_width=True):
            if not tg_token or not tg_chat:
                st.error("‚ùå –ù–µ—Ç —Ç–æ–∫–µ–Ω–∞/—á–∞—Ç–∞!")
            elif df_current.empty:
                st.warning("‚ö†Ô∏è –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö.")
            else:
                with st.spinner("–§–æ—Ä–º–∏—Ä—É—é –æ—Ç—á–µ—Ç..."):
                    try:
                        report_text = telegram_utils.format_report(df_full, target_date)
                        success, msg = telegram_utils.send_to_all(tg_token, tg_chat, report_text)
                        if success: st.success("–û—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ!")
                        else: st.error(msg)
                    except Exception as e:
                        st.error(f"–û—à–∏–±–∫–∞: {e}")
        
        st.divider()
        
        if not df_current.empty:
            sort_opt = st.radio(
                "–°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ Excel:",
                ["üí∞ –ü–æ –í—ã—Ä—É—á–∫–µ", "üìâ –ü–æ –§—É–¥-–∫–æ—Å—Ç—É", "üì¶ –ü–æ –ö–æ–ª–∏—á–µ—Å—Ç–≤—É"],
                index=0
            )
            excel_data = convert_df_to_excel(df_current, sort_opt, str(target_date.date()))
            
            if excel_data:
                st.download_button(
                    label="üìä –°–∫–∞—á–∞—Ç—å Excel (+–ì—Ä–∞—Ñ–∏–∫–∏)",
                    data=excel_data,
                    file_name=f"report_{target_date.strftime('%d-%m-%Y')}.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                    use_container_width=True
                )
            else:
                st.error("–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ Excel")

def render_inflation(df_full, df_current, target_date, inflation_start_date=None):
    target_dt = pd.to_datetime(target_date)
    if inflation_start_date is not None:
        start_dt = pd.to_datetime(inflation_start_date)
        scope = df_full[(df_full['–î–∞—Ç–∞_–û—Ç—á–µ—Ç–∞'] >= start_dt) & (df_full['–î–∞—Ç–∞_–û—Ç—á–µ—Ç–∞'] <= target_dt)]
        if scope.empty or df_current.empty:
            loss, save, det = 0, 0, pd.DataFrame()
        else:
            old_prices = scope.sort_values('–î–∞—Ç–∞_–û—Ç—á–µ—Ç–∞').groupby('–ë–ª—é–¥–æ')['Unit_Cost'].first()
            current_prices = df_current.groupby('–ë–ª—é–¥–æ')['Unit_Cost'].mean()
            merged = pd.concat([old_prices, current_prices], axis=1, keys=['Old', 'New']).dropna()
            merged['Diff'] = merged['New'] - merged['Old']
            merged['Pct'] = (merged['Diff'] / merged['Old']) * 100
            merged = merged.replace([float('inf'), float('-inf')], pd.NA).dropna(subset=['Pct'])
            qty_map = df_current.groupby('–ë–ª—é–¥–æ')['–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ'].sum()
            merged['Qty'] = qty_map
            merged['Effect'] = merged['Diff'] * merged['Qty']
            loss = merged[merged['Effect'] > 0]['Effect'].sum()
            save = abs(merged[merged['Effect'] < 0]['Effect'].sum())
            det = merged[merged['Effect'] != 0].copy()
            det['–¢–æ–≤–∞—Ä'] = det.index
            det['–†–æ—Å—Ç %'] = det['Pct']
            det['–≠—Ñ—Ñ–µ–∫—Ç (‚ÇΩ)'] = det['Effect']
    else:
        loss, save, det = analytics_service.compute_inflation_metrics(df_full[df_full['–î–∞—Ç–∞_–û—Ç—á–µ—Ç–∞'] <= target_dt], df_current)
    col1, col2, col3 = st.columns(3)
    col1.metric("üî¥ –ü–æ—Ç–µ—Ä–∏", f"-{loss:,.0f} ‚ÇΩ")
    col2.metric("üü¢ –≠–∫–æ–Ω–æ–º–∏—è", f"+{save:,.0f} ‚ÇΩ")
    net = save - loss
    col3.metric("–ò—Ç–æ–≥", f"{net:+,.0f} ‚ÇΩ")
    
    if not det.empty:
        c1, c2 = st.columns(2)
        with c1:
            st.caption("–¢–æ–ø —Ä–æ—Å—Ç–∞ (–£–±—ã—Ç–æ–∫)")
            st.dataframe(det[det['–≠—Ñ—Ñ–µ–∫—Ç (‚ÇΩ)'] > 0].sort_values('–≠—Ñ—Ñ–µ–∫—Ç (‚ÇΩ)', ascending=False).head(20)[['–¢–æ–≤–∞—Ä', '–†–æ—Å—Ç %', '–≠—Ñ—Ñ–µ–∫—Ç (‚ÇΩ)']], use_container_width=True)
        with c2:
            st.caption("–¢–æ–ø –ø–∞–¥–µ–Ω–∏—è (–≠–∫–æ–Ω–æ–º–∏—è)")
            st.dataframe(det[det['–≠—Ñ—Ñ–µ–∫—Ç (‚ÇΩ)'] < 0].sort_values('–≠—Ñ—Ñ–µ–∫—Ç (‚ÇΩ)', ascending=True).head(20)[['–¢–æ–≤–∞—Ä', '–†–æ—Å—Ç %', '–≠—Ñ—Ñ–µ–∫—Ç (‚ÇΩ)']], use_container_width=True)

def render_dynamics(df_full, df_current):
    c1, c2 = st.columns([2, 1])
    with c1:
        st.write("### –î–∏–Ω–∞–º–∏–∫–∞ —Ü–µ–Ω—ã –∑–∞–∫—É–ø–∫–∏")
        all_items = sorted(df_full['–ë–ª—é–¥–æ'].unique())
        if all_items:
            sel = st.selectbox("–¢–æ–≤–∞—Ä:", all_items)
            trend = df_full[df_full['–ë–ª—é–¥–æ'] == sel].sort_values('–î–∞—Ç–∞_–û—Ç—á–µ—Ç–∞')
            fig = px.line(trend, x='–î–∞—Ç–∞_–û—Ç—á–µ—Ç–∞', y='Unit_Cost', title=f"–¶–µ–Ω–∞: {sel}", markers=True)
            st.plotly_chart(ui.update_chart_layout(fig), use_container_width=True)
    with c2:
        st.write("### –¢–æ–ø –ü–æ—Å—Ç–∞–≤—â–∏–∫–æ–≤")
        stats = analytics_service.compute_supplier_stats(df_current)
        if not stats.empty:
            fig = px.bar(stats, x='–°–µ–±–µ—Å—Ç–æ–∏–º–æ—Å—Ç—å', y='–ü–æ—Å—Ç–∞–≤—â–∏–∫', orientation='h')
            st.plotly_chart(ui.update_chart_layout(fig), use_container_width=True)

def render_menu(df_current, df_prev, current_label="", prev_label=""):
    view_mode = st.radio("–í–∏–¥:", ["–ú–∞–∫—Ä–æ", "–ú–∏–∫—Ä–æ"], horizontal=True, label_visibility="collapsed")
    target_cat = '–ú–∞–∫—Ä–æ_–ö–∞—Ç–µ–≥–æ—Ä–∏—è' if view_mode == "–ú–∞–∫—Ä–æ" else '–ö–∞—Ç–µ–≥–æ—Ä–∏—è'
    
    cats, items = analytics_service.compute_menu_tab_data(df_current, target_cat)
    
    c1, c2 = st.columns([1, 1.5])
    with c1:
        # Clean donut: group small categories into "–ü—Ä–æ—á–µ–µ" and simplify legend
        cats_sorted = cats.sort_values('–í—ã—Ä—É—á–∫–∞ —Å –ù–î–°', ascending=False).copy()
        total_rev = cats_sorted['–í—ã—Ä—É—á–∫–∞ —Å –ù–î–°'].sum()
        if total_rev > 0:
            cats_sorted['share'] = cats_sorted['–í—ã—Ä—É—á–∫–∞ —Å –ù–î–°'] / total_rev
            small_mask = cats_sorted['share'] < 0.03
            if small_mask.any():
                other_sum = cats_sorted.loc[small_mask, '–í—ã—Ä—É—á–∫–∞ —Å –ù–î–°'].sum()
                cats_sorted = cats_sorted.loc[~small_mask, [target_cat, '–í—ã—Ä—É—á–∫–∞ —Å –ù–î–°']]
                cats_sorted = pd.concat(
                    [cats_sorted, pd.DataFrame({target_cat: ["üì¶ –ü—Ä–æ—á–µ–µ"], "–í—ã—Ä—É—á–∫–∞ —Å –ù–î–°": [other_sum]})],
                    ignore_index=True
                )
        fig = px.pie(
            cats_sorted,
            values='–í—ã—Ä—É—á–∫–∞ —Å –ù–î–°',
            names=target_cat,
            hole=0.55,
            title="–°—Ç—Ä—É–∫—Ç—É—Ä–∞ –≤—ã—Ä—É—á–∫–∏"
        )
        fig.update_traces(textposition='inside', textinfo='percent', insidetextorientation='radial')
        fig.update_layout(
            legend=dict(orientation="h", yanchor="top", y=-0.2, xanchor="center", x=0.5),
            title=dict(x=0.5, y=0.97, xanchor="center", yanchor="top"),
            margin=dict(l=10, r=10, t=60, b=120)
        )
        st.plotly_chart(ui.update_chart_layout(fig), use_container_width=True)
    with c2:
        if not df_current.empty:
            with st.expander("üîç –§–∏–ª—å—Ç—Ä —Ç–∞–±–ª–∏—Ü—ã —Ñ—É–¥–∫–æ—Å—Ç–∞", expanded=False):
                c_f1, c_f2 = st.columns(2)
                with c_f1:
                    min_rev = st.number_input("–ú–∏–Ω. –≤—ã—Ä—É—á–∫–∞ (‚ÇΩ)", min_value=0, value=0, step=1000)
                    min_qty = st.number_input("–ú–∏–Ω. –∫–æ–ª-–≤–æ", min_value=0, value=0, step=10)
                with c_f2:
                    top_n = st.slider("–ü–æ–∫–∞–∑–∞—Ç—å —Ç–æ–ø N –ø–æ –≤—ã—Ä—É—á–∫–µ", 10, 300, 150)

            period_sorted = df_current.sort_values('–î–∞—Ç–∞_–û—Ç—á–µ—Ç–∞')
            cost_start = period_sorted.groupby('–ë–ª—é–¥–æ')['Unit_Cost'].first()
            cost_end = period_sorted.groupby('–ë–ª—é–¥–æ')['Unit_Cost'].last()
            agg = df_current.groupby('–ë–ª—é–¥–æ').agg({
                '–í—ã—Ä—É—á–∫–∞ —Å –ù–î–°': 'sum',
                '–°–µ–±–µ—Å—Ç–æ–∏–º–æ—Å—Ç—å': 'sum',
                '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ': 'sum'
            })
            agg['–§–∞–∫—Ç —Ñ—É–¥–∫–æ—Å—Ç %'] = (agg['–°–µ–±–µ—Å—Ç–æ–∏–º–æ—Å—Ç—å'] / agg['–í—ã—Ä—É—á–∫–∞ —Å –ù–î–°'] * 100).fillna(0)
            agg = agg[(agg['–í—ã—Ä—É—á–∫–∞ —Å –ù–î–°'] >= min_rev) & (agg['–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ'] >= min_qty)]
            df_fc = pd.DataFrame({
                '–ë–ª—é–¥–æ': agg.index,
                '–°/–° –Ω–∞—á–∞–ª–æ –ø–µ—Ä–∏–æ–¥–∞': cost_start,
                '–°/–° –∫–æ–Ω–µ—Ü –ø–µ—Ä–∏–æ–¥–∞': cost_end,
                '–§–∞–∫—Ç —Ñ—É–¥–∫–æ—Å—Ç %': agg['–§–∞–∫—Ç —Ñ—É–¥–∫–æ—Å—Ç %'],
                '–í—ã—Ä—É—á–∫–∞ —Å –ù–î–°': agg['–í—ã—Ä—É—á–∫–∞ —Å –ù–î–°'],
                '–ö–æ–ª-–≤–æ –ø—Ä–æ–¥–∞–Ω–æ': agg['–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ']
            }).reset_index(drop=True)
            df_fc = df_fc.sort_values('–í—ã—Ä—É—á–∫–∞ —Å –ù–î–°', ascending=False).head(top_n)
            st.dataframe(
                df_fc,
                column_config={
                    "–°/–° –Ω–∞—á–∞–ª–æ –ø–µ—Ä–∏–æ–¥–∞": st.column_config.NumberColumn(format="%.2f ‚ÇΩ"),
                    "–°/–° –∫–æ–Ω–µ—Ü –ø–µ—Ä–∏–æ–¥–∞": st.column_config.NumberColumn(format="%.2f ‚ÇΩ"),
                    "–§–∞–∫—Ç —Ñ—É–¥–∫–æ—Å—Ç %": st.column_config.NumberColumn(format="%.1f %%"),
                    "–í—ã—Ä—É—á–∫–∞ —Å –ù–î–°": st.column_config.NumberColumn(format="%.0f ‚ÇΩ"),
                    "–ö–æ–ª-–≤–æ –ø—Ä–æ–¥–∞–Ω–æ": st.column_config.NumberColumn(format="%.0f"),
                },
                use_container_width=True,
                height=400
            )
        else:
            st.info("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ —Ñ—É–¥–∫–æ—Å—Ç–∞.")

    if not df_prev.empty:
        cats_prev, _ = analytics_service.compute_menu_tab_data(df_prev, target_cat)
        cur_cmp = cats.rename(columns={'–í—ã—Ä—É—á–∫–∞ —Å –ù–î–°': '–¢–µ–∫—É—â–∏–π'})
        prev_cmp = cats_prev.rename(columns={'–í—ã—Ä—É—á–∫–∞ —Å –ù–î–°': '–°—Ä–∞–≤–Ω–µ–Ω–∏–µ'})
        cmp_df = cur_cmp.merge(prev_cmp, on=target_cat, how='outer').fillna(0)
        cmp_df = cmp_df.sort_values('–¢–µ–∫—É—â–∏–π', ascending=False).head(12)
        cmp_long = cmp_df.melt(
            id_vars=[target_cat],
            value_vars=['–¢–µ–∫—É—â–∏–π', '–°—Ä–∞–≤–Ω–µ–Ω–∏–µ'],
            var_name='–ü–µ—Ä–∏–æ–¥',
            value_name='–í—ã—Ä—É—á–∫–∞ —Å –ù–î–°'
        )
        period_names = {
            '–¢–µ–∫—É—â–∏–π': current_label or '–¢–µ–∫—É—â–∏–π –ø–µ—Ä–∏–æ–¥',
            '–°—Ä–∞–≤–Ω–µ–Ω–∏–µ': prev_label or '–ü–µ—Ä–∏–æ–¥ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è',
        }
        cmp_long['–ü–µ—Ä–∏–æ–¥'] = cmp_long['–ü–µ—Ä–∏–æ–¥'].map(period_names)
        fig_cmp = px.bar(
            cmp_long,
            x=target_cat,
            y='–í—ã—Ä—É—á–∫–∞ —Å –ù–î–°',
            color='–ü–µ—Ä–∏–æ–¥',
            barmode='group',
            title='–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –≤—ã—Ä—É—á–∫–∏ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º'
        )
        st.plotly_chart(ui.update_chart_layout(fig_cmp), use_container_width=True)

def render_abc(df_current):
    abc, aq, am = analytics_service.compute_abc_data(df_current)
    if abc.empty:
        st.info("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö")
        return
        
    st.info(f"–°—Ä–µ–¥–Ω–∏–µ –ø—Ä–æ–¥–∞–∂–∏: {aq:.1f} —à—Ç | –°—Ä–µ–¥–Ω—è—è –º–∞—Ä–∂–∞ —Å —à—Ç: {am:.0f} ‚ÇΩ")
    fig = px.scatter(
        abc, x="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ", y="Unit_Margin", color="–ö–ª–∞—Å—Å", size="–í—ã—Ä—É—á–∫–∞ —Å –ù–î–°", log_x=True,
        color_discrete_map={"‚≠ê –ó–≤–µ–∑–¥–∞": "blue", "üêé –õ–æ—à–∞–¥–∫–∞": "gold", "‚ùì –ó–∞–≥–∞–¥–∫–∞": "green", "üê∂ –°–æ–±–∞–∫–∞": "red"},
        hover_name="–ë–ª—é–¥–æ"
    )
    fig.add_vline(x=aq, line_dash="dash", line_color="gray")
    fig.add_hline(y=am, line_dash="dash", line_color="gray")
    st.plotly_chart(ui.update_chart_layout(fig), use_container_width=True)

    with st.expander("üìã –¢–∞–±–ª–∏—Ü–∞ ABC", expanded=False):
        with st.container():
            c_a1, c_a2 = st.columns(2)
            with c_a1:
                abc_min_rev = st.number_input("–ú–∏–Ω. –≤—ã—Ä—É—á–∫–∞ (‚ÇΩ) ", min_value=0, value=0, step=1000, key="abc_min_rev")
                abc_min_qty = st.number_input("–ú–∏–Ω. –∫–æ–ª-–≤–æ ", min_value=0, value=0, step=10, key="abc_min_qty")
            with c_a2:
                abc_top_n = st.slider("–ü–æ–∫–∞–∑–∞—Ç—å —Ç–æ–ø N –ø–æ –≤—ã—Ä—É—á–∫–µ ", 10, 300, 150, key="abc_top_n")

        abc_view = abc.rename(columns={
            "–ë–ª—é–¥–æ": "–ë–ª—é–¥–æ",
            "–í—ã—Ä—É—á–∫–∞ —Å –ù–î–°": "–í—ã—Ä—É—á–∫–∞",
            "–°–µ–±–µ—Å—Ç–æ–∏–º–æ—Å—Ç—å": "–°/–°",
            "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ": "–ö–æ–ª-–≤–æ",
            "Unit_Margin": "–ú–∞—Ä–∂–∞/—à—Ç",
            "–ö–ª–∞—Å—Å": "–ö–ª–∞—Å—Å"
        })
        abc_view = abc_view[(abc_view["–í—ã—Ä—É—á–∫–∞"] >= abc_min_rev) & (abc_view["–ö–æ–ª-–≤–æ"] >= abc_min_qty)]
        abc_view = abc_view.sort_values("–í—ã—Ä—É—á–∫–∞", ascending=False).head(abc_top_n)
        st.dataframe(
            abc_view[["–ë–ª—é–¥–æ", "–ö–ª–∞—Å—Å", "–í—ã—Ä—É—á–∫–∞", "–°/–°", "–ö–æ–ª-–≤–æ", "–ú–∞—Ä–∂–∞/—à—Ç"]],
            column_config={
                "–í—ã—Ä—É—á–∫–∞": st.column_config.NumberColumn(format="%.0f ‚ÇΩ"),
                "–°/–°": st.column_config.NumberColumn(format="%.0f ‚ÇΩ"),
                "–ö–æ–ª-–≤–æ": st.column_config.NumberColumn(format="%.0f"),
                "–ú–∞—Ä–∂–∞/—à—Ç": st.column_config.NumberColumn(format="%.0f ‚ÇΩ"),
            },
            use_container_width=True,
            height=400
        )

def render_simulator(df_current, df_full):
    st.subheader("üîÆ –°–∏–º—É–ª—è—Ç–æ—Ä: –ê–Ω–∞–ª–∏–∑ '–ß—Ç–æ –µ—Å–ª–∏?'")
    
    c_in, c_res = st.columns([1, 2])
    with c_in:
        all_cats = sorted(df_full['–ö–∞—Ç–µ–≥–æ—Ä–∏—è'].dropna().unique())
        sel_cats = st.multiselect("–ö–∞—Ç–µ–≥–æ—Ä–∏–∏:", all_cats, default=all_cats[:3] if len(all_cats)>3 else all_cats)
        
        st.markdown("---")
        d_price = st.slider("–¶–µ–Ω–∞ –ø—Ä–æ–¥–∞–∂–∏ (%)", -50, 50, 0)
        d_cost = st.slider("–°–µ–±–µ—Å—Ç–æ–∏–º–æ—Å—Ç—å (%)", -50, 50, 0)
        d_vol = st.slider("–û–±—ä–µ–º –ø—Ä–æ–¥–∞–∂ (%)", -50, 50, 0)

    with c_res:
        if sel_cats:
            res = analytics_service.compute_simulation(df_current, sel_cats, d_price, d_cost, d_vol)
            if res:
                k1, k2, k3 = st.columns(3)
                k1.metric("–ù–æ–≤–∞—è –í—ã—Ä—É—á–∫–∞", f"{res['sim_revenue']:,.0f} ‚ÇΩ", f"{res['diff_rev']:+,.0f} ‚ÇΩ")
                k2.metric("–ù–æ–≤–∞—è –ú–∞—Ä–∂–∞", f"{res['sim_margin']:,.0f} ‚ÇΩ", f"{res['diff_margin']:+,.0f} ‚ÇΩ")
                k3.metric("–†–µ–Ω—Ç–∞–±–µ–ª—å–Ω–æ—Å—Ç—å", f"{res['new_profitability']:.1f}%", f"{res['new_profitability'] - res['old_profitability']:+.1f}%")
                
                comp_df = pd.DataFrame([
                    {'Metric': '–ú–∞—Ä–∂–∞', 'Scenario': '–ë—ã–ª–æ', 'Value': res['base_margin']},
                    {'Metric': '–ú–∞—Ä–∂–∞', 'Scenario': '–°—Ç–∞–ª–æ', 'Value': res['sim_margin']}
                ])
                fig = px.bar(comp_df, x='Scenario', y='Value', color='Scenario', title="–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ú–∞—Ä–∂–∏")
                st.plotly_chart(ui.update_chart_layout(fig), use_container_width=True)

def render_weekdays(df_current, df_prev, current_label="", prev_label=""):
    daily_cur, weekday_cur = analytics_service.compute_weekday_stats(df_current)
    if weekday_cur.empty:
        st.info("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –¥–Ω–µ–π –Ω–µ–¥–µ–ª–∏.")
        return

    c1, c2 = st.columns(2)
    with c1:
        if not df_prev.empty:
            _, weekday_prev = analytics_service.compute_weekday_stats(df_prev)
            cur_cmp = weekday_cur.rename(columns={'–í—ã—Ä—É—á–∫–∞ —Å –ù–î–°': '–¢–µ–∫—É—â–∏–π'})
            prev_cmp = weekday_prev.rename(columns={'–í—ã—Ä—É—á–∫–∞ —Å –ù–î–°': '–°—Ä–∞–≤–Ω–µ–Ω–∏–µ'})
            cmp_df = cur_cmp.merge(prev_cmp, on='–î–µ–Ω—å–†—É—Å', how='outer').fillna(0)
            cmp_long = cmp_df.melt(
                id_vars=['–î–µ–Ω—å–†—É—Å'],
                value_vars=['–¢–µ–∫—É—â–∏–π', '–°—Ä–∞–≤–Ω–µ–Ω–∏–µ'],
                var_name='–ü–µ—Ä–∏–æ–¥',
                value_name='–í—ã—Ä—É—á–∫–∞ —Å –ù–î–°'
            )
            period_names = {
                '–¢–µ–∫—É—â–∏–π': current_label or '–¢–µ–∫—É—â–∏–π –ø–µ—Ä–∏–æ–¥',
                '–°—Ä–∞–≤–Ω–µ–Ω–∏–µ': prev_label or '–ü–µ—Ä–∏–æ–¥ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è',
            }
            cmp_long['–ü–µ—Ä–∏–æ–¥'] = cmp_long['–ü–µ—Ä–∏–æ–¥'].map(period_names)
            fig_avg = px.bar(
                cmp_long,
                x='–î–µ–Ω—å–†—É—Å',
                y='–í—ã—Ä—É—á–∫–∞ —Å –ù–î–°',
                color='–ü–µ—Ä–∏–æ–¥',
                barmode='group',
                title='–°—Ä–µ–¥–Ω—è—è –≤—ã—Ä—É—á–∫–∞ –ø–æ –¥–Ω—è–º –Ω–µ–¥–µ–ª–∏'
            )
        else:
            fig_avg = px.bar(weekday_cur, x='–î–µ–Ω—å–†—É—Å', y='–í—ã—Ä—É—á–∫–∞ —Å –ù–î–°', title='–°—Ä–µ–¥–Ω—è—è –≤—ã—Ä—É—á–∫–∞ –ø–æ –¥–Ω—è–º –Ω–µ–¥–µ–ª–∏')
        st.plotly_chart(ui.update_chart_layout(fig_avg), use_container_width=True)

    with c2:
        daily_cur = daily_cur.sort_values('–î–∞—Ç–∞_–û—Ç—á–µ—Ç–∞').copy()
        daily_cur['–ò–Ω–¥–µ–∫—Å–î–Ω—è'] = range(1, len(daily_cur) + 1)
        fig_daily = go.Figure()
        fig_daily.add_trace(go.Scatter(
            x=daily_cur['–ò–Ω–¥–µ–∫—Å–î–Ω—è'],
            y=daily_cur['–í—ã—Ä—É—á–∫–∞ —Å –ù–î–°'],
            mode='lines+markers',
            name=current_label or '–¢–µ–∫—É—â–∏–π –ø–µ—Ä–∏–æ–¥',
            text=daily_cur['–î–µ–Ω—å–†—É—Å'],
            customdata=daily_cur['–î–∞—Ç–∞_–ü–æ–¥–ø–∏—Å—å'],
            hovertemplate='–î–µ–Ω—å #%{x}<br>%{customdata} (%{text})<br>–í—ã—Ä—É—á–∫–∞: %{y:,.0f} ‚ÇΩ<extra></extra>'
        ))

        if not df_prev.empty:
            daily_prev, _ = analytics_service.compute_weekday_stats(df_prev)
            daily_prev = daily_prev.sort_values('–î–∞—Ç–∞_–û—Ç—á–µ—Ç–∞').copy()
            daily_prev['–ò–Ω–¥–µ–∫—Å–î–Ω—è'] = range(1, len(daily_prev) + 1)
            fig_daily.add_trace(go.Scatter(
                x=daily_prev['–ò–Ω–¥–µ–∫—Å–î–Ω—è'],
                y=daily_prev['–í—ã—Ä—É—á–∫–∞ —Å –ù–î–°'],
                mode='lines+markers',
                name=prev_label or '–ü–µ—Ä–∏–æ–¥ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è',
                text=daily_prev['–î–µ–Ω—å–†—É—Å'],
                customdata=daily_prev['–î–∞—Ç–∞_–ü–æ–¥–ø–∏—Å—å'],
                hovertemplate='–î–µ–Ω—å #%{x}<br>%{customdata} (%{text})<br>–í—ã—Ä—É—á–∫–∞: %{y:,.0f} ‚ÇΩ<extra></extra>'
            ))

        fig_daily.update_layout(title='–î–Ω–µ–≤–Ω–∞—è –¥–∏–Ω–∞–º–∏–∫–∞ –≤–Ω—É—Ç—Ä–∏ –ø–µ—Ä–∏–æ–¥–∞', xaxis_title='–ù–æ–º–µ—Ä –¥–Ω—è –ø–µ—Ä–∏–æ–¥–∞')
        st.plotly_chart(ui.update_chart_layout(fig_daily), use_container_width=True)

def render_procurement_v2(df_sales, df_full, period_days):
    st.subheader("üì¶ –ü–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –ó–∞–∫—É–ø–æ–∫")
    
    recipes_map = data_engine.get_recipes_map()
    stock_df = data_engine.get_stock_data()
    
    if not recipes_map:
        st.warning("‚ö†Ô∏è –ù–µ –Ω–∞–π–¥–µ–Ω—ã —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–µ –∫–∞—Ä—Ç—ã (TTK). –ó–∞–≥—Ä—É–∑–∏—Ç–µ –∏—Ö –≤ –ø–∞–ø–∫—É 'TechnologicalMaps'.")
        return
        
    if stock_df is None or stock_df.empty:
        st.warning("‚ö†Ô∏è –ù–µ –Ω–∞–π–¥–µ–Ω—ã –æ—Å—Ç–∞—Ç–∫–∏ (–û–±–æ—Ä–æ—Ç–∫–∞). –ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª—ã –≤ –ø–∞–ø–∫—É 'ProductTurnover'.")
        return

    # --- UI CONTROLS ---
    c_method, c_days = st.columns([2, 1])
    with c_method:
        forecast_method = st.radio(
            "–ú–µ—Ç–æ–¥ –ø—Ä–æ–≥–Ω–æ–∑–∞:",
            ["üìä –°—Ä–µ–¥–Ω–µ–µ –ø–æ –≤—ã–±—Ä–∞–Ω–Ω–æ–º—É –ø–µ—Ä–∏–æ–¥—É", "üß† –£–º–Ω—ã–π –ø—Ä–æ–≥–Ω–æ–∑ (–¢—Ä–µ–Ω–¥ + –ü—Ä–æ—à–ª—ã–π –≥–æ–¥)"],
            horizontal=True
        )
    with c_days:
         target_days = st.slider("–ù–∞ —Å–∫–æ–ª—å–∫–æ –¥–Ω–µ–π –∑–∞–∫—É–ø–∞–µ–º?", 1, 30, 7)

    preset_mode = st.selectbox(
        "–†–µ–∂–∏–º –ø—Ä–æ–≥–Ω–æ–∑–∞",
        ["–ê–≤—Ç–æ (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)", "–°—Ç–∞–±–∏–ª—å–Ω–æ", "–ê–≥—Ä–µ—Å—Å–∏–≤–Ω–æ", "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π"],
        index=0
    )

    # Defaults for presets
    preset_params = {
        "–ê–≤—Ç–æ (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)": dict(
            lead_time=3, trend_window_days=28, ly_window_days=14, sigma_window_days=56,
            service_level=95, holiday_boost=20, trend_weight=0.6, ly_weight=0.4,
            use_weekday_yoy=True, yoy_cap=1.5
        ),
        "–°—Ç–∞–±–∏–ª—å–Ω–æ": dict(
            lead_time=3, trend_window_days=42, ly_window_days=21, sigma_window_days=90,
            service_level=98, holiday_boost=10, trend_weight=0.4, ly_weight=0.6,
            use_weekday_yoy=True, yoy_cap=1.3
        ),
        "–ê–≥—Ä–µ—Å—Å–∏–≤–Ω–æ": dict(
            lead_time=2, trend_window_days=21, ly_window_days=10, sigma_window_days=42,
            service_level=90, holiday_boost=30, trend_weight=0.75, ly_weight=0.25,
            use_weekday_yoy=True, yoy_cap=1.8
        ),
    }

    with st.expander("‚öôÔ∏è –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –ø—Ä–æ–≥–Ω–æ–∑–∞ (—Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–µ)", expanded=(preset_mode == "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π")):
        c1, c2, c3 = st.columns(3)
        with c1:
            lead_time = st.slider("Lead time (–¥–Ω–µ–π)", 0, 21, 3)
            trend_window_days = st.slider("–û–∫–Ω–æ —Ç—Ä–µ–Ω–¥–∞ (–¥–Ω–µ–π)", 14, 120, 28)
        with c2:
            service_level = st.selectbox("Service level", [80, 90, 95, 98], index=2)
            holiday_boost = st.slider("–ö–æ—ç—Ñ. –ø—Ä–∞–∑–¥–Ω–∏–∫–æ–≤ (%)", 0, 100, 20)
            ly_window_days = st.slider("–û–∫–Ω–æ –ø—Ä–æ—à–ª–æ–≥–æ –≥–æ–¥–∞ (¬±–¥–Ω–µ–π)", 7, 45, 14)
        with c3:
            trend_weight = st.slider("–í–µ—Å —Ç—Ä–µ–Ω–¥–∞", 0.0, 1.0, 0.6)
            ly_weight = st.slider("–í–µ—Å –ø—Ä–æ—à–ª–æ–≥–æ –≥–æ–¥–∞", 0.0, 1.0, 0.4)
            sigma_window_days = st.slider("–û–∫–Ω–æ –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏ (–¥–Ω–µ–π)", 14, 180, 56)
            pack_size_default = st.number_input("–ö—Ä–∞—Ç–Ω–æ—Å—Ç—å (—É–ø–∞–∫–æ–≤–∫–∞)", 0.0, 10000.0, 0.0)
            min_order_default = st.number_input("–ú–∏–Ω. –∑–∞–∫–∞–∑ (MOQ)", 0.0, 10000.0, 0.0)
            use_weekday_yoy = st.checkbox("–£—Å–∏–ª–∏—Ç—å —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø–æ –¥–Ω—è–º –Ω–µ–¥–µ–ª–∏ (YoY)", value=True)
            yoy_cap = st.slider("–û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ YoY –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–∞", 0.5, 2.0, 1.5)

        st.caption("–ü—Ä–∞–∑–¥–Ω–∏–∫–∏: –≤–≤–µ–¥–∏—Ç–µ –¥–∞—Ç—ã –≤ —Ñ–æ—Ä–º–∞—Ç–µ `YYYY-MM-DD` –∏–ª–∏ `DD.MM.YYYY`, –ø–æ –æ–¥–Ω–æ–π –≤ —Å—Ç—Ä–æ–∫–µ.")
        holiday_text = st.text_area("–î–æ–ø. –ø—Ä–∞–∑–¥–Ω–∏–∫–∏", value="", height=100)

    if preset_mode != "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π":
        p = preset_params[preset_mode]
        lead_time = p["lead_time"]
        trend_window_days = p["trend_window_days"]
        ly_window_days = p["ly_window_days"]
        sigma_window_days = p["sigma_window_days"]
        service_level = p["service_level"]
        holiday_boost = p["holiday_boost"]
        trend_weight = p["trend_weight"]
        ly_weight = p["ly_weight"]
        use_weekday_yoy = p["use_weekday_yoy"]
        yoy_cap = p["yoy_cap"]
        st.info(f"–†–µ–∂–∏–º: {preset_mode}. –ò—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã.")

    days_in_period = max(1, period_days)

    # --- HELPER: Get Consumption DataFrame ---
    def get_consumption(df_source, days_count):
        if df_source.empty: return pd.DataFrame(columns=["ingredient", "unit", "qty_needed"])
        
        # Group sales
        s_grouped = df_source.groupby("–ë–ª—é–¥–æ")["–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ"].sum().reset_index()
        s_grouped["norm_dish"] = s_grouped["–ë–ª—é–¥–æ"].apply(lambda x: parsing_service.normalize_name(str(x)))
        
        cons_data = []
        for _, row in s_grouped.iterrows():
            name = row["norm_dish"]
            qty = row["–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ"]
            ingredients = recipes_map.get(name)
            if ingredients:
                for ing in ingredients:
                    cons_data.append({
                        "ingredient": ing["ingredient"],
                        "unit": ing["unit"],
                        "qty_needed": ing["qty_per_dish"] * qty
                    })
        
        if not cons_data: return pd.DataFrame(columns=["ingredient", "unit", "qty_needed"])
        
        df_c = pd.DataFrame(cons_data)
        return df_c.groupby(["ingredient", "unit"])["qty_needed"].sum().reset_index()

    # --- 1. CURRENT PERIOD CONSUMPTION ---
    # This is always calculated to show "Current Usage"
    df_cons_current = get_consumption(df_sales, days_in_period)
    df_cons_current["avg_current"] = df_cons_current["qty_needed"] / days_in_period

    # --- 2. SMART FORECAST (WEEKDAY AWARE) ---
    df_forecast = pd.DataFrame()
    sigma_map = {}
    
    if "–£–º–Ω—ã–π" in forecast_method:
        # 2. Helper to get Weekday Profiles (Sales Based) with RECURSION
        # SWITCH: Use History or Sales?
        df_history = data_engine.get_turnover_history()
        use_history = df_history is not None and not df_history.empty

        profile_trend = {}
        profile_ly = {}

        # Ensure datetime in history
        if use_history and not pd.api.types.is_datetime64_any_dtype(df_history['date']):
            df_history['date'] = pd.to_datetime(df_history['date'])

        # 1. Determine Target Dates (Tomorrow -> Tomorrow + N)
        # Since reports might be old, we use: LastReportDate + 1 -> + N
        if use_history:
            last_report_date = df_history['date'].max()
        else:
            last_report_date = df_full['–î–∞—Ç–∞_–û—Ç—á–µ—Ç–∞'].max()
        target_dates = [last_report_date + timedelta(days=i) for i in range(1, target_days + 1)]
        target_weekdays = [d.weekday() for d in target_dates] # 0=Mon, 6=Sun

        # Holidays (base + manual)
        # –†–§ 2026 (–ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–µ–Ω–Ω—ã–π –∫–∞–ª–µ–Ω–¥–∞—Ä—å): –ø–µ—Ä–∏–æ–¥—ã –æ—Ç–¥—ã—Ö–∞ —Å –ø–µ—Ä–µ–Ω–æ—Å–∞–º–∏
        # –ò—Å—Ç–æ—á–Ω–∏–∫: –ö–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç–ü–ª—é—Å (–ø—Ä–∞–∑–¥–Ω–∏–∫–∏ –∏ –ø–µ—Ä–µ–Ω–æ—Å –≤—ã—Ö–æ–¥–Ω—ã—Ö –≤ 2026 –≥.)
        def get_ru_holidays(year):
            holidays = set()
            if year == 2025:
                # 29.12.2024‚Äì08.01.2025
                holidays.update(pd.date_range("2024-12-29", "2025-01-08").date)
                # 22‚Äì23.02.2025
                holidays.update(pd.date_range("2025-02-22", "2025-02-23").date)
                # 08‚Äì09.03.2025
                holidays.update(pd.date_range("2025-03-08", "2025-03-09").date)
                # 01‚Äì04.05.2025
                holidays.update(pd.date_range("2025-05-01", "2025-05-04").date)
                # 08‚Äì11.05.2025
                holidays.update(pd.date_range("2025-05-08", "2025-05-11").date)
                # 12‚Äì15.06.2025
                holidays.update(pd.date_range("2025-06-12", "2025-06-15").date)
                # 02‚Äì04.11.2025
                holidays.update(pd.date_range("2025-11-02", "2025-11-04").date)
                # 31.12.2025
                holidays.add(pd.to_datetime("2025-12-31").date())
            if year == 2026:
                # 31.12.2025‚Äì11.01.2026
                holidays.update(pd.date_range("2025-12-31", "2026-01-11").date)
                # 21‚Äì23.02.2026
                holidays.update(pd.date_range("2026-02-21", "2026-02-23").date)
                # 07‚Äì09.03.2026
                holidays.update(pd.date_range("2026-03-07", "2026-03-09").date)
                # 01‚Äì03.05.2026
                holidays.update(pd.date_range("2026-05-01", "2026-05-03").date)
                # 09‚Äì11.05.2026
                holidays.update(pd.date_range("2026-05-09", "2026-05-11").date)
                # 12‚Äì14.06.2026
                holidays.update(pd.date_range("2026-06-12", "2026-06-14").date)
                # 04.11.2026
                holidays.add(pd.to_datetime("2026-11-04").date())
                # 31.12.2026
                holidays.add(pd.to_datetime("2026-12-31").date())
            return holidays

        base_holidays = {
            "01-01", "01-02", "01-03", "01-04", "01-05", "01-06", "01-07", "01-08",
            "02-23", "03-08", "05-01", "05-09", "06-12", "11-04"
        }
        manual_holidays = set()
        for line in holiday_text.splitlines():
            line = line.strip()
            if not line:
                continue
            try:
                manual_holidays.add(pd.to_datetime(line, dayfirst=True).date())
            except Exception:
                pass

        holiday_dates = set(manual_holidays)
        for d in target_dates:
            if d.strftime("%m-%d") in base_holidays:
                holiday_dates.add(d.date())

        years_in_targets = {d.year for d in target_dates}
        for y in years_in_targets:
            holiday_dates.update(get_ru_holidays(y))

        def explode_sales_to_ingredients(df_src):
            if df_src.empty:
                return pd.DataFrame(columns=["date", "ingredient", "qty"])
            df_src = df_src.copy()
            daily_sales = df_src.groupby(['–î–∞—Ç–∞_–û—Ç—á–µ—Ç–∞', '–ë–ª—é–¥–æ'])['–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ'].sum().reset_index()
            daily_sales['norm_dish'] = daily_sales['–ë–ª—é–¥–æ'].apply(lambda x: parsing_service.normalize_name(str(x)))
            rows = []

            def resolve_ingredients(name, qty_needed, dt, depth=0):
                if depth > 10:
                    return
                ings = recipes_map.get(name)
                if ings:
                    for ing in ings:
                        i_name = ing['ingredient']
                        sub_qty = qty_needed * ing['qty_per_dish']
                        resolve_ingredients(i_name, sub_qty, dt, depth + 1)
                else:
                    rows.append({"date": dt, "ingredient": name, "qty": qty_needed})

            for _, row in daily_sales.iterrows():
                resolve_ingredients(row["norm_dish"], row["–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ"], row["–î–∞—Ç–∞_–û—Ç—á–µ—Ç–∞"])
            if not rows:
                return pd.DataFrame(columns=["date", "ingredient", "qty"])
            return pd.DataFrame(rows)

        def get_combined_daily(start_date, end_date):
            # Sales-based daily ingredients
            df_sales_range = df_full[(df_full['–î–∞—Ç–∞_–û—Ç—á–µ—Ç–∞'] >= start_date) & (df_full['–î–∞—Ç–∞_–û—Ç—á–µ—Ç–∞'] <= end_date)]
            df_sales_ing = explode_sales_to_ingredients(df_sales_range)
            if not df_sales_ing.empty:
                df_sales_ing = df_sales_ing.groupby(['ingredient', 'date'])['qty'].sum().reset_index()

            # History-based daily ingredients
            df_hist_ing = pd.DataFrame(columns=["ingredient", "date", "qty_out"])
            if use_history:
                df_hist_ing = df_history[(df_history['date'] >= start_date) & (df_history['date'] <= end_date)].copy()
                if not df_hist_ing.empty:
                    # Exclude semi-finished (have recipes)
                    df_hist_ing = df_hist_ing[~df_hist_ing['ingredient'].isin(recipes_map.keys())]
                    df_hist_ing = df_hist_ing.groupby(['ingredient', 'date'])['qty_out'].sum().reset_index()

            if df_hist_ing.empty and df_sales_ing.empty:
                return pd.DataFrame(columns=["ingredient", "date", "qty"])

            df_combined = pd.merge(
                df_sales_ing.rename(columns={"qty": "qty_sales"}),
                df_hist_ing.rename(columns={"qty_out": "qty_hist"}),
                on=["ingredient", "date"],
                how="outer"
            )
            df_combined["qty"] = df_combined["qty_hist"].where(df_combined["qty_hist"].notna(), df_combined["qty_sales"])
            return df_combined[["ingredient", "date", "qty"]].fillna(0)

        def get_weekday_profile_from_daily(df_daily):
            if df_daily.empty:
                return {}
            df_daily = df_daily.copy()
            df_daily['weekday'] = df_daily['date'].dt.weekday
            grp = df_daily.groupby(['ingredient', 'weekday'])['qty'].median()
            profile = {}
            for (ing, wd), qty in grp.items():
                if ing not in profile:
                    profile[ing] = {w: 0.0 for w in range(7)}
                profile[ing][wd] = qty
            return profile

        # Trend window
        trend_start = last_report_date - timedelta(days=trend_window_days)
        df_trend_daily = get_combined_daily(trend_start, last_report_date)
        profile_trend = get_weekday_profile_from_daily(df_trend_daily)

        # Seasonal (Last Year window)
        ly_center = last_report_date - timedelta(days=365)
        ly_start = ly_center - timedelta(days=ly_window_days)
        ly_end = ly_center + timedelta(days=ly_window_days)
        df_ly_daily = get_combined_daily(ly_start, ly_end)
        profile_ly = get_weekday_profile_from_daily(df_ly_daily)

        # 3b. Daily consumption stats for safety stock
        avg_current_map = dict(zip(df_cons_current["ingredient"], df_cons_current["avg_current"])) if not df_cons_current.empty else {}
        if not df_sales.empty and use_history:
            period_start = df_sales['–î–∞—Ç–∞_–û—Ç—á–µ—Ç–∞'].min()
            period_end = df_sales['–î–∞—Ç–∞_–û—Ç—á–µ—Ç–∞'].max()
            df_period_daily = get_combined_daily(period_start, period_end)
            if not df_period_daily.empty:
                avg_current_map = (df_period_daily.groupby('ingredient')['qty'].sum() / days_in_period).to_dict()

        def compute_sigma_map():
            end_date = last_report_date
            start_date = last_report_date - timedelta(days=sigma_window_days - 1)
            date_index = pd.date_range(start_date, end_date, freq="D")
            sigma_map = {}

            df_sigma = get_combined_daily(start_date, end_date)
            if df_sigma.empty:
                return sigma_map
            df_sigma['date'] = pd.to_datetime(df_sigma['date'])
            agg = df_sigma.groupby(['ingredient', 'date'])['qty'].sum().reset_index()
            for ing, sub in agg.groupby('ingredient'):
                series = pd.Series(0.0, index=date_index)
                sub_series = sub.set_index('date')['qty']
                series.loc[sub_series.index] = sub_series.values
                sigma_map[ing] = float(series.std(ddof=0))
            return sigma_map

        sigma_map = compute_sigma_map()
        
        # 4. Calculate Demand for Target Dates
        final_forecast = []

        # Normalize weights
        wt = max(0.0, trend_weight)
        wl = max(0.0, ly_weight)
        if wt + wl == 0:
            wt, wl = 0.5, 0.5
        else:
            wt, wl = wt / (wt + wl), wl / (wt + wl)
        
        # Get all ingredients
        all_ings = set(profile_trend.keys()) | set(profile_ly.keys())
        
        for ing in all_ings:
            p_trend = profile_trend.get(ing, {w: 0.0 for w in range(7)})
            p_ly = profile_ly.get(ing, {w: 0.0 for w in range(7)})
            avg_current = avg_current_map.get(ing, 0.0)
            
            total_need = 0.0
            sum_trend = 0.0
            sum_ly = 0.0
            sum_holiday_factor = 0.0
            
            for dt, wd in zip(target_dates, target_weekdays):
                # Forecast for this specific day = (Trend[wd] + LY[wd]) / 2
                val_t = p_trend[wd]
                val_l = p_ly[wd]

                # Weekday YoY adjustment: compare this year's recent weekday vs last year's weekday
                if use_weekday_yoy and val_l > 0:
                    ratio = val_t / val_l
                    if ratio < 1.0 / yoy_cap:
                        ratio = 1.0 / yoy_cap
                    elif ratio > yoy_cap:
                        ratio = yoy_cap
                    val_l = val_l * ratio
                
                sum_trend += val_t
                sum_ly += val_l
                
                day_val = (val_t * wt) + (val_l * wl)
                if day_val == 0.0 and avg_current > 0:
                    day_val = avg_current

                holiday_factor = 1.0
                if dt.date() in holiday_dates:
                    holiday_factor = (1 + holiday_boost / 100.0)
                    day_val = day_val * holiday_factor
                sum_holiday_factor += holiday_factor
                
                total_need += day_val
                
            # Avg metrics for display
            avg_daily_trend = sum_trend / target_days
            avg_daily_ly = sum_ly / target_days
            daily_forecast = total_need / target_days
            avg_holiday_factor = sum_holiday_factor / target_days if target_days > 0 else 1.0
            
            final_forecast.append({
                "ingredient": ing,
                "daily_forecast": daily_forecast, # This is technically "Avg Need for Target Period"
                "avg_trend": avg_daily_trend,
                "avg_ly": avg_daily_ly,
                "holiday_factor": avg_holiday_factor,
                "wt": wt,
                "wl": wl,
            })
            
        df_forecast = pd.DataFrame(final_forecast)
        if df_forecast.empty:
            df_forecast = pd.DataFrame(columns=["ingredient", "daily_forecast", "avg_trend", "avg_ly"])

    else:
        # Simple Mode: Forecast = Current Period Avg
        df_forecast = df_cons_current[["ingredient", "avg_current"]].rename(columns={"avg_current": "daily_forecast"})
        df_forecast["avg_trend"] = 0.0
        df_forecast["avg_ly"] = 0.0

    # 3. Merge with Stock
    # We use df_forecast as the base for "Needs", but we also want to show current period usage for reference?
    # Actually, the procurement should be based on the Forecast.
    
    # Let's merge Forecast with Stock
    df_final = pd.merge(df_forecast, stock_df, on="ingredient", how="outer")
    
    # Fill NaNs
    df_final["daily_forecast"] = df_final["daily_forecast"].fillna(0)
    df_final["stock_qty"] = df_final["stock_qty"].fillna(0)
    df_final["avg_trend"] = df_final.get("avg_trend", pd.Series(0)).fillna(0)
    df_final["avg_ly"] = df_final.get("avg_ly", pd.Series(0)).fillna(0)
    df_final["holiday_factor"] = df_final.get("holiday_factor", pd.Series(1.0)).fillna(1.0)
    df_final["wt"] = df_final.get("wt", pd.Series(0.0)).fillna(0.0)
    df_final["wl"] = df_final.get("wl", pd.Series(0.0)).fillna(0.0)
    
    # Recover Unit (it might be lost in merges if not careful)
    # We can get unit from recipes or stock or consumption df
    # Let's try to fetch it from df_cons_current or stock
    
    # Helper to map units
    # Create valid unit map from all sources
    all_units = {}
    if not df_cons_current.empty: 
        all_units.update(dict(zip(df_cons_current.ingredient, df_cons_current.unit)))
    
    if "unit" in stock_df.columns:
        all_units.update(dict(zip(stock_df.ingredient, stock_df.unit))) 
    
    df_final["unit"] = df_final["ingredient"].map(all_units).fillna("")

    # 4. Analyze

    # Safety stock (simple, based on variability)
    z_map = {80: 0.84, 90: 1.28, 95: 1.65, 98: 2.05}
    z = z_map.get(service_level, 1.65)
    review_period = max(1, target_days)
    horizon = lead_time + review_period
    df_final["sigma_daily"] = df_final["ingredient"].map(sigma_map).fillna(df_final["daily_forecast"] * 0.25)
    df_final["safety_stock"] = z * df_final["sigma_daily"] * (horizon ** 0.5)
    on_order_cols = [c for c in ["on_order_qty", "in_transit", "in_transit_qty", "on_order"] if c in df_final.columns]
    if on_order_cols:
        df_final["on_order"] = df_final[on_order_cols[0]].fillna(0)
    else:
        df_final["on_order"] = 0.0
    
    # Days Left = Stock / Daily Forecast
    df_final["days_left"] = df_final.apply(
        lambda x: x["stock_qty"] / x["daily_forecast"] if x["daily_forecast"] > 0.001 else 999, 
        axis=1
    )
    
    df_final["to_buy"] = (df_final["daily_forecast"] * horizon) + df_final["safety_stock"] - df_final["stock_qty"] - df_final["on_order"]
    df_final["to_buy"] = df_final["to_buy"].apply(lambda x: max(0.0, x))

    # Apply MOQ / pack size if provided (use per-item overrides when available)
    pack_col = "pack_size" if "pack_size" in df_final.columns else None
    moq_col = "min_order_qty" if "min_order_qty" in df_final.columns else None

    def apply_pack_moq(row):
        qty = row["to_buy"]
        if qty <= 0:
            return 0.0
        pack = row[pack_col] if pack_col else pack_size_default
        moq = row[moq_col] if moq_col else min_order_default
        try:
            pack = float(pack) if pack is not None else 0.0
        except Exception:
            pack = 0.0
        try:
            moq = float(moq) if moq is not None else 0.0
        except Exception:
            moq = 0.0
        if pack and pack > 0:
            qty = (int((qty + pack - 1) // pack) * pack)
        if moq and moq > 0:
            qty = max(qty, moq)
        return qty

    df_final["to_buy"] = df_final.apply(apply_pack_moq, axis=1)
    
    # Filter: Show only relevant items
    df_view = df_final[(df_final["daily_forecast"] > 0) | (df_final["stock_qty"] > 0)].copy()
    
    # Sort
    df_view = df_view.sort_values("days_left", ascending=True)
    
    # Metrics Header
    st.info(f"üìä –ó–∞–≥—Ä—É–∂–µ–Ω–æ —Ä–µ—Ü–µ–ø—Ç–æ–≤: {len(recipes_map)}. –ü–æ–∑–∏—Ü–∏–π –Ω–∞ —Å–∫–ª–∞–¥–µ: {len(stock_df)}")

    # Rename & Columns
    cols_to_show = ["ingredient", "unit", "stock_qty", "days_left", "to_buy", "safety_stock"]
    rename_map = {
        "ingredient": "–ò–Ω–≥—Ä–µ–¥–∏–µ–Ω—Ç",
        "unit": "–ï–¥.",
        "stock_qty": "–û—Å—Ç–∞—Ç–æ–∫",
        "days_left": "–•–≤–∞—Ç–∏—Ç (–¥–Ω–µ–π)",
        "to_buy": "–ó–∞–∫—É–ø–∏—Ç—å",
        "safety_stock": "–°—Ç—Ä–∞—Ö. –∑–∞–ø–∞—Å"
    }

    if "–£–º–Ω—ã–π" in forecast_method:
        trend_label = f"–¢—Ä–µ–Ω–¥ ({trend_window_days}–¥)"
        cols_to_show = cols_to_show[:2] + ["avg_trend", "avg_ly", "daily_forecast"] + cols_to_show[2:]
        rename_map.update({
            "avg_trend": trend_label,
            "avg_ly": "–ü—Ä–æ—à–ª—ã–π –≥–æ–¥",
            "daily_forecast": "–ü—Ä–æ–≥–Ω–æ–∑/–¥–µ–Ω—å",
            "holiday_factor": "–ü—Ä–∞–∑–¥–Ω. –∫–æ—ç—Ñ."
        })
        cols_to_show = cols_to_show[:5] + ["holiday_factor"] + cols_to_show[5:]
    else:
        cols_to_show.insert(2, "daily_forecast")
        rename_map["daily_forecast"] = "–°—Ä. —Ä–∞—Å—Ö–æ–¥/–¥–µ–Ω—å"
        
    df_display = df_view[cols_to_show].rename(columns=rename_map)
    
    # Formatting
    format_dict = {
        "–û—Å—Ç–∞—Ç–æ–∫": "{:.2f}",
        "–•–≤–∞—Ç–∏—Ç (–¥–Ω–µ–π)": "{:.0f}",
        "–ó–∞–∫—É–ø–∏—Ç—å": "{:.2f}",
        "–°—Ä. —Ä–∞—Å—Ö–æ–¥/–¥–µ–Ω—å": "{:.2f}",
        "–ü—Ä–æ–≥–Ω–æ–∑/–¥–µ–Ω—å": "{:.2f}",
        "–ü—Ä–æ—à–ª—ã–π –≥–æ–¥": "{:.2f}",
        "–ü—Ä–∞–∑–¥–Ω. –∫–æ—ç—Ñ.": "{:.2f}"
    }
    if "–£–º–Ω—ã–π" in forecast_method:
        format_dict[trend_label] = "{:.2f}"

    st.dataframe(
        df_display.style.format(format_dict).apply(
            lambda x: ["color: #e53935; font-weight: 700" if v < 3 else ("color: #f9a825; font-weight: 700" if v < 7 else "") for v in x],
            subset=["–•–≤–∞—Ç–∏—Ç (–¥–Ω–µ–π)"]
        )
    )
